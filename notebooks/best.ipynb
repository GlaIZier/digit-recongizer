{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-sellers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.seed=101\n",
    "args.reproducibility = True\n",
    "\n",
    "args.run_baseline = True\n",
    "\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "args.predictions_folder = Path('../predictions/best')\n",
    "args.models_folder = Path('../models/best')\n",
    "\n",
    "args.model_name = 'best.hdf5'\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.models_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.run_baseline = True\n",
    "args.run_transfer = False\n",
    "args.run_augment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def reproducibility():\n",
    "    if args.reproducibility:\n",
    "        tf.random.set_seed(args.seed)\n",
    "\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAABKCAYAAADkMDmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFNElEQVR4nO2bTWhUVxTHf//mYxNbUPphbKTaWAwqNG1CS2kXES2pdlETTDCLQsBiKQiGUrC4ErRiFymSRYpKXbVQQhuhYqGLaqEurMZoojGN2GAbYyiGLCalYPvG08V7Mx1FncmbO+Mb8/5wYN7l3Y/5vXPP3HvfGZkZ812PPewBREExBGIIQAwBiCEAMQQghgBEHIKkLyVNSUpIuiLpvYL0E+XFkqTVwFUzuyWpDvgJeNvMzrnsJ9KeYGYjZnYrdRlYret+Ig0BQFKvpL+BX4Ep4HvnfUR5OqQkqQx4DWgCPjWzf122H3lPADCzpJmdAmqAD1y3XxIQMlTOfIoJkp6WtEXSAkllkpqBDuBH531FNSZIegr4BngR/2H9DvSY2WHnfUUVQjEV2elQTMUQyBOCpLckjUm6KuljV4MqtkLHhGABcwV4E7gOnAU6zOyyu+EVR/l4wiv4m5txM/sH+Bp4x82wiqvyPOo+C0xkXF8HXr37JknbgG3BZUMe/c1ZZqZc7ssHQq4DOQQcApAUyd/jfKbDJLA047omKCs9mVkow/eicWA5UAkMAauz1LFiWq7fJbQnmJkHbAd+AEaBPjMbCdve3WpqauLEiROYGYlEgj179tDY2Eh5eQFmcFhPCOk9OT3B9evXWyKRMM/zLJlMmud5aevp6bHKykqnnhBJCGNjY+kv3dnZaZ2dnXb06NF02b59+x59CDt37rSBgQHr6OhIl61YsSIN4dixY48+hHvZ2rVr5zeErq4uu3HjhnmeZ6dPn7bm5ub5A6Gurs7a2trs+PHj5nmeTU9PW319fc71cx1XwVeM+ailpYW9e/emAJJIJJiennbfUZQ9oaqqyg4cOGCDg4PpeHD+/HlbsmTJ/JkOKVu0aNEdIPr7+51CKImTpZmZGdrb25GEJCoqKpy2H+mYcLdSscG1SsITCq2SgFBTU8PWrVsL10HUA+O6detsfHw8HRSHhoZs06ZN8+fXoba29o5d5MzMjDU0NDhfLEUKQnV1tbW1tdmaNWts//79NjExYclk0mZnZ623t9dWrlw5J4jOIOAfoZ0ELgMjwI6gfDf+cdqFwDbmA2Hx4sXW3d1tnufZzZs300//zJkztnnz5lDrC5cQqoGXg8+P479rWBVA+MiVJ/T19d1xeHLw4EFrb2+3qqqqUADmAiHrOsHMpvDTZDCzWUmj+MftTjU8PExrayujo6Ns2LCBycnJFLjCa45PchnwB/AEvidcA4aBI8DC+9TZBgwEFvqphjHngRFYAJwDWoPrZ4Ay/LXGJ8CRfANjpCEAFfinyh8+wEMulSqErDFBkoAvgFEz+yyjvDqIFwAtwKVsbQF/AWM53JePngSmgedyrZD1rbSkN4CfgYvA7aB4F37+UD0+9WvA+xlQ7tfWgJk15jq4MArTRy6/DqeAe73YdJ5U+bBUEhuoQqvYEA5FsY84e414OgBFhOA6yUvSUkknJV2WNCJpR1C+W9KkpAuBbcza2FyWzWENf2X5G/A8/+cyrMqzTWcbu2J5gvMkLzObMrPB4PMsfo5EqI1dsSDcK8nL2U5U0jLgJeCXoGi7pGFJRyQtzFa/5AOjpAXAt0CXmSWAz/H/DlCPfwTQna2NYkEoSJKXpAp8AF+ZWT+Amf1p/p9EbgOH8afiA1UsCGeBFyQtl1QJbAG+y6fBB23sMm7LaWNXlDdQZuZJSiV5leGfPeSb5PU68C5wUdKFoGwX0CGpnoyNXbaG4hUjj0BgdKEYAjEEIIYAxBCAGAIQQwBiCAD8BxnJMrOuzxdrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def draw_digit(pixels_2d, label=None, size_inches=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    if label is not None:\n",
    "        ax.set_title(label)\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    imgplot = ax.imshow(pixels_2d, cmap='gray')\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "draw_digit(pixels_2d, label, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fixed-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 16:44:29,569 : INFO : X_train_full.shape: (42000, 28, 28, 1)\n",
      "2021-05-13 16:44:29,570 : INFO : Y_train_full.shape: (42000, 10)\n",
      "2021-05-13 16:44:29,575 : INFO : Type of target Y_train_full: 'multilabel-indicator'\n",
      "2021-05-13 16:44:29,576 : INFO : y_train_full.shape: (42000,)\n",
      "2021-05-13 16:44:29,577 : INFO : Type of target y_train_full: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X_train_full = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1) / 255.0\n",
    "Y_train_full = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_train_full = args.labels.to_numpy()\n",
    "X_test = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1) / 255.0\n",
    "\n",
    "log.info('X_train_full.shape: %s', repr(X_train_full.shape))\n",
    "# log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('Y_train_full.shape: %s', repr(Y_train_full.shape))\n",
    "# log.info('y[0], %s', y[0])\n",
    "log.info('Type of target Y_train_full: %s', repr(sklearn.utils.multiclass.type_of_target(Y_train_full)))\n",
    "\n",
    "log.info('y_train_full.shape: %s', repr(y_train_full.shape))\n",
    "# log.info('y_sparse: %s', repr(y_sparse))\n",
    "# log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('Type of target y_train_full: %s', repr(sklearn.utils.multiclass.type_of_target(y_train_full)))\n",
    "\n",
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_classes = np.argmax(predictions, axis=1)\n",
    "    image_ids = np.arange(1, len(predictions_classes) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_classes})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-necklace",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wound-proceeding",
   "metadata": {},
   "source": [
    "def reprod():\n",
    "    reproducibility()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    monitor='val_accuracy'\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=monitor, patience=10, mode='auto', restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, min_delta=1e-4, mode='auto', verbose=1)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=args.val_fraction, epochs=1, batch_size=32,\n",
    "                        verbose=1, callbacks=[early_stopping, reduce_lr_on_plateau])\n",
    "    plot_history(history)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'baseline.csv')\n",
    "\n",
    "reprod()\n",
    "\n",
    "assert False\n",
    "# mac mini 1182/1182 [==============================] - 20s 16ms/step - loss: 0.5071 - accuracy: 0.8442 - val_loss: 0.0995 - val_accuracy: 0.9707\n",
    "# macbook 1182/1182 [==============================] - 62s 50ms/step - loss: 0.5066 - accuracy: 0.8437 - val_loss: 0.1070 - val_accuracy: 0.9662\n",
    "# macbook 29/29 [==============================] - 4s 64ms/step - loss: 2.2990 - accuracy: 0.3006 - val_loss: 3.0213 - val_accuracy: 0.5200\n",
    "\n",
    "# mini 1182/1182 [==============================] - 31s 25ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# macbook 1182/1182 [==============================] - 74s 60ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729\n",
    "# mini 1182/1182 [==============================] - 34s 28ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# mini 1182/1182 [==============================] - 31s 25ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# macbook 1182/1182 [==============================] - 73s 60ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729\n",
    "# macbook 1182/1182 [==============================] - 74s 61ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tribal-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,954\n",
      "Trainable params: 242,250\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      " 477/1182 [===========>..................] - ETA: 12s - loss: 0.8184 - accuracy: 0.7370"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e5eda9222e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_baseline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e5eda9222e1a>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mreduce_lr_on_plateau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     history = model.fit(X_train_full, y_train_full, validation_split=args.val_fraction, epochs=args.epochs, batch_size=32,\n\u001b[0m\u001b[1;32m     38\u001b[0m                         verbose=1, callbacks=[early_stopping, reduce_lr_on_plateau])\n\u001b[1;32m     39\u001b[0m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# 1-cycle lr\n",
    "# data augmentation\n",
    "# ensemble\n",
    "def baseline():\n",
    "    reproducibility()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    monitor='val_loss'\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=monitor, patience=10, mode='auto', restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, min_delta=1e-4, mode='auto', verbose=1)\n",
    "    \n",
    "    history = model.fit(X_train_full, y_train_full, validation_split=args.val_fraction, epochs=args.epochs, batch_size=32,\n",
    "                        verbose=1, callbacks=[early_stopping, reduce_lr_on_plateau])\n",
    "    plot_history(history)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'baseline.csv')\n",
    "\n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-place",
   "metadata": {},
   "source": [
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | No dropout, early_stopping='val_acc' | 0.99017 | 0.9924 |\n",
    "| Baseline | Dropout=0.4, early_stopping='val_acc' | 0.99200 | 0.9931 |\n",
    "| Baseline | Dropout=0.4, Batch normalization, early_stopping='val_acc'  | 0.99278 |  0.9943 |\n",
    "| Baseline | Dropout=0.4, Batch normalization, early_stopping='val_loss'  | 0.99389 |  0.9948 |\n",
    "\n",
    "\n",
    "##### Other results\n",
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | Dropout=0.25 (after 2 first conv) | 0.99150 | 0.9929 |\n",
    "| Baseline | Dropout=0.5 (after 2 first conv) | 0.99178 | 0.9924 |\n",
    "| Baseline | Dropout=0.5  | 0.98867 | 0.9912 |\n",
    "| Baseline | Dropout=0.3  | 0.99182 |  0.9936 |\n",
    "| Baseline | Dropout=0.4 batch normalization before activation  | 0.99275 |  0.9929 |\n",
    "| Baseline | Dropout=0.4 batch normalization he normal | 0.99250 |  0.9940 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-texture",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transfer_learning():\n",
    "    batch_size = 32\n",
    "    train_idx = len(X_train) - int(len(X_train) * args.val_fraction)\n",
    "    val_idx = train_idx\n",
    "#     train_idx = 50\n",
    "#     val_idx = len(X_train) - train_idx \n",
    "    def preprocess(image, label):\n",
    "        resized_image = tf.image.resize(image, [224, 224])\n",
    "        rgb_image = tf.image.grayscale_to_rgb(resized_image)\n",
    "        final_image = keras.applications.xception.preprocess_input(rgb_image)\n",
    "        return final_image, label\n",
    "    \n",
    "    def dataset(features_labels):\n",
    "        def debug_data(data):\n",
    "            for d in data:\n",
    "                print(d)\n",
    "                fig, ax = plt.subplots()\n",
    "                imgplot = ax.imshow(d[0][0])\n",
    "                break\n",
    "        data = tf.data.Dataset.from_tensor_slices(features_labels).shuffle(len(X_train)).map(preprocess).batch(batch_size).prefetch(1)\n",
    "        return data\n",
    "    \n",
    "    def build_model():\n",
    "        base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "        avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        output = keras.layers.Dense(10, activation='softmax')(avg)\n",
    "        model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "        return base_model, model\n",
    "    \n",
    "    \n",
    "    def train(base_model, model, train_data, val_data, train_base=False, epochs=5, lr=0.2):\n",
    "        for l in base_model.layers:\n",
    "            l.tranable = False\n",
    "        optimizer = keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        history = model.fit(train_data, epochs=epochs, validation_data=val_data)\n",
    "        plot_history(history)\n",
    "    \n",
    "    train_data = dataset((X_train[:train_idx], y_train[:train_idx]))\n",
    "    val_data = dataset((X_train[val_idx:], y_train[val_idx:]))\n",
    "    base_model, model = build_model()\n",
    "    train(base_model, model, train_data, val_data)\n",
    "    train(base_model, model, train_data, val_data, train_base=True, lr=0.01)\n",
    "\n",
    "if args.run_transfer:\n",
    "    transfer_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-entertainment",
   "metadata": {},
   "source": [
    "### 1-cycle learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-knowing",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tamil-perfume",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-79447c18c18b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_augment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-79447c18c18b>\u001b[0m in \u001b[0;36mdata_augmentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     datagen = keras.preprocessing.image.ImageDataGenerator(\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         rescale=255,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         featurewise_center=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "def data_augmentation():\n",
    "    X_train, X_val, y_train2, Y_val2 = train_test_split(X_train_full, y_train_full, test_size = 0.1)\n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#         rescale=255,\n",
    "#         featurewise_center=True,\n",
    "#         featurewise_std_normalization=True,\n",
    "#         shear_range=0.2,\n",
    "#         channel_shift_range=0.2,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2)\n",
    "    datagen.fit(X_train)\n",
    "#     for x in X_train:\n",
    "#         print(x[12][12])\n",
    "#         augm_x = datagen.apply_transform(x, {'flip_horizontal': True})\n",
    "#         draw_digit(x)\n",
    "#         draw_digit(augm_x)\n",
    "#         print(augm_x[12][12])\n",
    "#         break\n",
    "\n",
    "    \n",
    "    train_generator = datagen.flow(X_train, y_train)\n",
    "    \n",
    "    for i in range(10):\n",
    "        d = train_generator.next()\n",
    "        print(d[0].shape)\n",
    "        draw_digit(d[0][0])\n",
    "#     for d in train_generator:\n",
    "#         print(d[0].shape)\n",
    "#         draw_digit(d[0][0])\n",
    "#         print(d[0][0])\n",
    "#         break\n",
    "\n",
    "if args.run_augment:\n",
    "    data_augmentation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
