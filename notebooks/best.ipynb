{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-sellers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.seed=101\n",
    "args.reproducibility = True\n",
    "\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "args.predictions_folder = Path('../predictions/best')\n",
    "args.models_folder = Path('../models/best')\n",
    "\n",
    "args.model_name = 'best.hdf5'\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.models_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.run_baseline = 0\n",
    "args.run_transfer = 1\n",
    "args.run_augment = 0\n",
    "args.run_ensemble = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reproducibility():\n",
    "    if args.reproducibility:\n",
    "        np.random.seed(args.seed)\n",
    "        tf.random.set_seed(args.seed)\n",
    "\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def draw_digit(pixels_2d, label=None, size_inches=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    if label is not None:\n",
    "        ax.set_title(label)\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    imgplot = ax.imshow(pixels_2d, cmap='gray')\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "draw_digit(pixels_2d, label, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fixed-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 14:10:14,808 : INFO : X_train_full.shape: (42000, 28, 28, 1)\n",
      "2021-06-01 14:10:14,809 : INFO : Y_train_full.shape: (42000, 10)\n",
      "2021-06-01 14:10:14,814 : INFO : Type of target Y_train_full: 'multilabel-indicator'\n",
      "2021-06-01 14:10:14,815 : INFO : y_train_full.shape: (42000,)\n",
      "2021-06-01 14:10:14,816 : INFO : Type of target y_train_full: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X_train_full = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1) / 255.0\n",
    "Y_train_full = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_train_full = args.labels.to_numpy()\n",
    "X_test = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1) / 255.0\n",
    "\n",
    "log.info('X_train_full.shape: %s', repr(X_train_full.shape))\n",
    "# log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('Y_train_full.shape: %s', repr(Y_train_full.shape))\n",
    "# log.info('y[0], %s', y[0])\n",
    "log.info('Type of target Y_train_full: %s', repr(sklearn.utils.multiclass.type_of_target(Y_train_full)))\n",
    "\n",
    "log.info('y_train_full.shape: %s', repr(y_train_full.shape))\n",
    "# log.info('y_sparse: %s', repr(y_sparse))\n",
    "# log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('Type of target y_train_full: %s', repr(sklearn.utils.multiclass.type_of_target(y_train_full)))\n",
    "\n",
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_classes = np.argmax(predictions, axis=1)\n",
    "    csv_predictions_categorical(predictions_classes, filename)\n",
    "\n",
    "def csv_predictions_categorical(predictions_classes, filename):\n",
    "    image_ids = np.arange(1, len(predictions_classes) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_classes})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-necklace",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tribal-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def baseline_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    monitor='val_loss'\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=monitor, patience=10, mode='auto', restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, min_delta=1e-4, mode='auto', verbose=1)\n",
    "    \n",
    "    return model, [early_stopping, reduce_lr_on_plateau]\n",
    "\n",
    "def baseline():\n",
    "    reproducibility()\n",
    "    model, callbacks = baseline_model()\n",
    "    \n",
    "    history = model.fit(X_train_full, y_train_full, validation_split=args.val_fraction, epochs=args.epochs, \n",
    "                        callbacks=callbacks, verbose=1)\n",
    "    plot_history(history)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'baseline.csv')\n",
    "\n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-place",
   "metadata": {},
   "source": [
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | No dropout, early_stopping='val_acc' | 0.99017 | 0.9924 |\n",
    "| Baseline | Dropout=0.4, early_stopping='val_acc' | 0.99200 | 0.9931 |\n",
    "| Baseline | Dropout=0.4, Batch normalization, early_stopping='val_acc'  | 0.99278 |  0.9943 |\n",
    "| Baseline | Dropout=0.4, Batch normalization, early_stopping='val_loss'  | 0.99389 |  0.9948 |\n",
    "\n",
    "\n",
    "##### Other results\n",
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | Dropout=0.25 (after 2 first conv) | 0.99150 | 0.9929 |\n",
    "| Baseline | Dropout=0.5 (after 2 first conv) | 0.99178 | 0.9924 |\n",
    "| Baseline | Dropout=0.5  | 0.98867 | 0.9912 |\n",
    "| Baseline | Dropout=0.3  | 0.99182 |  0.9936 |\n",
    "| Baseline | Dropout=0.4 batch normalization before activation  | 0.99275 |  0.9929 |\n",
    "| Baseline | Dropout=0.4 batch normalization he normal | 0.99250 |  0.9940 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-texture",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "endless-running",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 1 512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 2 32768       add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 2 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 7 186368      add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 7 2912        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 745472      add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 1 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           20490       global_average_pooling2d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,881,970\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x172fe8160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:06:44,152 : WARNING : 6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x172fe8160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 2.3355 - accuracy: 0.0256WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x172ffdd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:06:46,689 : WARNING : 6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x172ffdd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 6s 3s/step - loss: 2.3358 - accuracy: 0.0237 - val_loss: 2.2497 - val_accuracy: 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:06:47,352 : INFO : History keys: dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdRUlEQVR4nO3df7RcZX3v8ffHEBNNACFohAQMipULVyR6FhahemKt1WIL1h+Ya/lRtCxZbdVWa5FexR/QFpdSpa3XUrHUas3lIqyLZSEiJVQvFQ2YBpIgKGKJRApBCBEQot/7x2xwjCfh5Mec82TO+7XWWZl59rNnvnO+Rj559t6zU1VIkiSpDU+Y7AIkSZL0M4YzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRNWUkWJKkku4xj7olJvrq9ryNJj8dwJmmnkOS2JA8n2WuT8W92wWjBJJUmSTuU4UzSzuS7wOJHnyR5LvDkyStHknY8w5mknck/Acf3PT8B+HT/hCS7J/l0kruSfC/J/0zyhG7btCQfTnJ3kluBo8bY97wka5N8P8kZSaZtbZFJ9klySZJ7knw7ye/1bTssybIk65PcmeTsbnxmks8kWZfk3iTfSDJ3a99b0s7PcCZpZ/I1YLck/60LTW8APrPJnL8GdgeeCbyEXpj73W7b7wGvAhYCI8BrN9n3fGAjcEA35+XAm7ehziXAGmCf7j3+PMlLu20fAz5WVbsBzwIu6MZP6OreF5gDvAV4cBveW9JOznAmaWfz6OrZrwGrge8/uqEvsL27qu6vqtuAjwDHdVNeD3y0qm6vqnuAv+jbdy7wG8Dbq+pHVfVfwF91rzduSfYFjgD+tKoeqqrlwCf52YrfI8ABSfaqqg1V9bW+8TnAAVX1k6q6rqrWb817SxoOhjNJO5t/Av4HcCKbHNIE9gKmA9/rG/seMK97vA9w+ybbHvWMbt+13WHFe4G/A562lfXtA9xTVfdvpoY3Ab8E3NQdunxV3+e6HFiS5I4kH0oyfSvfW9IQMJxJ2qlU1ffoXRjwG8BFm2y+m94K1DP6xvbjZ6tra+kdNuzf9qjbgR8De1XVU7qf3arq4K0s8Q5gzyS7jlVDVd1SVYvphb6zgAuTzKqqR6rq/VV1EPAieodfj0fSlGM4k7QzehPw0qr6Uf9gVf2E3jlcZybZNckzgD/mZ+elXQC8Ncn8JHsAp/btuxb4EvCRJLsleUKSZyV5ydYUVlW3A9cAf9Gd5H9IV+9nAJL8TpKnVtVPgXu73X6aZFGS53aHZtfTC5k/3Zr3ljQcDGeSdjpV9Z2qWraZzX8I/Ai4Ffgq8M/Ap7ptf0/v0OF/ANfziytvxwNPBFYBPwQuBPbehhIXAwvoraJdDJxeVV/utr0CWJlkA72LA95QVQ8CT+/ebz29c+mupneoU9IUk6qa7BokSZLUceVMkiSpIYYzSZKkhhjOJEmSGjKwcJZk3yRXJVmVZGWSt40x5+gkK5Is725ncuQm23dLsibJ3wyqTkmSpJYM7IKAJHsDe1fV9d33/VwHHFNVq/rmzAZ+VFXVXW5+QVUd2Lf9Y8BT6X2h4x8MpFBJkqSG7DKoF+6+M2ht9/j+JKvpfUP2qr45G/p2mQU8lhSTvACYC3yR3j3wHtdee+1VCxYs2O7ap4of/ehHzJo1a7LLUB970ib70h570h57svWuu+66u6vqqZuODyyc9UuygN5NhK8dY9ur6d3f7mnAUd3YE+jdD+93gJeN930WLFjAsmWb++ojbWrp0qWMjo5OdhnqY0/aZF/aY0/aY0+2XpLvjTk+6O856w5dXg2cWVWbfuFj/7wXA++tqpcl+QPgyVX1oSQnAiObO6yZ5GTgZIC5c+e+YMmSJTv8MwyrDRs2MHv27MkuQ33sSZvsS3vsSXvsydZbtGjRdVX1C0cHBxrOupv2/gtweVWdPY75twKH0fvW7F+hd+uS2fS+sfvjVXXqFnZnZGSkXDkbP/+V0x570ib70h570h57svWSjBnOBnZYM0mA84DVmwtmSQ4AvtNdEPB8YAawrqre2DfnRHorZ1sMZpIkScNgkOecHQEcB9yQZHk3dhqwH0BVfQJ4DXB8kkeAB4Fjawcv5T3yyCOsWbOGhx56aEe+bJNmzpzJ/PnzmT59+mSXIkmSttEgr9b8KpDHmXMWcNbjzDkfOH9b61izZg277rorCxYsoLeYN5yqinXr1rFmzRr233//yS5HkiRto6G/Q8BDDz3EnDlzhjqYASRhzpw5U2KFUJKkYTb04QwY+mD2qKnyOSVJGmZTIpxNlnXr1nHooYdy6KGH8vSnP5158+Y99vzhhx/e4r7Lli3jrW996wRVKkmSWjEhX0I7Vc2ZM4fly5cD8L73vY/Zs2fzzne+87HtGzduZJddxm7ByMgIIyPjujGCJEkaIq6cTbATTzyRt7zlLbzwhS/kXe96F1//+tc5/PDDWbhwIS960Yv41re+BfS+L+ZVr3oV0At2J510EqOjozzzmc/knHPOmcyPIEmSBsiVs0mwZs0arrnmGqZNm8b69ev5yle+wi677MKXv/xlTjvtND7/+c//wj433XQTV111Fffffz/Pec5zOOWUU/zKDEmShtCUCmfv/8JKVt2xfoe+5kH77Mbpv3nwVu3zute9jmnTpgFw3333ccIJJ3DLLbeQhEceeWTMfY466ihmzJjBjBkzeNrTnsadd97J/Pnzt7t+SZLUFg9rToJZs2Y99vg973kPixYt4sYbb+QLX/jCZr8KY8aMGY89njZtGhs3bhx4nZIkaeJNqZWzrV3hmgj33Xcf8+bNA+D888+f3GIkSdKkc+Vskr3rXe/i3e9+NwsXLnQ1TJIkTa2Vs8n0vve9b8zxww8/nJtvvvmx52eccQYAo6OjjI6OjrnvjTfeOIgSJUlSA1w5kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhrMBW7RoEZdffvnPjX30ox/llFNOGXP+6Ogoy5Ytm4jSJElSgwxnA7Z48WKWLFnyc2NLlixh8eLFk1SRJElqmeFswF772tdy6aWX8vDDDwNw2223cccdd/C5z32OkZERDj74YE4//fRJrlKSJLXCcDZge+65J4cddhiXXXYZ0Fs1e/3rX8+ZZ57JsmXLWLFiBVdffTUrVqyY5EolSVILptbtmy47FX5ww459zac/F175l1uc8uihzaOPPpolS5Zw3nnnccEFF3DuueeyceNG1q5dy6pVqzjkkEN2bG2SJGmn48rZBDj66KO58soruf7663nggQfYc889+fCHP8yVV17JihUrOOqoo3jooYcmu0xJktSAqbVy9jgrXIMye/ZsFi1axEknncTixYtZv349s2bNYvfdd+fOO+/ksssue+wm55IkaWqbWuFsEi1evJhXv/rVLFmyhAMPPJCFCxdy4IEHsu+++3LEEUdMdnmSJKkRhrMJcswxx1BVjz0///zzx5y3dOnSiSlIkiQ1yXPOJEmSGmI4kyRJaojhTJIkqSFTIpz1n+s1zKbK55QkaZgNfTibOXMm69atG/rgUlWsW7eOmTNnTnYpkiRpOwz91Zrz589nzZo13HXXXZNdysDNnDmT+fPnT3YZkiRpOwx9OJs+fTr777//ZJchSZI0LkN/WFOSJGlnYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIQMLZ0n2TXJVklVJViZ52xhzjk6yIsnyJMuSHNmNH5rk37v9ViQ5dlB1SpIktWSXAb72RuAdVXV9kl2B65JcUVWr+uZcCVxSVZXkEOAC4EDgAeD4qrolyT7dvpdX1b0DrFeSJGnSDSycVdVaYG33+P4kq4F5wKq+ORv6dpkFVDd+c9+cO5L8F/BU4N5B1StJktSCCTnnLMkCYCFw7RjbXp3kJuBS4KQxth8GPBH4zoDLlCRJmnSpqsG+QTIbuBo4s6ou2sK8FwPvraqX9Y3tDSwFTqiqr21mv5OBkwHmzp37giVLluzA6ofbhg0bmD179mSXoT72pE32pT32pD32ZOstWrTouqoa2XR8oOEsyXTgX4DLq+rsccy/FTisqu5Oshu9YPbnVXXheN5vZGSkli1btj0lTylLly5ldHR0sstQH3vSJvvSHnvSHnuy9ZKMGc4GebVmgPOA1ZsLZkkO6OaR5PnADGBdkicCFwOfHm8wkyRJGgaDvFrzCOA44IYky7ux04D9AKrqE8BrgOOTPAI8CBzbXbn5euDFwJwkJ3b7nlhVy5EkSRpig7xa86tAHmfOWcBZY4x/BvjMgEqTJElqlncIkCRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGjKwcJZk3yRXJVmVZGWSt40x5+gkK5IsT7IsyZF9205Ickv3c8Kg6pQkSWrJLgN87Y3AO6rq+iS7AtcluaKqVvXNuRK4pKoqySHABcCBSfYETgdGgOr2vaSqfjjAeiVJkibdwFbOqmptVV3fPb4fWA3M22TOhqqq7uksekEM4NeBK6rqni6QXQG8YlC1SpIktWJCzjlLsgBYCFw7xrZXJ7kJuBQ4qRueB9zeN20NmwQ7SZKkYTTIw5oAJJkNfB54e1Wt33R7VV0MXJzkxcAHgZdt5eufDJwMMHfuXJYuXbrdNU8VGzZs8PfVGHvSJvvSHnvSHnuy4ww0nCWZTi+YfbaqLtrS3Kr6tyTPTLIX8H1gtG/zfGDpZvY7FzgXYGRkpEZHR8eapjEsXboUf19tsSdtsi/tsSftsSc7ziCv1gxwHrC6qs7ezJwDunkkeT4wA1gHXA68PMkeSfYAXt6NSZIkDbVBrpwdARwH3JBkeTd2GrAfQFV9AngNcHySR4AHgWO7CwTuSfJB4Bvdfh+oqnsGWKskSVITBhbOquqrQB5nzlnAWZvZ9ingUwMoTZIkqVneIUCSJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhowrnCWZleQJ3eNfSvJb3bf/S5IkaQca78rZvwEzk8wDvkTvy2XPH1RRkiRJU9V4w1mq6gHgt4GPV9XrgIMHV5YkSdLUNO5wluRw4I3Apd3YtMGUJEmSNHWNN5y9HXg3cHFVrUzyTOCqgVUlSZI0RY3r3ppVdTVwNUB3YcDdVfXWQRYmSZI0FY33as1/TrJbklnAjcCqJH8y2NIkSZKmnvEe1jyoqtYDxwCXAfvTu2JTkiRJO9B4w9n07nvNjgEuqapHgBpYVZIkSVPUeMPZ3wG3AbOAf0vyDGD9oIqSJEmaqsZ7QcA5wDl9Q99LsmgwJUmSJE1d470gYPckZydZ1v18hN4qmiRJknag8R7W/BRwP/D67mc98A+DKkqSJGmqGtdhTeBZVfWavufvT7J8APVIkiRNaeNdOXswyZGPPklyBPDgYEqSJEmausa7cvYW4NNJdu+e/xA4YTAlSZIkTV3jvVrzP4DnJdmte74+yduBFQOsTZIkacoZ72FNoBfKujsFAPzxAOqRJEma0rYqnG0iO6wKSZIkAdsXzrx9kyRJ0g62xXPOktzP2CEswJMGUpEkSdIUtsVwVlW7TlQhkiRJ2r7DmpIkSdrBDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1JCBhbMk+ya5KsmqJCuTvG2MOW9MsiLJDUmuSfK8vm1/1O13Y5LPJZk5qFolSZJaMciVs43AO6rqIOCXgd9PctAmc74LvKSqngt8EDgXIMk84K3ASFX9d2Aa8IYB1ipJktSEXQb1wlW1FljbPb4/yWpgHrCqb841fbt8DZi/SW1PSvII8GTgjkHVKkmS1IoJOecsyQJgIXDtFqa9CbgMoKq+D3wY+E96Ae++qvrSgMuUJEmadKmqwb5BMhu4Gjizqi7azJxFwMeBI6tqXZI9gM8DxwL3Av8HuLCqPjPGvicDJwPMnTv3BUuWLBnI5xhGGzZsYPbs2ZNdhvrYkzbZl/bYk/bYk623aNGi66pqZNPxgR3WBEgynV7I+uwWgtkhwCeBV1bVum74ZcB3q+qubs5FwIuAXwhnVXUu3blqIyMjNTo6uqM/xtBaunQp/r7aYk/aZF/aY0/aY092nEFerRngPGB1VZ29mTn7ARcBx1XVzX2b/hP45SRP7l7nV4HVg6pVkiSpFYNcOTsCOA64Icnybuw0YD+AqvoE8F5gDvDxXgZjY1WNVNW1SS4Erqd31ec36VbHJEmShtkgr9b8KpDHmfNm4M2b2XY6cPoASpMkSWqWdwiQJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaYjiTJElqiOFMkiSpIYYzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRJkhpiOJMkSWqI4UySJKkhhjNJkqSGGM4kSZIaMrBwlmTfJFclWZVkZZK3jTHnjUlWJLkhyTVJnte37SlJLkxyU5LVSQ4fVK2SJEmt2GWAr70ReEdVXZ9kV+C6JFdU1aq+Od8FXlJVP0zySuBc4IXdto8BX6yq1yZ5IvDkAdYqSZLUhIGFs6paC6ztHt+fZDUwD1jVN+eavl2+BswHSLI78GLgxG7ew8DDg6pVkiSpFRNyzlmSBcBC4NotTHsTcFn3eH/gLuAfknwzySeTzBpslZIkSZMvVTXYN0hmA1cDZ1bVRZuZswj4OHBkVa1LMkJvJe2Iqro2yceA9VX1njH2PRk4GWDu3LkvWLJkyaA+ytDZsGEDs2fPnuwy1MeetMm+tMeetMeebL1FixZdV1Ujm44PNJwlmQ78C3B5VZ29mTmHABcDr6yqm7uxpwNfq6oF3fNfAU6tqqO29H4jIyO1bNmyHfgJhtvSpUsZHR2d7DLUx560yb60x560x55svSRjhrNBXq0Z4Dxg9RaC2X7ARcBxjwYzgKr6AXB7kud0Q79K37lqkiRJw2qQV2seARwH3JBkeTd2GrAfQFV9AngvMAf4eC/LsbEvQf4h8NnuSs1bgd8dYK2SJElNGOTVml8F8jhz3gy8eTPblgO/sNQnSZI0zLxDgCRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkMMZ5IkSQ0xnEmSJDXEcCZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQwxnkiRJDTGcSZIkNcRwJkmS1BDDmSRJUkNSVZNdww6T5C7ge5Ndx05kL+DuyS5CP8eetMm+tMeetMeebL1nVNVTNx0cqnCmrZNkWVWNTHYd+hl70ib70h570h57suN4WFOSJKkhhjNJkqSGGM6mtnMnuwD9AnvSJvvSHnvSHnuyg3jOmSRJUkNcOZMkSWqI4WzIJdkzyRVJbun+3GMz807o5tyS5IQxtl+S5MbBVzz8tqcnSZ6c5NIkNyVZmeQvJ7b64ZLkFUm+leTbSU4dY/uMJP+7235tkgV9297djX8rya9PaOFDblv7kuTXklyX5Ibuz5dOePFDanv+rnTb90uyIck7J6zonZjhbPidClxZVc8Gruye/5wkewKnAy8EDgNO7w8MSX4b2DAx5U4J29uTD1fVgcBC4Igkr5yYsodLkmnA3wKvBA4CFic5aJNpbwJ+WFUHAH8FnNXtexDwBuBg4BXAx7vX03banr7Q+46t36yq5wInAP80MVUPt+3syaPOBi4bdK3DwnA2/I4G/rF7/I/AMWPM+XXgiqq6p6p+CFxB7z84JJkN/DFwxuBLnTK2uSdV9UBVXQVQVQ8D1wPzB1/yUDoM+HZV3dr9LpfQ602//l5dCPxqknTjS6rqx1X1XeDb3etp+21zX6rqm1V1Rze+EnhSkhkTUvVw256/KyQ5BvguvZ5oHAxnw29uVa3tHv8AmDvGnHnA7X3P13RjAB8EPgI8MLAKp57t7QkASZ4C/Ca91Tdtvcf9HffPqaqNwH3AnHHuq22zPX3p9xrg+qr68YDqnEq2uSfdP/D/FHj/BNQ5NHaZ7AK0/ZJ8GXj6GJv+rP9JVVWScV+em+RQ4FlV9Uebnj+gLRtUT/pefxfgc8A5VXXrtlUpDackB9M7rPbyya5FvA/4q6ra0C2kaRwMZ0Ogql62uW1J7kyyd1WtTbI38F9jTPs+MNr3fD6wFDgcGElyG73/rTwtydKqGkVbNMCePOpc4Jaq+uj2VztlfR/Yt+/5/G5srDlrukC8O7BunPtq22xPX0gyH7gYOL6qvjP4cqeE7enJC4HXJvkQ8BTgp0keqqq/GXjVOzEPaw6/S+idGEv35/8dY87lwMuT7NGddP5y4PKq+l9VtU9VLQCOBG42mO0Q29wTgCRn0Ps/vrcPvtSh9g3g2Un2T/JEeif4X7LJnP5evRb41+p9OeQlwBu6K9T2B54NfH2C6h5229yX7lD/pcCpVfX/JqrgKWCbe1JVv1JVC7r/jnwU+HOD2eMznA2/vwR+LcktwMu65yQZSfJJgKq6h965Zd/ofj7QjWkwtrkn3arAn9G7Yur6JMuTvHkyPsTOrjsv5g/ohd7VwAVVtTLJB5L8VjftPHrnzXyb3oUxp3b7rgQuAFYBXwR+v6p+MtGfYRhtT1+6/Q4A3tv93Vie5GkT/BGGznb2RNvAOwRIkiQ1xJUzSZKkhhjOJEmSGmI4kyRJaojhTJIkqSGGM0mSpIYYziRNCUl+0vf1CsuT7LBL/ZMsSHLjjno9SVObdwiQNFU8WFWHTnYRkvR4XDmTNKUluS3Jh5LckOTrSQ7oxhck+dckK5JcmWS/bnxukouT/Ef386LupaYl+fskK5N8KcmTJu1DSdqpGc4kTRVP2uSw5rF92+6rqucCf0PvFjMAfw38Y1UdAnwWOKcbPwe4uqqeBzwfWNmNPxv426o6GLgXeM1AP42koeUdAiRNCUk2VNXsMcZvA15aVbcmmQ78oKrmJLkb2LuqHunG11bVXknuAuZX1Y/7XmMBcEVVPbt7/qfA9Ko6YwI+mqQh48qZJEFt5vHW+HHf45/gOb2StpHhTJLg2L4//717fA3whu7xG4GvdI+vBE4BSDItye4TVaSkqcF/2UmaKp6UZHnf8y9W1aNfp7FHkhX0Vr8Wd2N/CPxDkj8B7gJ+txt/G3BukjfRWyE7BVg76OIlTR2ecyZpSuvOORupqrsnuxZJAg9rSpIkNcWVM0mSpIa4ciZJktQQw5kkSVJDDGeSJEkNMZxJkiQ1xHAmSZLUEMOZJElSQ/4/hG+6dmPmBQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 1 512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 2 32768       add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 2 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 7 186368      add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 7 2912        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 745472      add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 1 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           20490       global_average_pooling2d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,881,970\n",
      "Trainable params: 20,827,442\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x1730a79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:06:58,275 : WARNING : 6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x1730a79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 2.3201 - accuracy: 0.1381 WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x173277dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:07:03,784 : WARNING : 6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x173277dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 17s 6s/step - loss: 2.3181 - accuracy: 0.1321 - val_loss: 2.2589 - val_accuracy: 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:07:04,454 : INFO : History keys: dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:25:15,036 : INFO : Saved file: ../predictions/best/transfer.csv\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transfer_learning():\n",
    "    batch_size = 32\n",
    "    epochs = 5\n",
    "    train_idx = len(X_train_full) - int(len(X_train_full) * args.val_fraction)\n",
    "    val_idx = train_idx\n",
    "    \n",
    "#     train_idx = 50\n",
    "#     val_idx = len(X_train_full) - train_idx\n",
    "    \n",
    "    def preprocess_image(image):\n",
    "        resized_image = tf.image.resize(image, [224, 224])\n",
    "        rgb_image = tf.image.grayscale_to_rgb(resized_image)\n",
    "        final_image = keras.applications.xception.preprocess_input(rgb_image)\n",
    "        return final_image\n",
    "        \n",
    "    def preprocess(image, label):\n",
    "            return preprocess_image(image), label\n",
    "        \n",
    "    def dataset(x, preprocess_func=preprocess):\n",
    "        def debug_data(data):\n",
    "            for d in data:\n",
    "                print(d)\n",
    "                fig, ax = plt.subplots()\n",
    "                imgplot = ax.imshow(d[0][0])\n",
    "                break\n",
    "        data = tf.data.Dataset.from_tensor_slices(x).shuffle(len(X_train_full)).map(preprocess_func).batch(batch_size).prefetch(1)\n",
    "        return data\n",
    "    \n",
    "    def build_model():\n",
    "        base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "#         print(base_model.layers[5].weights)\n",
    "        avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        output = keras.layers.Dense(10, activation='softmax')(avg)\n",
    "        model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "        return base_model, model\n",
    "    \n",
    "    \n",
    "    def train(base_model, model, train_data, val_data, train_base=False, epochs=epochs, lr=0.2):\n",
    "#         print('Start')\n",
    "#         print(base_model.layers[5].weights)\n",
    "#         print(model.layers[5].weights)\n",
    "        for l in base_model.layers:\n",
    "            l.trainable = train_base\n",
    "        optimizer = keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        history = model.fit(train_data, epochs=epochs, validation_data=val_data)\n",
    "        plot_history(history)\n",
    "#         print('End')\n",
    "#         print(base_model.layers[5].weights)\n",
    "#         print(model.layers[5].weights)\n",
    "    \n",
    "    train_data = dataset((X_train_full[:train_idx], y_train_full[:train_idx]))\n",
    "    val_data = dataset((X_train_full[val_idx:], y_train_full[val_idx:]))\n",
    "    base_model, model = build_model()\n",
    "    train(base_model, model, train_data, val_data)\n",
    "    train(base_model, model, train_data, val_data, train_base=True, lr=0.005)\n",
    "    \n",
    "    test_data = dataset(X_test, preprocess_func=preprocess_image)\n",
    "    predictions = model.predict(test_data)\n",
    "    csv_predictions(predictions, 'transfer.csv')\n",
    "\n",
    "if args.run_transfer:\n",
    "    transfer_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# can't get around the shapes problem\n",
    "def transfer_learning_data_augmentation():\n",
    "    batch_size = 32\n",
    "    epochs = 5\n",
    "    train_idx = len(X_train_full) - int(len(X_train_full) * args.val_fraction)\n",
    "    val_idx = train_idx\n",
    "    \n",
    "    \n",
    "    def dataset(features_labels):\n",
    "        def debug_data(data):\n",
    "            for d in data:\n",
    "                print(d)\n",
    "                fig, ax = plt.subplots()\n",
    "                imgplot = ax.imshow(d[0][0])\n",
    "                break\n",
    "                \n",
    "        def data_augmentator():\n",
    "            datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=5,\n",
    "                zoom_range=0.05,\n",
    "                width_shift_range=0.05,\n",
    "                height_shift_range=0.05)\n",
    "            image_augmented_generator = datagen.flow(features_labels[0], features_labels[1], seed=args.seed)\n",
    "            return image_augmented_generator\n",
    "        def preprocess(image, label):\n",
    "            print(image.shape)\n",
    "            resized_image = tf.image.resize(image, [224, 224])\n",
    "            print(resized_image.shape)\n",
    "            rgb_image = tf.image.grayscale_to_rgb(resized_image)\n",
    "            final_image = keras.applications.xception.preprocess_input(rgb_image)\n",
    "            print(final_image.shape)\n",
    "            return final_image, label\n",
    "        \n",
    "        output_signature=(tf.TensorSpec(shape=(batch_size, 28, 28, 1), dtype=tf.float32), \n",
    "                          tf.TensorSpec(shape=(batch_size), dtype=tf.int32))\n",
    "        for d in tf.data.Dataset.from_generator(data_augmentator, output_signature=output_signature):\n",
    "            print(d[0].shape)\n",
    "            break\n",
    "        data = tf.data.Dataset.from_generator(data_augmentator, output_signature=output_signature).shuffle(len(features_labels[0])).map(preprocess).batch(batch_size).prefetch(1)\n",
    "#         print(data.next())\n",
    "#         for d in data.take(1):\n",
    "#             print(d[0].shape)\n",
    "#             break\n",
    "        return data\n",
    "    \n",
    "    def build_model():\n",
    "        base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "#         print(base_model.layers[5].weights)\n",
    "        avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        output = keras.layers.Dense(10, activation='softmax')(avg)\n",
    "        model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "        return base_model, model\n",
    "    \n",
    "    \n",
    "    def train(base_model, model, train_data, val_data, train_base=False, epochs=epochs, lr=0.2):\n",
    "\n",
    "        for l in base_model.layers:\n",
    "            l.trainable = train_base\n",
    "        optimizer = keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        history = model.fit(train_data, epochs=epochs, validation_data=val_data)\n",
    "        plot_history(history)\n",
    "    \n",
    "    train_data = dataset((X_train_full[:train_idx], y_train_full[:train_idx]))\n",
    "    val_data = dataset((X_train_full[val_idx:], y_train_full[val_idx:]))\n",
    "    base_model, model = build_model()\n",
    "    train(base_model, model, train_data, val_data)\n",
    "    train(base_model, model, train_data, val_data, train_base=True, lr=0.005)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'transfer.csv')\n",
    "\n",
    "if args.run_transfer:\n",
    "    transfer_learning_data_augmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-knowing",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_augmentator():\n",
    "        datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        #   shear_range=0.05,\n",
    "        #   channel_shift_range=0.05,\n",
    "            rotation_range=5,\n",
    "            zoom_range=0.05,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05)\n",
    "        return datagen\n",
    "\n",
    "def data_augmentation():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=args.val_fraction, \n",
    "                                                      random_state=args.seed)\n",
    "    datagen = data_augmentator()\n",
    "#     val_modified_batch = datagen.flow(X_val, y_val, seed=args.seed).next()\n",
    "#     draw_digit(val_modified_batch[0][0], val_modified_batch[1][0])\n",
    "    \n",
    "    train_generator = datagen.flow(X_train, y_train, seed=args.seed)\n",
    "    model, callbacks = baseline_model()\n",
    "    history = model.fit(train_generator, epochs=args.epochs, validation_data=(X_val, y_val), callbacks=callbacks)\n",
    "    plot_history(history)\n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'augment.csv')\n",
    "\n",
    "if args.run_augment:\n",
    "    data_augmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-cause",
   "metadata": {},
   "source": [
    "| Model | Params  | Test score  | CV mean score | Val loss |\n",
    "|---|---|---|---|---|\n",
    "| Augment run 1 | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1  | 0.99421 | 0.9936 | 0.0188|\n",
    "| Augment run 2 | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1  | 0.99453 | 0.9964 | 0.0135|\n",
    "| Augment run 3 | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1  | 0.99435 | 0.9948 | 0.0151|\n",
    "| Augment | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=5, zoom_range=0.05, width_shift_range=0.05, height_shift_range=0.05  | 0.99503 | 0.9950 | 0.0147 |\n",
    "| Augment | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=2, zoom_range=0.02, width_shift_range=0.02, height_shift_range=0.02  | 0.99392 | 0.9962 | 0.0160 |\n",
    "| Augment | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=7, zoom_range=0.07, width_shift_range=0.07, height_shift_range=0.07  | 0.99453 | 0.9950 | 0.0144 |\n",
    "| Augment | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=5, zoom_range=0.05, width_shift_range=0.05, height_shift_range=0.05  | 0.99503 | 0.9950 | 0.0147 |\n",
    "| Augment | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=5, zoom_range=0.05, width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05, channel_shift_range=0.05  | 0.99475 | 0.9950 | 0.0139 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-calvin",
   "metadata": {},
   "source": [
    "### Ensemble + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def ensemble(num_models=5):\n",
    "    models = []\n",
    "    for model_num in range(num_models):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=args.val_fraction, \n",
    "                                                  random_state=model_num)\n",
    "        datagen = data_augmentator()\n",
    "        datagen.fit(X_train, seed=model_num)\n",
    "        train_generator = datagen.flow(X_train, y_train, seed=args.seed)\n",
    "        model, callbacks = baseline_model()\n",
    "        history = model.fit(train_generator, epochs=args.epochs, validation_data=(X_val, y_val), callbacks=callbacks)\n",
    "        plot_history(history)\n",
    "        models.append(model)\n",
    "    \n",
    "    predictions_classes = []\n",
    "    for model in models:\n",
    "        predictions_cur = model.predict(X_test)\n",
    "        predictions_classes_cur = np.argmax(predictions_cur, axis=1)\n",
    "        predictions_classes.append(predictions_classes_cur)\n",
    "    \n",
    "    def bag_predictions(predictions_classes):\n",
    "        predictions_classes_bagged = []\n",
    "        predictions_classes_stacked = np.stack(predictions_classes, axis=-1)\n",
    "        for prediction_i in predictions_classes_stacked:\n",
    "            predictions_classes_bagged.append(Counter(prediction_i).most_common(1)[0][0])\n",
    "        return predictions_classes_bagged\n",
    "    \n",
    "    csv_predictions = csv_predictions_categorical(bag_predictions(predictions_classes), 'ensemble-augment.csv')\n",
    "\n",
    "if args.run_ensemble:\n",
    "    ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-prince",
   "metadata": {},
   "source": [
    "| Model | Params  | Test score  | CV mean score | Val loss |\n",
    "|---|---|---|---|---|\n",
    "| Augment ensemble 5 models | Baseline model, Dropout=0.4, Batch normalization, early_stopping='val_loss', rotation_range=5, zoom_range=0.05, width_shift_range=0.05, height_shift_range=0.05  | 0.99517 | - | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "warming-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]\n",
      "\n",
      "\n",
      " [[[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]\n",
      "\n",
      "  [[-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   ...\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]\n",
      "   [-1. -1. -1.]]]], shape=(32, 224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_test(image, label=None):\n",
    "        resized_image = tf.image.resize(image, [224, 224])\n",
    "        rgb_image = tf.image.grayscale_to_rgb(resized_image)\n",
    "        final_image = keras.applications.xception.preprocess_input(rgb_image)\n",
    "        return (final_image, label) if label else final_image\n",
    "    \n",
    "def preprocess_test1(X_test_row):\n",
    "    print(X_test_row)\n",
    "    return preprocess_test(X_test_row, None)[0].numpy()\n",
    "\n",
    "# # print(X_test[1])\n",
    "# np.apply_along_axis(preprocess_test1, 3, X_test)\n",
    "# X_test_preprocessed = \n",
    "# for image in X_test:\n",
    "#     print(preprocess_test(image, None)[0].numpy())\n",
    "#     X_test\n",
    "#     break\n",
    "\n",
    "testd = tf.data.Dataset.from_tensor_slices(X_test).shuffle(len(X_test)).map(preprocess_test).batch(32).prefetch(1)\n",
    "for d in testd:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bibliographic-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[None],\n",
       "        [None],\n",
       "        [None]],\n",
       "\n",
       "       [[None],\n",
       "        [None],\n",
       "        [None]]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[[1],[2], [3]], [[4], [5], [6]]])\n",
    "f = lambda x: print(x)\n",
    "np.vectorize(f)(t)\n",
    "# np.apply_along_axis(f, 1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "prostate-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
