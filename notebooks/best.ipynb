{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-sellers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.seed=101\n",
    "args.reproducibility = True\n",
    "\n",
    "args.run_baseline = True\n",
    "\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "args.predictions_folder = Path('../predictions/best')\n",
    "args.models_folder = Path('../models/best')\n",
    "\n",
    "args.model_name = 'best.hdf5'\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.models_folder.mkdir(parents=True, exist_ok=True) \n",
    "args.run_baseline = False\n",
    "args.run_transfer = False\n",
    "args.run_augment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def reproducibility():\n",
    "    if args.reproducibility:\n",
    "        tf.random.set_seed(args.seed)\n",
    "\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brave-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def draw_digit(pixels_2d, label=None, size_inches=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    if label is not None:\n",
    "        ax.set_title(label)\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    imgplot = ax.imshow(pixels_2d, cmap='gray')\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "draw_digit(pixels_2d, label, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fixed-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:46:10,377 : INFO : X.shape: (42000, 28, 28, 1)\n",
      "2021-05-11 10:46:10,378 : INFO : Y_train.shape: (42000, 10)\n",
      "2021-05-11 10:46:10,382 : INFO : Type of target Y_train: 'multilabel-indicator'\n",
      "2021-05-11 10:46:10,383 : INFO : y_train.shape: (42000,)\n",
      "2021-05-11 10:46:10,384 : INFO : Type of target y_train: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X_train = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "Y_train = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_train = args.labels.to_numpy()\n",
    "X_test = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)\n",
    "\n",
    "log.info('X.shape: %s', repr(X_train.shape))\n",
    "# log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('Y_train.shape: %s', repr(Y_train.shape))\n",
    "# log.info('y[0], %s', y[0])\n",
    "log.info('Type of target Y_train: %s', repr(sklearn.utils.multiclass.type_of_target(Y_train)))\n",
    "\n",
    "log.info('y_train.shape: %s', repr(y_train.shape))\n",
    "# log.info('y_sparse: %s', repr(y_sparse))\n",
    "# log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('Type of target y_train: %s', repr(sklearn.utils.multiclass.type_of_target(y_train)))\n",
    "\n",
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_classes = np.argmax(predictions, axis=1)\n",
    "    image_ids = np.arange(1, len(predictions_classes) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_classes})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-necklace",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wound-proceeding",
   "metadata": {},
   "source": [
    "def reprod():\n",
    "    reproducibility()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    monitor='val_accuracy'\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=monitor, patience=10, mode='auto', restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, min_delta=1e-4, mode='auto', verbose=1)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=args.val_fraction, epochs=1, batch_size=32,\n",
    "                        verbose=1, callbacks=[early_stopping, reduce_lr_on_plateau])\n",
    "    plot_history(history)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'baseline.csv')\n",
    "\n",
    "reprod()\n",
    "\n",
    "assert False\n",
    "# mac mini 1182/1182 [==============================] - 20s 16ms/step - loss: 0.5071 - accuracy: 0.8442 - val_loss: 0.0995 - val_accuracy: 0.9707\n",
    "# macbook 1182/1182 [==============================] - 62s 50ms/step - loss: 0.5066 - accuracy: 0.8437 - val_loss: 0.1070 - val_accuracy: 0.9662\n",
    "# macbook 29/29 [==============================] - 4s 64ms/step - loss: 2.2990 - accuracy: 0.3006 - val_loss: 3.0213 - val_accuracy: 0.5200\n",
    "\n",
    "# mini 1182/1182 [==============================] - 31s 25ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# macbook 1182/1182 [==============================] - 74s 60ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729\n",
    "# mini 1182/1182 [==============================] - 34s 28ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# mini 1182/1182 [==============================] - 31s 25ms/step - loss: 0.5001 - accuracy: 0.8464 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
    "# macbook 1182/1182 [==============================] - 73s 60ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729\n",
    "# macbook 1182/1182 [==============================] - 74s 61ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.0940 - val_accuracy: 0.9729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tribal-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# 1-cycle lr\n",
    "# data augmentation\n",
    "# ensemble\n",
    "def baseline():\n",
    "    reproducibility()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    monitor='val_accuracy'\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=monitor, patience=10, mode='auto', restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, min_delta=1e-4, mode='auto', verbose=1)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=args.val_fraction, epochs=args.epochs, batch_size=32,\n",
    "                        verbose=1, callbacks=[early_stopping, reduce_lr_on_plateau])\n",
    "    plot_history(history)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    csv_predictions(predictions, 'baseline.csv')\n",
    "\n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-place",
   "metadata": {},
   "source": [
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | No dropout | 0.99017 | 0.9924 |\n",
    "| Baseline | Dropout=0.4 | 0.99200 | 0.9931 |\n",
    "| Baseline | Dropout=0.4, Batch normalization  | 0.99278 |  0.9943 |\n",
    "\n",
    "\n",
    "##### Other results\n",
    "| Model | Params  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | Dropout=0.25 (after 2 first conv) | 0.99150 | 0.9929 |\n",
    "| Baseline | Dropout=0.5 (after 2 first conv) | 0.99178 | 0.9924 |\n",
    "| Baseline | Dropout=0.5  | 0.98867 | 0.9912 |\n",
    "| Baseline | Dropout=0.3  | 0.99182 |  0.9936 |\n",
    "| Baseline | Dropout=0.4 batch normalization before activation  | 0.99275 |  0.9929 |\n",
    "| Baseline | Dropout=0.4 batch normalization he normal | 0.99250 |  0.9940 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-texture",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endless-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transfer_learning():\n",
    "    batch_size = 32\n",
    "    train_idx = len(X_train) - int(len(X_train) * args.val_fraction)\n",
    "    val_idx = train_idx\n",
    "#     train_idx = 50\n",
    "#     val_idx = len(X_train) - train_idx \n",
    "    def preprocess(image, label):\n",
    "        resized_image = tf.image.resize(image, [224, 224])\n",
    "        rgb_image = tf.image.grayscale_to_rgb(resized_image)\n",
    "        final_image = keras.applications.xception.preprocess_input(rgb_image)\n",
    "        return final_image, label\n",
    "    \n",
    "    def dataset(features_labels):\n",
    "        def debug_data(data):\n",
    "            for d in data:\n",
    "                print(d)\n",
    "                fig, ax = plt.subplots()\n",
    "                imgplot = ax.imshow(d[0][0])\n",
    "                break\n",
    "        data = tf.data.Dataset.from_tensor_slices(features_labels).shuffle(len(X_train)).map(preprocess).batch(batch_size).prefetch(1)\n",
    "        return data\n",
    "    \n",
    "    def build_model():\n",
    "        base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "        avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        output = keras.layers.Dense(10, activation='softmax')(avg)\n",
    "        model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "        return base_model, model\n",
    "    \n",
    "    \n",
    "    def train(base_model, model, train_data, val_data, train_base=False, epochs=5, lr=0.2):\n",
    "        for l in base_model.layers:\n",
    "            l.tranable = False\n",
    "        optimizer = keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        history = model.fit(train_data, epochs=epochs, validation_data=val_data)\n",
    "        plot_history(history)\n",
    "    \n",
    "    train_data = dataset((X_train[:train_idx], y_train[:train_idx]))\n",
    "    val_data = dataset((X_train[val_idx:], y_train[val_idx:]))\n",
    "    base_model, model = build_model()\n",
    "    train(base_model, model, train_data, val_data)\n",
    "    train(base_model, model, train_data, val_data, train_base=True, lr=0.01)\n",
    "\n",
    "if args.run_transfer:\n",
    "    transfer_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-entertainment",
   "metadata": {},
   "source": [
    "### 1-cycle learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-knowing",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "tamil-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\n",
      "[254]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_augmentation():\n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    datagen.fit(X_train)\n",
    "    for x in X_train:\n",
    "        print(x[12][12])\n",
    "        augm_x = datagen.apply_transform(x, {'flip_horizontal': True})\n",
    "        draw_digit(x)\n",
    "        draw_digit(augm_x)\n",
    "        print(augm_x[12][12])\n",
    "        break\n",
    "    \n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=60)\n",
    "    \n",
    "#     for d in train_generator:\n",
    "#         print(d[0].shape)\n",
    "#         print(d[0][0])\n",
    "#         break\n",
    "\n",
    "if args.run_augment:\n",
    "    data_augmentation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
