{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo stop the numbers to vary from time to time\n",
    "# Todo add K-fold\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo implement augmentation\n",
    "# Todo try to get a pretrained cnn\n",
    "# Todo early stop\n",
    "# Todo print the numbers in square like in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "\n",
    "args.n_splits = 10\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.model_name = 'deep-learning-keras-model.hdf5'\n",
    "args.seed=1337\n",
    "\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "\n",
    "args.run_baseline = True\n",
    "args.run_early_stop = True\n",
    "args.run_grid_search = True\n",
    "args.run_kfold_validation = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(label, pixels_2d, size_inches=None):\n",
    "    title = args.raw_train.iloc[random_row, 0]\n",
    "    fig, ax = plt.subplots()\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    ax.set_title(label)\n",
    "    imgplot = ax.imshow(pixels_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 12:04:17,631 : INFO : X.shape: (42000, 28, 28, 1)\n",
      "2020-06-30 12:04:17,632 : INFO : X[0][14][14]: [254]\n",
      "2020-06-30 12:04:17,633 : INFO : y.shape: (42000, 10)\n",
      "2020-06-30 12:04:17,633 : INFO : y[0], [0 1 0 0 0 0 0 0 0 0]\n",
      "2020-06-30 12:04:17,641 : INFO : type of target y: 'multilabel-indicator'\n",
      "2020-06-30 12:04:17,641 : INFO : y_sparse.shape: (42000,)\n",
      "2020-06-30 12:04:17,642 : INFO : y_sparse: array([1, 0, 1, ..., 7, 6, 9])\n",
      "2020-06-30 12:04:17,643 : INFO : y_sparse[0]: 1\n",
      "2020-06-30 12:04:17,645 : INFO : type of target y_sparse: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_sparse = args.labels.to_numpy()\n",
    "x = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)\n",
    "\n",
    "log.info('X.shape: %s', repr(X.shape))\n",
    "log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('y.shape: %s', repr(y.shape))\n",
    "log.info('y[0], %s', y[0])\n",
    "log.info('type of target y: %s', repr(sklearn.utils.multiclass.type_of_target(y)))\n",
    "\n",
    "log.info('y_sparse.shape: %s', repr(y_sparse.shape))\n",
    "log.info('y_sparse: %s', repr(y_sparse))\n",
    "log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('type of target y_sparse: %s', repr(sklearn.utils.multiclass.type_of_target(y_sparse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated?\n",
    "def predict(X, y, x, build_classifier, parameters, splits=args.n_splits, n_jobs=args.n_jobs):\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    classifier = build_classifier()\n",
    "    gcv = GridSearchCV(classifier, parameters, n_jobs=n_jobs, cv=skf, verbose=5)\n",
    "    gcv.fit(X, y)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    classifier = build_classifier(gcv.best_params_)\n",
    "    classifier.fit(X, y)\n",
    "    predictions = classifier.predict(x)\n",
    "    return gcv.best_params_, gcv.best_score_, predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_sparse_predictions(predictions_sparse, filename):\n",
    "    image_ids = np.arange(1, len(predictions_sparse) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_sparse})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_sparse = np.argmax(predictions, axis=1)\n",
    "    csv_sparse_predictions(predictions_sparse, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cross_val_score_sklearn(sklearn_model, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params=None):\n",
    "    cvs = cross_val_score(sklearn_model, X, y, cv=n_splits, n_jobs=args.n_jobs, fit_params=fit_params)\n",
    "    log.info('CV mean accuracy: %0.4f. std: %0.4f', cvs.mean(), cvs.std())\n",
    "    return cvs\n",
    "    \n",
    "def cross_val_score_keras(keras_model_builder, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params={'epochs': args.epochs}):\n",
    "    keras_classifier = KerasClassifier(keras_model_builder)\n",
    "    return cross_val_score_sklearn(keras_classifier, X, y, scoring=scoring, n_splits=n_splits, fit_params=fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "def build_model(layers_list, optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy', metrics_tuple=('accuracy')):\n",
    "    model = models.Sequential(layers_list)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics_tuple])\n",
    "    log.info(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "\n",
    "def build_baseline_model_sparse():\n",
    "    layers_list = [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "    return build_model(layers_list=layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 12:04:19,682 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 11s 280us/step - loss: 0.5393 - accuracy: 0.9128 - val_loss: 0.0735 - val_accuracy: 0.9776\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0790 - accuracy: 0.9777 - val_loss: 0.0591 - val_accuracy: 0.9840\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0532 - accuracy: 0.9850 - val_loss: 0.0617 - val_accuracy: 0.9838\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.0481 - val_accuracy: 0.9857\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 10s 274us/step - loss: 0.0355 - accuracy: 0.9910 - val_loss: 0.0912 - val_accuracy: 0.9779\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9867\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 10s 258us/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.0493 - val_accuracy: 0.9871\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.1012 - val_accuracy: 0.9838\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0231 - accuracy: 0.9947 - val_loss: 0.0721 - val_accuracy: 0.9867\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 9s 229us/step - loss: 0.0234 - accuracy: 0.9951 - val_loss: 0.1565 - val_accuracy: 0.9848\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 9s 233us/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 0.0836 - val_accuracy: 0.9869\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 0.1078 - val_accuracy: 0.9836\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0231 - accuracy: 0.9953 - val_loss: 0.0842 - val_accuracy: 0.9890\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0261 - accuracy: 0.9955 - val_loss: 0.1172 - val_accuracy: 0.9812\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 10s 265us/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.0836 - val_accuracy: 0.9893\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.1955 - val_accuracy: 0.9852\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0193 - accuracy: 0.9966 - val_loss: 0.1661 - val_accuracy: 0.9871\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0253 - accuracy: 0.9963 - val_loss: 0.1262 - val_accuracy: 0.9898\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0244 - accuracy: 0.9964 - val_loss: 0.2161 - val_accuracy: 0.9824\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.1628 - val_accuracy: 0.9886\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.1798 - val_accuracy: 0.9871\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 9s 235us/step - loss: 0.0210 - accuracy: 0.9973 - val_loss: 0.1887 - val_accuracy: 0.9874\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.1561 - val_accuracy: 0.9871\n",
      "Epoch 24/50\n",
      "37800/37800 [==============================] - 9s 251us/step - loss: 0.0237 - accuracy: 0.9968 - val_loss: 0.1840 - val_accuracy: 0.9850\n",
      "Epoch 25/50\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.1838 - val_accuracy: 0.9883\n",
      "Epoch 26/50\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0233 - accuracy: 0.9973 - val_loss: 0.2917 - val_accuracy: 0.9852\n",
      "Epoch 27/50\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0243 - accuracy: 0.9975 - val_loss: 0.4307 - val_accuracy: 0.9838\n",
      "Epoch 28/50\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.1652 - val_accuracy: 0.9898\n",
      "Epoch 29/50\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0248 - accuracy: 0.9975 - val_loss: 0.2276 - val_accuracy: 0.9888\n",
      "Epoch 30/50\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0202 - accuracy: 0.9979 - val_loss: 0.2476 - val_accuracy: 0.9893\n",
      "Epoch 31/50\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0236 - accuracy: 0.9975 - val_loss: 0.2084 - val_accuracy: 0.9876\n",
      "Epoch 32/50\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0191 - accuracy: 0.9980 - val_loss: 0.2304 - val_accuracy: 0.9871\n",
      "Epoch 33/50\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.2821 - val_accuracy: 0.9852\n",
      "Epoch 34/50\n",
      "37800/37800 [==============================] - 10s 261us/step - loss: 0.0266 - accuracy: 0.9976 - val_loss: 0.2515 - val_accuracy: 0.9883\n",
      "Epoch 35/50\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0262 - accuracy: 0.9979 - val_loss: 0.1961 - val_accuracy: 0.9898\n",
      "Epoch 36/50\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0239 - accuracy: 0.9978 - val_loss: 0.2465 - val_accuracy: 0.9898\n",
      "Epoch 37/50\n",
      "37800/37800 [==============================] - 9s 251us/step - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.3066 - val_accuracy: 0.9898\n",
      "Epoch 38/50\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.2728 - val_accuracy: 0.9898\n",
      "Epoch 39/50\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0235 - accuracy: 0.9980 - val_loss: 0.2933 - val_accuracy: 0.9893\n",
      "Epoch 40/50\n",
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0184 - accuracy: 0.9983 - val_loss: 0.2900 - val_accuracy: 0.9860\n",
      "Epoch 41/50\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0281 - accuracy: 0.9981 - val_loss: 0.3804 - val_accuracy: 0.9886\n",
      "Epoch 42/50\n",
      "37800/37800 [==============================] - 10s 261us/step - loss: 0.0163 - accuracy: 0.9985 - val_loss: 0.4761 - val_accuracy: 0.9883\n",
      "Epoch 43/50\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 0.0260 - accuracy: 0.9982 - val_loss: 0.3579 - val_accuracy: 0.9876\n",
      "Epoch 44/50\n",
      "37800/37800 [==============================] - 10s 265us/step - loss: 0.0236 - accuracy: 0.9984 - val_loss: 0.4070 - val_accuracy: 0.9895\n",
      "Epoch 45/50\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0252 - accuracy: 0.9983 - val_loss: 0.2835 - val_accuracy: 0.9898\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0229 - accuracy: 0.9983 - val_loss: 0.3584 - val_accuracy: 0.9881\n",
      "Epoch 47/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0211 - accuracy: 0.9984 - val_loss: 0.2907 - val_accuracy: 0.9879\n",
      "Epoch 48/50\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0254 - accuracy: 0.9984 - val_loss: 0.3840 - val_accuracy: 0.9876\n",
      "Epoch 49/50\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0250 - accuracy: 0.9986 - val_loss: 0.4957 - val_accuracy: 0.9888\n",
      "Epoch 50/50\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0302 - accuracy: 0.9984 - val_loss: 0.3583 - val_accuracy: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 12:12:16,512 : INFO : History keys: dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 12:12:18,057 : INFO : Saved file: ../predictions/cnn_baseline_predictions.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-dbff8cd081f1>\u001b[0m in \u001b[0;36mcross_val_score_keras\u001b[0;34m(keras_model_builder, X, y, scoring, n_splits, fit_params)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_val_score_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mkeras_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_val_score_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-dbff8cd081f1>\u001b[0m in \u001b[0;36mcross_val_score_sklearn\u001b[0;34m(sklearn_model, X, y, scoring, n_splits, fit_params)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_val_score_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV mean accuracy: %0.4f. std: %0.4f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 235\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def baseline():\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1)\n",
    "    plot_history(history)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_baseline_predictions.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse)\n",
    "    \n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def early_stop(monitor='val_loss'):\n",
    "    # val_loss\n",
    "    # val_accuracy\n",
    "    early_stopping = EarlyStopping(monitor=monitor, patience=10, mode='auto', verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor=monitor, mode='auto', verbose=1)\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='auto')\n",
    "\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])\n",
    "\n",
    "    plot_history(history)\n",
    "    model.load_weights(args.model_name)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_early_stop_predictions.csv')\n",
    "    \n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse, fit_params={'validation_split': args.val_fraction, 'epochs': args.epochs, 'batch_size': 64, 'callbacks': [early_stopping, model_checkpoint, reduce_lr_on_plateau]})\n",
    "\n",
    "if args.run_early_stop:\n",
    "    early_stop(monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic grid search to choose the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 10.6min remaining: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 17.8min finished\n",
      "2020-06-30 12:33:57,812 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "42000/42000 [==============================] - 14s 325us/step - loss: 0.3435 - accuracy: 0.9349\n",
      "Epoch 2/15\n",
      "42000/42000 [==============================] - 14s 324us/step - loss: 0.0845 - accuracy: 0.9767\n",
      "Epoch 3/15\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0629 - accuracy: 0.9838\n",
      "Epoch 4/15\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 0.0611 - accuracy: 0.9850\n",
      "Epoch 5/15\n",
      "42000/42000 [==============================] - 14s 327us/step - loss: 0.0584 - accuracy: 0.9867\n",
      "Epoch 6/15\n",
      "42000/42000 [==============================] - 13s 321us/step - loss: 0.0663 - accuracy: 0.9866\n",
      "Epoch 7/15\n",
      "42000/42000 [==============================] - 14s 332us/step - loss: 0.0593 - accuracy: 0.9874\n",
      "Epoch 8/15\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0688 - accuracy: 0.9869\n",
      "Epoch 9/15\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0655 - accuracy: 0.9868\n",
      "Epoch 10/15\n",
      "42000/42000 [==============================] - 13s 310us/step - loss: 0.0711 - accuracy: 0.9870\n",
      "Epoch 11/15\n",
      "42000/42000 [==============================] - 13s 310us/step - loss: 0.0748 - accuracy: 0.9873\n",
      "Epoch 12/15\n",
      "42000/42000 [==============================] - 12s 294us/step - loss: 0.0902 - accuracy: 0.9868\n",
      "Epoch 13/15\n",
      "42000/42000 [==============================] - 12s 295us/step - loss: 0.0853 - accuracy: 0.9875\n",
      "Epoch 14/15\n",
      "42000/42000 [==============================] - 13s 301us/step - loss: 0.0827 - accuracy: 0.9866\n",
      "Epoch 15/15\n",
      "42000/42000 [==============================] - 13s 311us/step - loss: 0.0928 - accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 12:37:18,955 : INFO : Best params: {'epochs': 15, 'layers_candidates_key': 1}\n",
      "2020-06-30 12:37:18,957 : INFO : Best CV score: 0.9817619047619047\n",
      "2020-06-30 12:37:18,957 : INFO : Best std: 0.006317560021547117\n",
      "2020-06-30 12:37:20,627 : INFO : Saved file: ../predictions/cnn_basic_grid_search.csv\n",
      "2020-06-30 12:37:20,661 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.0585 - accuracy: 0.9903 - val_loss: 0.0528 - val_accuracy: 0.9929\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.0522 - accuracy: 0.9908 - val_loss: 0.1288 - val_accuracy: 0.9824\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0571 - accuracy: 0.9907 - val_loss: 0.0876 - val_accuracy: 0.9921\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 10s 269us/step - loss: 0.0517 - accuracy: 0.9917 - val_loss: 0.0643 - val_accuracy: 0.9879\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 0.0494 - accuracy: 0.9924 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0599 - accuracy: 0.9911 - val_loss: 0.0599 - val_accuracy: 0.9926\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0447 - accuracy: 0.9931 - val_loss: 0.2310 - val_accuracy: 0.9831\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0476 - accuracy: 0.9928 - val_loss: 0.1895 - val_accuracy: 0.9867\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0502 - accuracy: 0.9930 - val_loss: 0.1362 - val_accuracy: 0.9819\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0566 - accuracy: 0.9928 - val_loss: 0.2081 - val_accuracy: 0.9852\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 226us/step - loss: 0.0486 - accuracy: 0.9940 - val_loss: 0.0631 - val_accuracy: 0.9914\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 9s 227us/step - loss: 0.0551 - accuracy: 0.9928 - val_loss: 0.0877 - val_accuracy: 0.9931\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 8s 222us/step - loss: 0.0464 - accuracy: 0.9934 - val_loss: 0.1168 - val_accuracy: 0.9871\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 8s 224us/step - loss: 0.0449 - accuracy: 0.9938 - val_loss: 0.1307 - val_accuracy: 0.9848\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 226us/step - loss: 0.0451 - accuracy: 0.9937 - val_loss: 0.0752 - val_accuracy: 0.9926\n",
      "{'val_loss': [0.05280252194974394, 0.12884081301960534, 0.08761186395129505, 0.06432523344942767, 0.08023058895199071, 0.059899576534582936, 0.23101790450437237, 0.18947754393169383, 0.13617331436840774, 0.20807692845752207, 0.06308492760528767, 0.08773061795946699, 0.11677699517207471, 0.13068896498494897, 0.07517511431199092], 'val_accuracy': [0.9928571581840515, 0.9823809266090393, 0.9921428561210632, 0.9878571629524231, 0.9814285635948181, 0.9926190376281738, 0.9830952286720276, 0.9866666793823242, 0.9819047451019287, 0.9852380752563477, 0.991428554058075, 0.9930952191352844, 0.9871428608894348, 0.9847618937492371, 0.9926190376281738], 'loss': [0.058526474870799663, 0.05220495660882854, 0.05709646756177223, 0.05166887772057856, 0.04942976096160983, 0.059914474330611645, 0.04473778120511146, 0.04760927165953121, 0.050230172150399356, 0.05663984240821972, 0.04858692775792145, 0.05508816830990821, 0.04638268603750199, 0.04489351995681747, 0.04510078759651408], 'accuracy': [0.990291, 0.99079365, 0.9907143, 0.99169314, 0.992381, 0.99113756, 0.99306875, 0.9928042, 0.99304235, 0.99277776, 0.9939947, 0.99277776, 0.9933598, 0.9937566, 0.99367726]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 9s 235us/step - loss: 0.0673 - accuracy: 0.9931 - val_loss: 0.0227 - val_accuracy: 0.9964\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 237us/step - loss: 0.0493 - accuracy: 0.9937 - val_loss: 0.0743 - val_accuracy: 0.9936\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0564 - accuracy: 0.9938 - val_loss: 0.1085 - val_accuracy: 0.9919\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 241us/step - loss: 0.0527 - accuracy: 0.9952 - val_loss: 0.1317 - val_accuracy: 0.9924\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0599 - accuracy: 0.9949 - val_loss: 0.0711 - val_accuracy: 0.9886\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0499 - accuracy: 0.9942 - val_loss: 0.0981 - val_accuracy: 0.9943\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0512 - accuracy: 0.9945 - val_loss: 0.0530 - val_accuracy: 0.9943\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 243us/step - loss: 0.0466 - accuracy: 0.9951 - val_loss: 0.0819 - val_accuracy: 0.9917\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0464 - accuracy: 0.9949 - val_loss: 0.0429 - val_accuracy: 0.9921\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 228us/step - loss: 0.0399 - accuracy: 0.9954 - val_loss: 0.0484 - val_accuracy: 0.9924\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.0452 - accuracy: 0.9964 - val_loss: 0.0689 - val_accuracy: 0.9926\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0407 - accuracy: 0.9961 - val_loss: 0.1668 - val_accuracy: 0.9919\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0431 - accuracy: 0.9957 - val_loss: 0.0641 - val_accuracy: 0.9914\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 9s 241us/step - loss: 0.0392 - accuracy: 0.9964 - val_loss: 0.0623 - val_accuracy: 0.9957\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 240us/step - loss: 0.0349 - accuracy: 0.9962 - val_loss: 0.0677 - val_accuracy: 0.9936\n",
      "{'val_loss': [0.022669813217166775, 0.07432059660180074, 0.10850877447890679, 0.13173285020335831, 0.0711065862292006, 0.09808920858056173, 0.05303809166014072, 0.08189812469067108, 0.0428586010089123, 0.04836402276774327, 0.06893648092506613, 0.16678644962609201, 0.06414438510748767, 0.062299234777793824, 0.06766880904711407], 'val_accuracy': [0.9964285492897034, 0.993571400642395, 0.9919047355651855, 0.9923809766769409, 0.9885714054107666, 0.9942857027053833, 0.9942857027053833, 0.9916666746139526, 0.9921428561210632, 0.9923809766769409, 0.9926190376281738, 0.9919047355651855, 0.991428554058075, 0.9957143068313599, 0.993571400642395], 'loss': [0.06728650105321791, 0.049312416982024064, 0.0564143841871718, 0.052727546039068464, 0.05993345799865669, 0.04991593096733995, 0.051183244143978464, 0.0466497162413992, 0.046436029522668336, 0.03987436609400408, 0.04523752541433128, 0.04067147078765358, 0.04306998362421884, 0.039215472839490735, 0.03487494677220953], 'accuracy': [0.99306875, 0.9937302, 0.9938095, 0.99515873, 0.99486774, 0.99420637, 0.99449736, 0.99505293, 0.9948942, 0.99539685, 0.99642855, 0.9960582, 0.9957407, 0.99640214, 0.9961905]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0468 - accuracy: 0.9959 - val_loss: 0.0192 - val_accuracy: 0.9971\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0395 - accuracy: 0.9966 - val_loss: 0.0259 - val_accuracy: 0.9974\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 9s 238us/step - loss: 0.0399 - accuracy: 0.9957 - val_loss: 0.0351 - val_accuracy: 0.9962\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0440 - accuracy: 0.9962 - val_loss: 0.0552 - val_accuracy: 0.9945\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 9s 236us/step - loss: 0.0455 - accuracy: 0.9963 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 234us/step - loss: 0.0279 - accuracy: 0.9972 - val_loss: 0.0485 - val_accuracy: 0.9943\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 231us/step - loss: 0.0399 - accuracy: 0.9963 - val_loss: 0.0727 - val_accuracy: 0.9962\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0439 - accuracy: 0.9965 - val_loss: 0.1418 - val_accuracy: 0.9950\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0356 - accuracy: 0.9967 - val_loss: 0.0629 - val_accuracy: 0.9938\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 235us/step - loss: 0.0480 - accuracy: 0.9968 - val_loss: 0.1025 - val_accuracy: 0.9933\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0388 - accuracy: 0.9972 - val_loss: 0.0321 - val_accuracy: 0.9976\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 11s 287us/step - loss: 0.0276 - accuracy: 0.9969 - val_loss: 0.1216 - val_accuracy: 0.9948\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 9s 251us/step - loss: 0.0405 - accuracy: 0.9972 - val_loss: 0.0531 - val_accuracy: 0.9974\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0439 - accuracy: 0.9972 - val_loss: 0.0815 - val_accuracy: 0.9938\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0295 - accuracy: 0.9978 - val_loss: 0.1067 - val_accuracy: 0.9945\n",
      "{'val_loss': [0.019210594216367907, 0.025931274223874673, 0.03509524673791818, 0.055150046820671074, 0.06975532612393563, 0.04847769303468784, 0.07269002528502301, 0.14177308406913755, 0.06293062923531967, 0.10253448897563948, 0.03214101399543476, 0.12156215880245609, 0.05309754387780354, 0.08146147322675304, 0.10667471453035622], 'val_accuracy': [0.9971428513526917, 0.9973809719085693, 0.9961904883384705, 0.994523823261261, 0.9900000095367432, 0.9942857027053833, 0.9961904883384705, 0.9950000047683716, 0.9938095211982727, 0.9933333396911621, 0.9976190328598022, 0.9947618842124939, 0.9973809719085693, 0.9938095211982727, 0.994523823261261], 'loss': [0.04681804471673651, 0.03945259022991998, 0.03991645279500117, 0.04396625318231904, 0.04548959766938151, 0.027885752561055032, 0.039913374708154634, 0.04393117198396703, 0.035601837761278905, 0.04800129861879223, 0.038773891949391535, 0.027559451535678833, 0.04047966853803371, 0.043861083171401034, 0.02950216209378067], 'accuracy': [0.99587303, 0.9966402, 0.9956614, 0.9961905, 0.9962963, 0.99724865, 0.9963492, 0.996455, 0.9967196, 0.99677247, 0.99722224, 0.9969048, 0.99722224, 0.99724865, 0.99777776]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0423 - accuracy: 0.9973 - val_loss: 0.0267 - val_accuracy: 0.9981\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0383 - accuracy: 0.9974 - val_loss: 0.0392 - val_accuracy: 0.9974\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 9s 240us/step - loss: 0.0296 - accuracy: 0.9977 - val_loss: 0.0290 - val_accuracy: 0.9990\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0429 - accuracy: 0.9980 - val_loss: 0.1349 - val_accuracy: 0.9955\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 11s 292us/step - loss: 0.0416 - accuracy: 0.9978 - val_loss: 0.0939 - val_accuracy: 0.9940\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.0358 - accuracy: 0.9976 - val_loss: 0.1000 - val_accuracy: 0.9964\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.0313 - accuracy: 0.9979 - val_loss: 0.0651 - val_accuracy: 0.9971\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0306 - accuracy: 0.9979 - val_loss: 0.2054 - val_accuracy: 0.9964\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0540 - accuracy: 0.9975 - val_loss: 0.0913 - val_accuracy: 0.9952\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0421 - accuracy: 0.9978 - val_loss: 0.0691 - val_accuracy: 0.9981\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 229us/step - loss: 0.0477 - accuracy: 0.9974 - val_loss: 0.0413 - val_accuracy: 0.9971\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0457 - accuracy: 0.9973 - val_loss: 0.2306 - val_accuracy: 0.9962\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 11s 287us/step - loss: 0.0473 - accuracy: 0.9983 - val_loss: 0.0665 - val_accuracy: 0.9971\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0478 - accuracy: 0.9977 - val_loss: 0.1462 - val_accuracy: 0.9974\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 238us/step - loss: 0.0449 - accuracy: 0.9976 - val_loss: 0.1691 - val_accuracy: 0.9962\n",
      "{'val_loss': [0.02673773934799856, 0.03919420690903969, 0.029019140399615707, 0.13492536679046468, 0.09391946822451167, 0.09997525721465861, 0.06511169608258158, 0.20543354160192762, 0.09125585350146316, 0.0691371167750613, 0.041307194932498556, 0.23061818256069072, 0.06650431572540383, 0.1461568171530165, 0.16905750083226037], 'val_accuracy': [0.9980952143669128, 0.9973809719085693, 0.9990476369857788, 0.9954761862754822, 0.9940476417541504, 0.9964285492897034, 0.9971428513526917, 0.9964285492897034, 0.9952380657196045, 0.9980952143669128, 0.9971428513526917, 0.9961904883384705, 0.9971428513526917, 0.9973809719085693, 0.9961904883384705], 'loss': [0.042303326897518576, 0.03827551512932907, 0.029625083781705027, 0.042915118567840554, 0.04156751408891129, 0.035825147590255034, 0.03132937022111844, 0.030574068010944977, 0.05404082965050801, 0.04205800643324187, 0.0476721377397556, 0.04572010428948985, 0.047344378111415474, 0.0477757091416696, 0.044895879669383014], 'accuracy': [0.9972751, 0.99740744, 0.99767196, 0.9980159, 0.9978307, 0.9976455, 0.9979101, 0.9979365, 0.9974603, 0.9977513, 0.997381, 0.99732804, 0.99825394, 0.9977249, 0.9976455]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0667 - accuracy: 0.9972 - val_loss: 0.0231 - val_accuracy: 0.9988\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 240us/step - loss: 0.0480 - accuracy: 0.9980 - val_loss: 0.0378 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0402 - accuracy: 0.9977 - val_loss: 0.0591 - val_accuracy: 0.9976\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 12s 307us/step - loss: 0.0323 - accuracy: 0.9985 - val_loss: 0.0545 - val_accuracy: 0.9974\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 11s 284us/step - loss: 0.0379 - accuracy: 0.9984 - val_loss: 0.0479 - val_accuracy: 0.9986\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 10s 274us/step - loss: 0.0306 - accuracy: 0.9986 - val_loss: 0.0650 - val_accuracy: 0.9950\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0341 - accuracy: 0.9983 - val_loss: 0.0677 - val_accuracy: 0.9974\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.0374 - accuracy: 0.9984 - val_loss: 0.0488 - val_accuracy: 0.9979\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 10s 264us/step - loss: 0.0272 - accuracy: 0.9989 - val_loss: 0.0340 - val_accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 11s 278us/step - loss: 0.0239 - accuracy: 0.9990 - val_loss: 0.0260 - val_accuracy: 0.9988\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 11s 279us/step - loss: 0.0292 - accuracy: 0.9987 - val_loss: 0.0204 - val_accuracy: 0.9981\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 0.0225 - accuracy: 0.9983 - val_loss: 0.0510 - val_accuracy: 0.9976\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 12s 306us/step - loss: 0.0171 - accuracy: 0.9992 - val_loss: 0.0599 - val_accuracy: 0.9960\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.0328 - accuracy: 0.9988 - val_loss: 0.0594 - val_accuracy: 0.9981\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 11s 293us/step - loss: 0.0244 - accuracy: 0.9988 - val_loss: 0.0922 - val_accuracy: 0.9969\n",
      "{'val_loss': [0.02314082332147611, 0.03781132370406195, 0.05906372444413936, 0.05451316932795509, 0.04785251879455512, 0.06498222319969635, 0.0676737839514836, 0.048805637942341926, 0.03396492533860281, 0.026032442093320306, 0.020366387810721726, 0.05100551976811895, 0.05990328816875159, 0.05944075137038061, 0.09223416959779093], 'val_accuracy': [0.9988095164299011, 0.9980952143669128, 0.9976190328598022, 0.9973809719085693, 0.9985714554786682, 0.9950000047683716, 0.9973809719085693, 0.9978571534156799, 0.9978571534156799, 0.9988095164299011, 0.9980952143669128, 0.9976190328598022, 0.9959523677825928, 0.9980952143669128, 0.9969047904014587], 'loss': [0.06669083802550421, 0.04797759281767355, 0.04023176502472175, 0.03229889096797746, 0.03787843333945621, 0.030645870509051553, 0.034085698114858114, 0.03736318008806676, 0.027168277557826977, 0.023862575933455213, 0.029194047206904935, 0.02250035623075431, 0.017052337531404595, 0.03279440698226865, 0.024356361309755263], 'accuracy': [0.99724865, 0.99804235, 0.9977249, 0.9984656, 0.99838626, 0.99857146, 0.9983069, 0.99843913, 0.99886245, 0.9989947, 0.99867725, 0.99833333, 0.9991799, 0.99878305, 0.9987566]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 12s 307us/step - loss: 0.0292 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0226 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0370 - accuracy: 0.9987 - val_loss: 0.0777 - val_accuracy: 0.9950\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 0.0341 - accuracy: 0.9980 - val_loss: 0.0202 - val_accuracy: 0.9993\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 0.0286 - val_accuracy: 0.9990\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 10s 261us/step - loss: 0.0276 - accuracy: 0.9989 - val_loss: 0.0499 - val_accuracy: 0.9983\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0448 - accuracy: 0.9988 - val_loss: 0.1572 - val_accuracy: 0.9967\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0419 - accuracy: 0.9983 - val_loss: 0.0594 - val_accuracy: 0.9971\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0332 - accuracy: 0.9985 - val_loss: 0.0322 - val_accuracy: 0.9983\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 10s 264us/step - loss: 0.0230 - accuracy: 0.9992 - val_loss: 0.1498 - val_accuracy: 0.9971\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0451 - accuracy: 0.9987 - val_loss: 0.0087 - val_accuracy: 0.9990\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0225 - accuracy: 0.9993 - val_loss: 0.0466 - val_accuracy: 0.9983\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0221 - accuracy: 0.9991 - val_loss: 0.0912 - val_accuracy: 0.9979\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.0343 - accuracy: 0.9989 - val_loss: 0.0577 - val_accuracy: 0.9976\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0321 - accuracy: 0.9990 - val_loss: 0.0382 - val_accuracy: 0.9988\n",
      "{'val_loss': [0.005446549561819056, 0.0031322305779238895, 0.07773272479910551, 0.020183460525814937, 0.0285984441005096, 0.04989352747434818, 0.15717805712702185, 0.0594422979145586, 0.03223767840298649, 0.14977504610479064, 0.008658666805304192, 0.04655114248819049, 0.09120155346091992, 0.05766401450372428, 0.038234041476655205], 'val_accuracy': [0.9995238184928894, 0.9997618794441223, 0.9950000047683716, 0.9992856979370117, 0.9990476369857788, 0.9983333349227905, 0.996666669845581, 0.9971428513526917, 0.9983333349227905, 0.9971428513526917, 0.9990476369857788, 0.9983333349227905, 0.9978571534156799, 0.9976190328598022, 0.9988095164299011], 'loss': [0.02924627437831318, 0.022561539261199873, 0.036952754733867076, 0.034116083956013156, 0.02451957430546944, 0.02760783770603922, 0.04481065123336038, 0.041873574909543895, 0.033169891138083524, 0.022979429864120098, 0.04508888396920605, 0.02253732359945967, 0.02211885896013585, 0.03429942249307759, 0.032112022904222395], 'accuracy': [0.9983598, 0.9988889, 0.99867725, 0.99796295, 0.9989153, 0.9989418, 0.99878305, 0.9983069, 0.99849206, 0.9991799, 0.9986508, 0.9993386, 0.9991005, 0.9989418, 0.9990212]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0270 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 10s 271us/step - loss: 0.0536 - accuracy: 0.9983 - val_loss: 0.0504 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 9s 241us/step - loss: 0.0386 - accuracy: 0.9988 - val_loss: 0.0244 - val_accuracy: 0.9988\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 238us/step - loss: 0.0229 - accuracy: 0.9990 - val_loss: 0.1153 - val_accuracy: 0.9971\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0379 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0193 - accuracy: 0.9993 - val_loss: 0.0315 - val_accuracy: 0.9990\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0346 - accuracy: 0.9990 - val_loss: 0.0199 - val_accuracy: 0.9990\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0131 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9993\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0358 - accuracy: 0.9988 - val_loss: 0.0262 - val_accuracy: 0.9988\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0259 - accuracy: 0.9993 - val_loss: 0.0223 - val_accuracy: 0.9993\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0432 - accuracy: 0.9988 - val_loss: 0.1062 - val_accuracy: 0.9976\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.0387 - accuracy: 0.9991 - val_loss: 0.2614 - val_accuracy: 0.9969\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.0394 - accuracy: 0.9989 - val_loss: 0.0832 - val_accuracy: 0.9986\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0204 - accuracy: 0.9992 - val_loss: 0.0238 - val_accuracy: 0.9986\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.0153 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9995\n",
      "{'val_loss': [0.0014090112702909946, 0.05035905796383824, 0.02444091273416269, 0.11528372969924774, 0.0015180026397394744, 0.031491749532025055, 0.01988193108140652, 0.01777522274371563, 0.026156304055392477, 0.022298179538476955, 0.10620027700020919, 0.2614429721608758, 0.08316823051465994, 0.023759798712119282, 0.004561653179739551], 'val_accuracy': [0.9997618794441223, 0.9980952143669128, 0.9988095164299011, 0.9971428513526917, 0.9995238184928894, 0.9990476369857788, 0.9990476369857788, 0.9992856979370117, 0.9988095164299011, 0.9992856979370117, 0.9976190328598022, 0.9969047904014587, 0.9985714554786682, 0.9985714554786682, 0.9995238184928894], 'loss': [0.026973056430999728, 0.05358985335057826, 0.0386028402091868, 0.022911194286683444, 0.03789060776553341, 0.019285345679678986, 0.03463007034775139, 0.013106364456659789, 0.035845915486654535, 0.02591899948072074, 0.043213446689841166, 0.038709823148667645, 0.039420023220498195, 0.02042481805800853, 0.01526281305522748], 'accuracy': [0.99896824, 0.9982804, 0.99878305, 0.9990212, 0.9987037, 0.99931216, 0.9989947, 0.9994444, 0.9987566, 0.9993386, 0.998836, 0.9991005, 0.9989418, 0.9992328, 0.99960315]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 10s 268us/step - loss: 0.0269 - accuracy: 0.9995 - val_loss: 0.0107 - val_accuracy: 0.9998\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 12s 307us/step - loss: 0.0243 - accuracy: 0.9992 - val_loss: 0.0986 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.0158 - accuracy: 0.9994 - val_loss: 0.0373 - val_accuracy: 0.9986\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0140 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9993\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0291 - accuracy: 0.9994 - val_loss: 0.0271 - val_accuracy: 0.9993\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0443 - accuracy: 0.9989 - val_loss: 0.1517 - val_accuracy: 0.9971\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0344 - accuracy: 0.9992 - val_loss: 3.3669e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.0300 - accuracy: 0.9993 - val_loss: 0.0672 - val_accuracy: 0.9981\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0483 - accuracy: 0.9989 - val_loss: 0.0275 - val_accuracy: 0.9986\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 244us/step - loss: 0.0275 - accuracy: 0.9994 - val_loss: 0.0472 - val_accuracy: 0.9988\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0405 - accuracy: 0.9990 - val_loss: 0.0271 - val_accuracy: 0.9995\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 10s 274us/step - loss: 0.0219 - accuracy: 0.9993 - val_loss: 0.0132 - val_accuracy: 0.9995\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 11s 279us/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.0465 - val_accuracy: 0.9990\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0245 - accuracy: 0.9996 - val_loss: 0.0414 - val_accuracy: 0.9993\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0332 - accuracy: 0.9994 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
      "{'val_loss': [0.010728385637110998, 0.09861310271363306, 0.037328525131017073, 0.005927993653048242, 0.027061450998473794, 0.15165401079442484, 3.366876792694841e-06, 0.0672345310203066, 0.02747613352091451, 0.047195422915688144, 0.027122308725402455, 0.013166994367327009, 0.046548488591507044, 0.04141173281485126, 0.0025688511984688894], 'val_accuracy': [0.9997618794441223, 0.9980952143669128, 0.9985714554786682, 0.9992856979370117, 0.9992856979370117, 0.9971428513526917, 1.0, 0.9980952143669128, 0.9985714554786682, 0.9988095164299011, 0.9995238184928894, 0.9995238184928894, 0.9990476369857788, 0.9992856979370117, 0.9997618794441223], 'loss': [0.026911486830676585, 0.02428686162064662, 0.015781542804068797, 0.01396956772753656, 0.02909000990187866, 0.04426687257599497, 0.03443528092899582, 0.02996707830364285, 0.04831562147053853, 0.027505322221934542, 0.04053532259178878, 0.021890080815245617, 0.012110994636925372, 0.024455173369275832, 0.033152142255876156], 'accuracy': [0.9994709, 0.9992328, 0.99941796, 0.9995503, 0.99939156, 0.9989153, 0.99920636, 0.99931216, 0.99886245, 0.9993651, 0.9990212, 0.99931216, 0.99949735, 0.9995503, 0.9993651]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.0553 - val_accuracy: 0.9990\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0240 - accuracy: 0.9994 - val_loss: 0.0601 - val_accuracy: 0.9988\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0429 - accuracy: 0.9991 - val_loss: 0.0878 - val_accuracy: 0.9990\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0219 - accuracy: 0.9994 - val_loss: 0.0746 - val_accuracy: 0.9993\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.0323 - accuracy: 0.9993 - val_loss: 0.0285 - val_accuracy: 0.9988\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0238 - accuracy: 0.9996 - val_loss: 0.0398 - val_accuracy: 0.9986\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0181 - accuracy: 0.9995 - val_loss: 0.0148 - val_accuracy: 0.9998\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0383 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9998\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 0.1696 - val_accuracy: 0.9979\n",
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 251us/step - loss: 0.0326 - accuracy: 0.9991 - val_loss: 0.0397 - val_accuracy: 0.9983\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.0225 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.0199 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9993\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 0.0354 - val_accuracy: 0.9988\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0212 - accuracy: 0.9994 - val_loss: 0.0390 - val_accuracy: 0.9993\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0216 - accuracy: 0.9994 - val_loss: 0.0252 - val_accuracy: 0.9993\n",
      "{'val_loss': [0.05534019995303381, 0.060144725981212795, 0.08784384449323018, 0.07459777105422247, 0.02845177991093979, 0.03979574799193955, 0.01479164245577825, 0.006089863148663412, 0.16964979188782806, 0.03970045110055555, 0.002717199769048464, 0.05574677018892181, 0.035374171958177436, 0.038966535096532466, 0.025151256371697118], 'val_accuracy': [0.9990476369857788, 0.9988095164299011, 0.9990476369857788, 0.9992856979370117, 0.9988095164299011, 0.9985714554786682, 0.9997618794441223, 0.9997618794441223, 0.9978571534156799, 0.9983333349227905, 0.9997618794441223, 0.9992856979370117, 0.9988095164299011, 0.9992856979370117, 0.9992856979370117], 'loss': [0.009666896175374284, 0.02397894662009074, 0.042900927021090114, 0.021947203512466536, 0.032266010686738816, 0.023750283818639074, 0.018138448622373828, 0.038302079403627495, 0.01874255677919115, 0.03264339070687741, 0.02251282039422285, 0.01985460750651766, 0.0169811378154818, 0.021199366861697606, 0.021643044424078547], 'accuracy': [0.99949735, 0.99941796, 0.999127, 0.99941796, 0.9992857, 0.9996296, 0.99949735, 0.9989153, 0.9994709, 0.9990741, 0.9993386, 0.9996561, 0.9994709, 0.99941796, 0.9994444]}\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0189 - accuracy: 0.9996 - val_loss: 0.0203 - val_accuracy: 0.9998\n",
      "Epoch 2/15\n",
      "37800/37800 [==============================] - 9s 236us/step - loss: 0.0341 - accuracy: 0.9994 - val_loss: 0.0522 - val_accuracy: 0.9993\n",
      "Epoch 3/15\n",
      "37800/37800 [==============================] - 10s 253us/step - loss: 0.0169 - accuracy: 0.9997 - val_loss: 0.0127 - val_accuracy: 0.9993\n",
      "Epoch 4/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 5/15\n",
      "37800/37800 [==============================] - 10s 265us/step - loss: 0.0132 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
      "Epoch 6/15\n",
      "37800/37800 [==============================] - 9s 245us/step - loss: 0.0283 - accuracy: 0.9992 - val_loss: 5.9605e-10 - val_accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.0251 - accuracy: 0.9994 - val_loss: 0.0128 - val_accuracy: 0.9998\n",
      "Epoch 8/15\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.0122 - accuracy: 0.9997 - val_loss: 0.0959 - val_accuracy: 0.9986\n",
      "Epoch 9/15\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0132 - accuracy: 0.9996 - val_loss: 0.0265 - val_accuracy: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.0230 - accuracy: 0.9995 - val_loss: 0.0187 - val_accuracy: 0.9990\n",
      "Epoch 11/15\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0189 - accuracy: 0.9997 - val_loss: 0.0268 - val_accuracy: 0.9990\n",
      "Epoch 12/15\n",
      "37800/37800 [==============================] - 9s 250us/step - loss: 0.0242 - accuracy: 0.9993 - val_loss: 0.0505 - val_accuracy: 0.9988\n",
      "Epoch 13/15\n",
      "37800/37800 [==============================] - 10s 261us/step - loss: 0.0225 - accuracy: 0.9995 - val_loss: 0.0260 - val_accuracy: 0.9990\n",
      "Epoch 14/15\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.0278 - accuracy: 0.9994 - val_loss: 0.0348 - val_accuracy: 0.9990\n",
      "Epoch 15/15\n",
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.0202 - accuracy: 0.9993 - val_loss: 0.0776 - val_accuracy: 0.9990\n",
      "{'val_loss': [0.020300413828697943, 0.052185712541852676, 0.012715602877961784, 0.006985234447887925, 0.0027386879637127694, 5.960456898416547e-10, 0.012806424001499226, 0.09590391976492746, 0.026488800076321716, 0.01867007272606272, 0.026784253375870707, 0.05052200685729206, 0.026031527159197806, 0.03481582127688896, 0.07759213965563547], 'val_accuracy': [0.9997618794441223, 0.9992856979370117, 0.9992856979370117, 0.9995238184928894, 0.9997618794441223, 1.0, 0.9997618794441223, 0.9985714554786682, 0.9988095164299011, 0.9990476369857788, 0.9990476369857788, 0.9988095164299011, 0.9990476369857788, 0.9990476369857788, 0.9990476369857788], 'loss': [0.018893616466305753, 0.03408522653968005, 0.016939409233220546, 0.014053966211045597, 0.013173120083138538, 0.028330024740374483, 0.025120260386459897, 0.012170037880312987, 0.01322182363056407, 0.023044795536713545, 0.018879327115618506, 0.024195763946752942, 0.02254013763372418, 0.02775059616827661, 0.020152560692075848], 'accuracy': [0.9995503, 0.9993651, 0.9996561, 0.9995238, 0.99968255, 0.99920636, 0.99941796, 0.9997355, 0.9995503, 0.9995238, 0.999709, 0.9993386, 0.9995238, 0.9993651, 0.9993386]}\n",
      "CPU times: user 1h 9min 22s, sys: 32min 58s, total: 1h 42min 21s\n",
      "Wall time: 45min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [15], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    predictions = gcv.best_estimator_.predict(x)\n",
    "    csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        best_grid_search_model = build_model(layers_candidates[gcv.best_params_['layers_candidates_key']])\n",
    "        skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "        for train_index, val_index in skf.split(X, y_sparse):\n",
    "            history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "            print(history.history)\n",
    "#         t1 = gcv.best_params_['layers_candidates_key']\n",
    "#         t2 = gcv.best_params_['epochs']\n",
    "#         def _build_model_grid_search_cv():\n",
    "#             return build_model(layers_candidates[t1])\n",
    "#         keras_classifier_best = KerasClassifier(_build_model_grid_search_cv)\n",
    "#         cross_val_score_sklearn(gcv.best_estimator_, X, y_sparse, fit_params={'epochs': t2})\n",
    "    \n",
    "if args.run_grid_search:\n",
    "    grid_search()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "}\n",
    "\n",
    "def test():\n",
    "    return build_model(layers_candidates[1])\n",
    "\n",
    "keras_classifier_best = KerasClassifier(test)\n",
    "cross_val_score_sklearn(keras_classifier_best, X, y_sparse, fit_params={'epochs':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Results\n",
    "\n",
    "input:\n",
    "{'epochs': [2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "results:\n",
    "\n",
    "2020-04-26 15:34:19,980 : INFO : Best params: {'epochs': 10, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-26 15:34:19,982 : INFO : Best CV score: 0.9835238095238095\n",
    "2020-04-26 15:34:19,983 : INFO : Best std: 0.001621147098147533   \n",
    "\n",
    "---\n",
    "input:\n",
    " param_grid={'epochs': [10, 20, 30], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy'}\n",
    "\n",
    "\n",
    "2020-04-27 23:44:34,829 : INFO : Best params: {'epochs': 30, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-27 23:44:34,829 : INFO : Best CV score: 0.9846190476190475\n",
    "2020-04-27 23:44:34,830 : INFO : Best std: 0.002779092659317115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | 50 epochs | 0.98814 | 0.9861 ±0.0026 |\n",
    "| Early stop (val_loss) | 16 epochs | 0.98957 | 0.9901 ±0.0019 |\n",
    "| Early stop (val_accuracy) | 17 epochs | 0.98757 | 0.9901 ±0.0018 |\n",
    "| Basic grid search (accuracy) | 15 epochs, layers: 1 | 0.96503 |  |\n",
    "| Basic grid search (neg_log_loss) | 2 epochs, layers: 2 | 0.98125 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  |\n",
    "|---|---|---|\n",
    "| Baseline | No validation, 200 epochs  | 0.99157, 0.98857 |\n",
    "| Baseline | Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_loss  | 0.98628 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_accuracy  | 0.98957 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_loss  | 0.98700 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_accuracy  | 0.98857 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=5  | 0.98200 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=12  | 0.98142 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the most confusing predicitons\n",
    "def analyse_confusing_predictions(predictions=predictions, n_confused=10, labels=None):\n",
    "    log.info(predictions.shape)\n",
    "    probabilities_sparse = np.max(predictions, axis=1)\n",
    "    min_prob = np.min(probabilities_spar§se)\n",
    "    min_index = np.argmin(probabilities_sparse, axis=0)\n",
    "    log.info('The most likely numbers for the less confident prediction: %s, probabilities: %s', \n",
    "             np.argpartition(predictions[min_index], -3)[-3:], \n",
    "             predictions[min_index][np.argpartition(predictions[min_index], -3)[-3:]])\n",
    "    \n",
    "    most_confused_predictions_indices = np.argpartition(probabilities_sparse, n_confused)[:n_confused]\n",
    "    log.info('Most confused indices: %s', most_confused_predictions_indices)\n",
    "    most_confused_probabilities = predictions[most_confused_predictions_indices]\n",
    "    likely_numbers_most_confused_probabilities = np.argpartition(most_confused_probabilities, -3, axis=1)[:, -3:]\n",
    "\n",
    "    probabilities_likely_numbers_most_confused_probabilities = np.empty(likely_numbers_most_confused_probabilities.shape)\n",
    "    for i, row in enumerate(most_confused_probabilities):\n",
    "        probabilities_likely_numbers_most_confused_probabilities[i] = row[likely_numbers_most_confused_probabilities[i]]\n",
    "\n",
    "    log.info('The most likely numbers for the less confident predictions: \\n%s, \\nprobabilities: \\n%s', \n",
    "            likely_numbers_most_confused_probabilities,\n",
    "            np.around(probabilities_likely_numbers_most_confused_probabilities, decimals=2))\n",
    "\n",
    "    if labels is not None:\n",
    "        for most_confusing_predictions_index in most_confused_predictions_indices:\n",
    "            draw_number(labels[most_confusing_predictions_index], \n",
    "                        args.raw_train.iloc[most_confusing_predictions_index, 1:].to_numpy().reshape(28, 28),\n",
    "                       (0.5, 0.5))\n",
    "\n",
    "analyse_confusing_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
