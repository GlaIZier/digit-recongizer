{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo add early stopping or choosing a model with the best validation score\n",
    "# Todo add K-fold\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo implement augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "args.n_splits = 5\n",
    "args.n_jobs = 3\n",
    "args.val_fraction = 0.2\n",
    "args.epochs = 200\n",
    "args.model_name = 'model.hdf5'\n",
    "\n",
    "args.X = args.raw_train.iloc[:, 1:].copy()\n",
    "args.y = args.raw_train['label'].copy()\n",
    "args.x = args.raw_test.copy()\n",
    "\n",
    "args.run_cnn = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1) \n",
    "title = args.raw_train.iloc[random_row, 0]\n",
    "plt.title(title)\n",
    "imgplot = plt.imshow(args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1) \n",
    "title = args.raw_train.iloc[random_row, 0]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(0.5, 0.5)\n",
    "ax.set_title(title)\n",
    "imgplot = ax.imshow(args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, x, build_classifier, parameters, splits=args.n_splits, n_jobs=args.n_jobs):\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    classifier = build_classifier()\n",
    "    gcv = GridSearchCV(classifier, parameters, n_jobs=n_jobs, cv=skf, verbose=5)\n",
    "    gcv.fit(X, y)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    classifier = build_classifier(gcv.best_params_)\n",
    "    classifier.fit(X, y)\n",
    "    predictions = classifier.predict(x)\n",
    "    return gcv.best_params_, gcv.best_score_, predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_predictions(predictions, filename):\n",
    "    image_ids = np.arange(1, len(predictions) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers \n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkhokhlush/github/digit-recongizer/.venv/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/200\n",
      "33600/33600 [==============================] - 10s 295us/step - loss: 0.5408 - accuracy: 0.9124 - val_loss: 0.1456 - val_accuracy: 0.9582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14564, saving model to model.hdf5\n",
      "Epoch 2/200\n",
      "33600/33600 [==============================] - 10s 285us/step - loss: 0.0787 - accuracy: 0.9769 - val_loss: 0.0847 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14564 to 0.08469, saving model to model.hdf5\n",
      "Epoch 3/200\n",
      "33600/33600 [==============================] - 10s 297us/step - loss: 0.0543 - accuracy: 0.9845 - val_loss: 0.0903 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08469\n",
      "Epoch 4/200\n",
      "33600/33600 [==============================] - 9s 282us/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.0735 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08469 to 0.07351, saving model to model.hdf5\n",
      "Epoch 5/200\n",
      "33600/33600 [==============================] - 10s 287us/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.0796 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07351\n",
      "Epoch 6/200\n",
      "33600/33600 [==============================] - 10s 287us/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 0.0861 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07351\n",
      "Epoch 7/200\n",
      "33600/33600 [==============================] - 10s 299us/step - loss: 0.0274 - accuracy: 0.9926 - val_loss: 0.0833 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07351\n",
      "Epoch 8/200\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.0826 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07351\n",
      "Epoch 9/200\n",
      "33600/33600 [==============================] - 11s 316us/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.1163 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07351\n",
      "Epoch 10/200\n",
      "33600/33600 [==============================] - 9s 276us/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 0.1451 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07351\n",
      "Epoch 11/200\n",
      "33600/33600 [==============================] - 9s 263us/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.1170 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/200\n",
      "33600/33600 [==============================] - 9s 274us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0922 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07351\n",
      "Epoch 13/200\n",
      "33600/33600 [==============================] - 9s 265us/step - loss: 6.5244e-04 - accuracy: 0.9998 - val_loss: 0.0991 - val_accuracy: 0.9905\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07351\n",
      "Epoch 14/200\n",
      "33600/33600 [==============================] - 9s 268us/step - loss: 1.6685e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07351\n",
      "Epoch 15/200\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 4.1289e-05 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07351\n",
      "Epoch 16/200\n",
      "33600/33600 [==============================] - 9s 272us/step - loss: 1.4026e-04 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9911\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07351\n",
      "Epoch 17/200\n",
      "33600/33600 [==============================] - 9s 283us/step - loss: 1.6138e-05 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07351\n",
      "Epoch 18/200\n",
      "33600/33600 [==============================] - 9s 268us/step - loss: 6.0687e-07 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 19/200\n",
      "33600/33600 [==============================] - 9s 280us/step - loss: 6.3328e-09 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07351\n",
      "Epoch 20/200\n",
      "33600/33600 [==============================] - 9s 271us/step - loss: 5.1017e-09 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07351\n",
      "Epoch 21/200\n",
      "33600/33600 [==============================] - 9s 276us/step - loss: 4.3992e-09 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07351\n",
      "Epoch 22/200\n",
      "33600/33600 [==============================] - 9s 275us/step - loss: 3.8245e-09 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07351\n",
      "Epoch 23/200\n",
      "33600/33600 [==============================] - 9s 270us/step - loss: 3.7642e-09 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9914\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07351\n",
      "Epoch 24/200\n",
      "33600/33600 [==============================] - 9s 279us/step - loss: 3.1079e-09 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07351\n",
      "Epoch 25/200\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 2.6644e-09 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 26/200\n",
      "33600/33600 [==============================] - 9s 276us/step - loss: 2.0648e-09 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07351\n",
      "Epoch 27/200\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 2.0578e-09 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07351\n",
      "Epoch 28/200\n",
      "33600/33600 [==============================] - 9s 275us/step - loss: 2.0223e-09 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07351\n",
      "Epoch 29/200\n",
      "33600/33600 [==============================] - 9s 270us/step - loss: 1.9868e-09 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07351\n",
      "Epoch 30/200\n",
      "33600/33600 [==============================] - 9s 282us/step - loss: 1.9655e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07351\n",
      "Epoch 31/200\n",
      "33600/33600 [==============================] - 9s 274us/step - loss: 1.9336e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07351\n",
      "Epoch 32/200\n",
      "33600/33600 [==============================] - 10s 285us/step - loss: 1.9442e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 33/200\n",
      "33600/33600 [==============================] - 10s 296us/step - loss: 1.8910e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07351\n",
      "Epoch 34/200\n",
      "33600/33600 [==============================] - 10s 291us/step - loss: 1.8875e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07351\n",
      "Epoch 35/200\n",
      "33600/33600 [==============================] - 10s 289us/step - loss: 1.8839e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07351\n",
      "Epoch 36/200\n",
      "33600/33600 [==============================] - 9s 282us/step - loss: 1.8804e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07351\n",
      "Epoch 37/200\n",
      "33600/33600 [==============================] - 9s 270us/step - loss: 1.8768e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07351\n",
      "Epoch 38/200\n",
      "33600/33600 [==============================] - 9s 273us/step - loss: 1.8768e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07351\n",
      "Epoch 39/200\n",
      "33600/33600 [==============================] - 9s 264us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 40/200\n",
      "33600/33600 [==============================] - 9s 259us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07351\n",
      "Epoch 41/200\n",
      "33600/33600 [==============================] - 9s 263us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07351\n",
      "Epoch 42/200\n",
      "33600/33600 [==============================] - 9s 268us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07351\n",
      "Epoch 43/200\n",
      "33600/33600 [==============================] - 9s 264us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07351\n",
      "Epoch 44/200\n",
      "33600/33600 [==============================] - 9s 269us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07351\n",
      "Epoch 45/200\n",
      "33600/33600 [==============================] - 9s 273us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07351\n",
      "Epoch 46/200\n",
      "33600/33600 [==============================] - 9s 282us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 47/200\n",
      "33600/33600 [==============================] - 9s 271us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07351\n",
      "Epoch 48/200\n",
      "33600/33600 [==============================] - 9s 273us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07351\n",
      "Epoch 49/200\n",
      "33600/33600 [==============================] - 9s 273us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07351\n",
      "Epoch 50/200\n",
      "33600/33600 [==============================] - 9s 263us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07351\n",
      "Epoch 51/200\n",
      "33600/33600 [==============================] - 9s 265us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07351\n",
      "Epoch 52/200\n",
      "33600/33600 [==============================] - 9s 260us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07351\n",
      "Epoch 53/200\n",
      "33600/33600 [==============================] - 9s 257us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07351\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 54/200\n",
      "33600/33600 [==============================] - 9s 259us/step - loss: 1.8733e-09 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07351\n",
      "Epoch 00054: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17e612f90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, mode='min', verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.fit(args.X.to_numpy().reshape(args.X.shape[0], 28, 28, 1), pd.get_dummies(args.y, prefix='label').to_numpy(), validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-21 12:21:03,754 : INFO : Saved file: ../predictions/cnn_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "if args.run_cnn:\n",
    "    predictions = model.predict(args.x.to_numpy().reshape(args.x.shape[0], 28, 28, 1))\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    csv_predictions(predictions, 'cnn_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.X.shape\n",
    "args.X.to_numpy().reshape(args.X.shape[0], 28, 28, 1)\n",
    "pd.get_dummies(args.y, prefix='label').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_classifier_builder(params_dict=None):\n",
    "    _params_dict = params_dict if params_dict else {}\n",
    "    return SVC(**_params_dict, kernel='linear')\n",
    "\n",
    "parameters = {'C': [0.01], 'gamma': [0.001]}\n",
    "\n",
    "if args.run_svm:\n",
    "    best_params, score, predictions = predict(args.X, args.y, args.x, svm_classifier_builder, parameters)\n",
    "    csv_predictions(predictions, 'svm_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Model  | Test score  |\n",
    "|---|---|\n",
    "| No validation, 200 epochs  | 0.99157 |\n",
    "| Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Validation (20%), 200 epochs, early stopping val_loss  | 0.98885 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
