{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo stop the numbers to vary from time to time\n",
    "# Todo add K-fold\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo implement augmentation\n",
    "# Todo try to get a pretrained cnn\n",
    "# Todo early stop\n",
    "# Todo print the numbers in square like in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "_seed = 1337\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(_seed)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(_seed)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.model_name = 'deep-learning-keras-model.hdf5'\n",
    "args.seed=_seed\n",
    "\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "\n",
    "args.run_baseline = True\n",
    "args.run_early_stop = True\n",
    "args.run_grid_search = True\n",
    "args.run_kfold_validation = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(label, pixels_2d, size_inches=None):\n",
    "    title = args.raw_train.iloc[random_row, 0]\n",
    "    fig, ax = plt.subplots()\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    ax.set_title(label)\n",
    "    imgplot = ax.imshow(pixels_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAABKCAYAAADkMDmGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAE8klEQVR4nO2bb2hVZRzHP9/WjCQHhTZWjWV3vXCv+jPawnbfhBC9CSHY9qL7Lr2gkaOIkF4I0YukHFHRWmg0CFpQQoQwQoKZbaaJZTqUu+ySOiQxmGhq5q8X92zee13es3ufc/Zo5wuXnXN2zvP78bnP83t+z3N+V2bG/123LLQDPiiBQAIBSCAACQQggQAkEIAbAIKkHkkTks5JmpTU5drGra4bdClJq4A3gW7gB6ApEjs+Z4ySvge2mtnWKO14Oxwk1QHtwDJJOUnHJb0n6XbXtryFADQC9cCzQBfwEPAw8JprQz5D+Cv4+66ZTZnZaWAL8LRrQ95CMLM/geNAcdCKJIB5CyHQx8ALku6WdCfQB3zt2ojXUyTwOrAUOApcAD4H3nBtxOspMi75PhxiUQKBGiFIekrSkSCZedWVU3Gr6pgQZHRHgVUUprK9QK+ZHXbnXjyqpSc8BuTM7FczuwR8Bjzjxq14VcsUeS/we9H5caCj/CZJa4A1AHXUPbqYhhpMhtcFznHJLirMvZHnCWY2CAwCNOgu69CT827j/OoOlr8ywVDLKF3r1rJ4+56Kz+yxnaHbrwXCCaC56Py+4Jpz7Xr/w9njk2nRut1t+7XEhL3Ag5KWS1oE9ABfuXHrqnL9nSXnrX3jrk1U3xPM7LKk9cAIUAdsM7NDzjwDGscaGGkZACCTT3Ns8woWU3kozFc1xQQz2wHscORLiRrHGhhqGZ093z3eRut2970APM4YiwFANMNgRl5CKI8DXevWRmrPSwiT3QOzx5l8OtSUWIu8g1DeC3aPt0Vu0zsI5bpntHRtk+vvJNffycjJAzSOuck+vYOwsvPq+is1nJ0dCrn+ThrHGpjsHpgdLkMto9f0nGrk3fZa+axwfnVHkDEeiMymVxDKu/dk90DhBVzE8mo4lPeCTD59zT2p4WzJuYv8wSsI5SqHkhrOlkyfrvIHryDM9c0XqxgA4Cx/8ArCsc0rQt9bPixqkVcQwn6zmXza6VrCKwhQ+RvO5NOcenzaqU3vILT2jZcEvNRwlkw+TWo4S2o46xwAhNhyl9QMDFGoFzBg0MzekbQJeB74I7h1Y7C/8J+qdo+xGu2xnUzbGWcbrZeBl8xsv6QlwI+Svgn+129mb1XrqC+qCMHMpoCp4PispAkK2+03jeYVEyTdT6FkZiaMr5f0s6RtQf3AXM+skbRP0r6/uViTs1EpNARJdwBfABvMbBr4AEhRqCWaAt6e6zkzGzSzdjNrr+c2By67VygIkuopAPjUzL4EMLNTZvaPmV0BPqLwWu6GVJjZQcAnwBkz21B0vSmIF0jqAzrMrKdCW2eBIzV7fX0tBU4DLWa2LMwDYSA8AewCDgJXgssbgV4KQ8GA34C1M1Cu09Y+M2sP41i1qsZGmNnhO2Cu+TaS9w0LIe8yxoVQ3BAGfbSRVK+RDAcgRgiui7wkNUv6VtJhSYckvRhc3yTphKQDwadyLbSZRf6h8Op+EngAWAT8BLTV2GYT8EhwvIRCEVkbsAl4eT5txdUTnBd5BZXv+4Pjs0DVC7u4IMxV5OVsJVrNwq5YN3xgrHZhV6y4IERS5OVqYRcXBOdFXsHCbiswYWZbiq4X/2JuNfBLpbZieRcZUZHXSuA54KCkmbe1G4FeSSULu0oNJRkjN0FgdKEEAgkEIIEAJBCABAKQQAASCAD8CxqqVhohMoqJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAABKCAYAAADkMDmGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAF4UlEQVR4nO2aeWxUVRSHvx8zbSmlNRCxIpu4B1qFikIFCUIIS4yIMRFw4w9ZJEZqNMS4xCUmRkUxMaamRhANAaNgxGAUQ0jUaBugQKFtKJSAtLaigHYslDIzxz9m0IrFmc68mb7i+yWTvHd77z0nX+9yzn1XZsb/Xb262wE3yIOABwHwIAAeBMCDAHgQAJdDkNRf0qeSWiUdljQvFXb8qejUQb0NtAP5wChgk6TdZlbtpBG5NWKUlAOcAArMrC5a9iHQaGZPOmnLzdPhGiB4FkBUu4GRThtyM4S+QMs5Zb8DuU4bcjOEP4C8c8rygIDThtwMoQ7wS7q6Q9kNgKOLIrh4YQSQtA4w4CEiu8MXwC1O7w5uHgkAS4Bs4CiwFnjYaQDg8pGQLrl9JKRFHgSShCBpuqR9kg5IcjSKS6cSXhMk+YhsY1OBBmAbMNfMapxzLz1KZiTcDBwws4Nm1g6sA2Y541Z6lUwWOQg40uG9ARh7biVJC4GFAD58N/b5VxCYGrXRSrudVjx1U55Km1kZUAaQp/42VlNSbRKACtsSd91kpkMjMKTD++BoWY9TMhC2AVdLGi4pE5gDbHTGrfQq4elgZkFJjwBfAT5gZSpC2nQoqTXBzL4gktT0aLn6jDE0qYhgHx9H5gXJqM/m0ooz9Nl/jND+g47acS0E/5DBLHtvNVOyQ5GCycAC2HG6ncfq7iF3/imCTc2O2HJv7hAOs/ro+L9ep9XeTuGbS3jhxzv4pvBTXvx+I78sLnbElCtHQsvccWx4ZTkD/X15v+USVpfMInNzJZeFGzi93MeMnFsBaF0Gd1ed4pPSyeSv2km4rS0he64aCcrK4vf7xvFxFMCihmLWzp9O5pfbIBydFuEQ4UCAcCDAFS/v5kSwD5XPllL/3GiUlZWQXVdBqH+hiPJX36GmvR83Pf0wR2ZkQ3nVeeuHT55k7/xrAah7sJTmRTcmZNcVEHr17k3+D3nsf6CU8rYQK0aPo/+qHwgdOx6zrdUc4JmjhQC0DkosI3YFhN9mj+KDYd8AMO/bBYQD8Z+qWzDIR5snAHDn1PKE7Hc7BP/gQUxcFnG+uv0U1730W5f7yG6OJIuvXbozMR8SauWgDiweyqb8TQAsK55NqCn+QMg/fBj1r+RRccvr/BEW05cuJYeKLvvQ7RCmTIv899YF+tF8x3Dy154EIBQIIH8GyvAj/99uHllUQGtBG3Ou3870iz5jYm949KeJ1JaMJOe7rgOANB+5d3ae0LB+JNXFa/5Vd3zVXUzIP8iMvComZYfP22dB+b0MfeYMoZq6f5RX2BZa7HhchyrdDkFjCigsq45rPm855eNQ+wBOhrN46/OZXPXhcaz+cKdBUo+CABC6rYhgb1/M9jlVjQQbf4rLVlcgdPuaAODbWklsBBBMkf2YW6SkIZK2SqqRVC1pabT8eUmNknZFfzNT5GPKFc9ICAKPm1mlpFxgh6Svo39bYWbLU+deehQTgpk1AU3R54CkWiLH7ReMuhQxSrocGA1/RSSPSKqStFJSv/O0WShpu6TtZzidlLOpUtwQJPUF1gMlZtYClAJXErk80QS83lk7MyszszFmNiaDxFLdVCsuCJIyiABYY2YbAMzsZzMLmVkYeJfIZ7keqZhxgiQBq4HjZlbSoXxgdL1A0mPAWDObE6OvALAvaa//WxcDvwLDzGxAPA3igTAB+BbYA5yNX58C5hKZCgYcAhadhfIffW03szHxOJaoErERz+7wHdBZ5NXjvzecVbefJ7hB6YZQ5kYb3u01vOkApBGC05e8HE3szCzlPyKf7uuBK4BMIlf2RyTZ50CgKPqcS+QS2QjgeeCJrvSVrpHg+CUvM2sys8rocwBIOLFLF4TOLnk5lokmkth1VI9fGBNN7DoqXRBScsnLqcQuXRAcv+QVTezeA2rN7I0O5QM7VJsN7I3VV1oOWlN0yWs8cD+wR9KuaNlTwFxJ/0jsYnXkRYxcAAujE/Ig4EEAPAiABwHwIAAeBMCDAMCfHzbadnyvbN0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 19:00:53,793 : INFO : X.shape: (42000, 28, 28, 1)\n",
      "2020-07-07 19:00:53,794 : INFO : X[0][14][14]: [254]\n",
      "2020-07-07 19:00:53,795 : INFO : y.shape: (42000, 10)\n",
      "2020-07-07 19:00:53,796 : INFO : y[0], [0 1 0 0 0 0 0 0 0 0]\n",
      "2020-07-07 19:00:53,803 : INFO : type of target y: 'multilabel-indicator'\n",
      "2020-07-07 19:00:53,804 : INFO : y_sparse.shape: (42000,)\n",
      "2020-07-07 19:00:53,805 : INFO : y_sparse: array([1, 0, 1, ..., 7, 6, 9])\n",
      "2020-07-07 19:00:53,806 : INFO : y_sparse[0]: 1\n",
      "2020-07-07 19:00:53,808 : INFO : type of target y_sparse: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_sparse = args.labels.to_numpy()\n",
    "x = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)\n",
    "\n",
    "log.info('X.shape: %s', repr(X.shape))\n",
    "log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('y.shape: %s', repr(y.shape))\n",
    "log.info('y[0], %s', y[0])\n",
    "log.info('type of target y: %s', repr(sklearn.utils.multiclass.type_of_target(y)))\n",
    "\n",
    "log.info('y_sparse.shape: %s', repr(y_sparse.shape))\n",
    "log.info('y_sparse: %s', repr(y_sparse))\n",
    "log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('type of target y_sparse: %s', repr(sklearn.utils.multiclass.type_of_target(y_sparse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_sparse_predictions(predictions_sparse, filename):\n",
    "    image_ids = np.arange(1, len(predictions_sparse) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_sparse})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_sparse = np.argmax(predictions, axis=1)\n",
    "    csv_sparse_predictions(predictions_sparse, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cross_val_score_sklearn(sklearn_model, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params=None):\n",
    "    cvs = cross_val_score(sklearn_model, X, y, cv=n_splits, n_jobs=args.n_jobs, fit_params=fit_params)\n",
    "    log.info('CV mean accuracy: %0.5f. std: %0.5f', cvs.mean(), cvs.std())\n",
    "    return cvs\n",
    "    \n",
    "def cross_val_score_keras(keras_model_builder, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params={'epochs': args.epochs}):\n",
    "    keras_classifier = KerasClassifier(keras_model_builder)\n",
    "    return cross_val_score_sklearn(keras_classifier, X, y, scoring=scoring, n_splits=n_splits, fit_params=fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "def build_model(layers_list, optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy', metrics_tuple=('accuracy')):\n",
    "    model = models.Sequential(layers_list)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics_tuple])\n",
    "    log.info(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "\n",
    "def build_baseline_model_sparse():\n",
    "    layers_list = [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "    return build_model(layers_list=layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 19:00:53,981 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.5283 - accuracy: 0.9170 - val_loss: 0.1021 - val_accuracy: 0.9717\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 10s 271us/step - loss: 0.0816 - accuracy: 0.9769 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0566 - accuracy: 0.9839 - val_loss: 0.0547 - val_accuracy: 0.9869\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 10s 271us/step - loss: 0.0442 - accuracy: 0.9881 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 10s 271us/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 0.0969 - val_accuracy: 0.9817\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 0.0324 - accuracy: 0.9916 - val_loss: 0.0655 - val_accuracy: 0.9864\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 11s 290us/step - loss: 0.0318 - accuracy: 0.9921 - val_loss: 0.0561 - val_accuracy: 0.9888\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 10s 276us/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0764 - val_accuracy: 0.9855\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 11s 278us/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.0960 - val_accuracy: 0.9862\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 11s 282us/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 0.1092 - val_accuracy: 0.9850\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 0.0270 - accuracy: 0.9943 - val_loss: 0.1350 - val_accuracy: 0.9807\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0228 - accuracy: 0.9954 - val_loss: 0.0658 - val_accuracy: 0.9867\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 0.0695 - val_accuracy: 0.9898\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 11s 287us/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 0.1003 - val_accuracy: 0.9895\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 11s 296us/step - loss: 0.0244 - accuracy: 0.9957 - val_loss: 0.0861 - val_accuracy: 0.9900\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.1087 - val_accuracy: 0.9907\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 10s 270us/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.1066 - val_accuracy: 0.9898\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 10s 261us/step - loss: 0.0200 - accuracy: 0.9963 - val_loss: 0.0944 - val_accuracy: 0.9881\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 0.1082 - val_accuracy: 0.9898\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 11s 289us/step - loss: 0.0154 - accuracy: 0.9977 - val_loss: 0.1711 - val_accuracy: 0.9914\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 11s 288us/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 0.1206 - val_accuracy: 0.9888\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.0198 - accuracy: 0.9968 - val_loss: 0.1877 - val_accuracy: 0.9869\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 11s 295us/step - loss: 0.0225 - accuracy: 0.9974 - val_loss: 0.1997 - val_accuracy: 0.9874\n",
      "Epoch 24/50\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.0177 - accuracy: 0.9972 - val_loss: 0.1818 - val_accuracy: 0.9883\n",
      "Epoch 25/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0194 - accuracy: 0.9974 - val_loss: 0.1603 - val_accuracy: 0.9902\n",
      "Epoch 26/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0169 - accuracy: 0.9980 - val_loss: 0.1941 - val_accuracy: 0.9876\n",
      "Epoch 27/50\n",
      "37800/37800 [==============================] - 11s 283us/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.2327 - val_accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 0.0212 - accuracy: 0.9976 - val_loss: 0.2556 - val_accuracy: 0.9902\n",
      "Epoch 29/50\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0261 - accuracy: 0.9976 - val_loss: 0.3934 - val_accuracy: 0.9852\n",
      "Epoch 30/50\n",
      "37800/37800 [==============================] - 11s 283us/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 0.2585 - val_accuracy: 0.9881\n",
      "Epoch 31/50\n",
      "37800/37800 [==============================] - 11s 284us/step - loss: 0.0187 - accuracy: 0.9979 - val_loss: 0.2206 - val_accuracy: 0.9864\n",
      "Epoch 32/50\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.3007 - val_accuracy: 0.9867\n",
      "Epoch 33/50\n",
      "37800/37800 [==============================] - 11s 299us/step - loss: 0.0170 - accuracy: 0.9981 - val_loss: 0.2456 - val_accuracy: 0.9888\n",
      "Epoch 34/50\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.2612 - val_accuracy: 0.9900\n",
      "Epoch 35/50\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.3547 - val_accuracy: 0.9893\n",
      "Epoch 36/50\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0229 - accuracy: 0.9981 - val_loss: 0.3749 - val_accuracy: 0.9874\n",
      "Epoch 37/50\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 0.0249 - accuracy: 0.9977 - val_loss: 0.3896 - val_accuracy: 0.9883\n",
      "Epoch 38/50\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.0255 - accuracy: 0.9978 - val_loss: 0.2379 - val_accuracy: 0.9900\n",
      "Epoch 39/50\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.3728 - val_accuracy: 0.9886\n",
      "Epoch 40/50\n",
      "37800/37800 [==============================] - 10s 276us/step - loss: 0.0130 - accuracy: 0.9984 - val_loss: 0.3090 - val_accuracy: 0.9895\n",
      "Epoch 41/50\n",
      "37800/37800 [==============================] - 10s 265us/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 0.3432 - val_accuracy: 0.9888\n",
      "Epoch 42/50\n",
      "37800/37800 [==============================] - 10s 269us/step - loss: 0.0203 - accuracy: 0.9986 - val_loss: 0.4997 - val_accuracy: 0.9893\n",
      "Epoch 43/50\n",
      "37800/37800 [==============================] - 10s 269us/step - loss: 0.0192 - accuracy: 0.9987 - val_loss: 0.2942 - val_accuracy: 0.9902\n",
      "Epoch 44/50\n",
      "37800/37800 [==============================] - 11s 292us/step - loss: 0.0224 - accuracy: 0.9979 - val_loss: 0.4356 - val_accuracy: 0.9876\n",
      "Epoch 45/50\n",
      "37800/37800 [==============================] - 10s 277us/step - loss: 0.0226 - accuracy: 0.9983 - val_loss: 0.4325 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "37800/37800 [==============================] - 11s 280us/step - loss: 0.0236 - accuracy: 0.9985 - val_loss: 0.3791 - val_accuracy: 0.9876\n",
      "Epoch 47/50\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0216 - accuracy: 0.9984 - val_loss: 0.5514 - val_accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0226 - accuracy: 0.9985 - val_loss: 0.3774 - val_accuracy: 0.9871\n",
      "Epoch 49/50\n",
      "37800/37800 [==============================] - 11s 281us/step - loss: 0.0251 - accuracy: 0.9983 - val_loss: 0.3676 - val_accuracy: 0.9881\n",
      "Epoch 50/50\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 0.0165 - accuracy: 0.9984 - val_loss: 0.6189 - val_accuracy: 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 19:09:32,347 : INFO : History keys: dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 19:09:34,332 : INFO : Saved file: ../predictions/cnn_baseline_predictions.csv\n",
      "2020-07-07 19:34:02,451 : INFO : CV mean accuracy: 0.98790. std: 0.00069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 20s, sys: 9min 26s, total: 30min 47s\n",
      "Wall time: 33min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def baseline():\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1)\n",
    "    plot_history(history)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_baseline_predictions.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse)\n",
    "    \n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-08 11:17:55,274 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 11s 296us/step - loss: 0.5810 - accuracy: 0.9099 - val_loss: 0.0708 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97952, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 11s 279us/step - loss: 0.0803 - accuracy: 0.9766 - val_loss: 0.0637 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.97952 to 0.98048, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.0539 - accuracy: 0.9847 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.98048\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.0432 - accuracy: 0.9880 - val_loss: 0.0539 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98048 to 0.98571, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 10s 275us/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0560 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98571 to 0.98667, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 10s 276us/step - loss: 0.0311 - accuracy: 0.9922 - val_loss: 0.0572 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98667\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 10s 277us/step - loss: 0.0286 - accuracy: 0.9931 - val_loss: 0.0531 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98667 to 0.98786, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 10s 270us/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0734 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.98786 to 0.98810, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 10s 264us/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.1432 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98810\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.0661 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98810\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 11s 284us/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.1515 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98810\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 10s 276us/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0938 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.98810 to 0.98952, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 11s 280us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0884 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.98952 to 0.99000, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 10s 259us/step - loss: 4.2077e-04 - accuracy: 0.9999 - val_loss: 0.1006 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.99000 to 0.99024, saving model to deep-learning-keras-model.hdf5\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 2.5384e-04 - accuracy: 0.9999 - val_loss: 0.1134 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99024\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 10s 265us/step - loss: 2.5868e-04 - accuracy: 0.9999 - val_loss: 0.1161 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99024\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 10s 269us/step - loss: 2.4277e-04 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99024\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 6.8385e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99024\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 10s 269us/step - loss: 7.3249e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99024\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 10s 273us/step - loss: 6.2847e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99024\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 5.2704e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99024\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 10s 263us/step - loss: 5.2820e-05 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99024\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 11s 290us/step - loss: 5.2500e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99024\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 24/50\n",
      "37800/37800 [==============================] - 10s 276us/step - loss: 5.1280e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-08 11:22:04,036 : INFO : History keys: dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99024\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-08 11:22:05,852 : INFO : Saved file: ../predictions/cnn_early_stop_predictions.csv\n",
      "2020-07-08 11:33:07,336 : INFO : CV mean accuracy: 0.99017. std: 0.00037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 14s, sys: 4min 52s, total: 15min 7s\n",
      "Wall time: 15min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def early_stop(monitor='val_loss'):\n",
    "    # val_loss\n",
    "    # val_accuracy\n",
    "    early_stopping = EarlyStopping(monitor=monitor, patience=10, mode='auto', verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor=monitor, mode='auto', verbose=1)\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='auto')\n",
    "\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])\n",
    "\n",
    "    plot_history(history)\n",
    "    model.load_weights(args.model_name)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_early_stop_predictions.csv')\n",
    "    \n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse, fit_params={'validation_split': args.val_fraction, 'epochs': args.epochs, 'batch_size': 64, 'callbacks': [early_stopping, model_checkpoint, reduce_lr_on_plateau]})\n",
    "\n",
    "if args.run_early_stop:\n",
    "    early_stop(monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic grid search to choose the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 398.2min finished\n",
      "2020-07-09 05:54:12,502 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 0.3101 - accuracy: 0.9454\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0796 - accuracy: 0.9798\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0766 - accuracy: 0.9835\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 14s 332us/step - loss: 0.0731 - accuracy: 0.9846\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 14s 329us/step - loss: 0.0803 - accuracy: 0.9835\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 14s 331us/step - loss: 0.0850 - accuracy: 0.9848\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 14s 331us/step - loss: 0.0766 - accuracy: 0.9860\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 14s 332us/step - loss: 0.0838 - accuracy: 0.9852\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 14s 332us/step - loss: 0.0809 - accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 14s 329us/step - loss: 0.0845 - accuracy: 0.9859\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.0871 - accuracy: 0.9859\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0982 - accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 13s 321us/step - loss: 0.0896 - accuracy: 0.9866\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0974 - accuracy: 0.9869\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 13s 321us/step - loss: 0.0918 - accuracy: 0.9884\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0880 - accuracy: 0.9878\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.1020 - accuracy: 0.9883\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.1051 - accuracy: 0.9891\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 14s 324us/step - loss: 0.0779 - accuracy: 0.9899\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0851 - accuracy: 0.9883\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 13s 313us/step - loss: 0.0883 - accuracy: 0.9894\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 13s 308us/step - loss: 0.1099 - accuracy: 0.9893\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 13s 300us/step - loss: 0.0912 - accuracy: 0.9899\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 13s 301us/step - loss: 0.0950 - accuracy: 0.9896\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 13s 302us/step - loss: 0.0991 - accuracy: 0.9898\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 13s 305us/step - loss: 0.0952 - accuracy: 0.9896\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 13s 309us/step - loss: 0.0890 - accuracy: 0.9908\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 13s 313us/step - loss: 0.0975 - accuracy: 0.9909\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 13s 313us/step - loss: 0.1109 - accuracy: 0.9901\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 13s 313us/step - loss: 0.0959 - accuracy: 0.9918\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 13s 314us/step - loss: 0.1214 - accuracy: 0.9915\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 13s 315us/step - loss: 0.0959 - accuracy: 0.9928\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0875 - accuracy: 0.9926\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0750 - accuracy: 0.9918\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 13s 315us/step - loss: 0.0950 - accuracy: 0.9920\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.1159 - accuracy: 0.9918\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0930 - accuracy: 0.9931\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 14s 322us/step - loss: 0.1184 - accuracy: 0.9927\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 13s 315us/step - loss: 0.0900 - accuracy: 0.9927\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0901 - accuracy: 0.9948\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.1060 - accuracy: 0.9929\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 13s 321us/step - loss: 0.0846 - accuracy: 0.9944\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.1177 - accuracy: 0.9935\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0902 - accuracy: 0.9935\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0943 - accuracy: 0.9940\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0859 - accuracy: 0.9949\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.0705 - accuracy: 0.9945\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0730 - accuracy: 0.9953\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.1019 - accuracy: 0.9950\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.1112 - accuracy: 0.9957\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0979 - accuracy: 0.9952\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0687 - accuracy: 0.9960\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0885 - accuracy: 0.9963\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.1132 - accuracy: 0.9961\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0939 - accuracy: 0.9958\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0746 - accuracy: 0.9961\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0787 - accuracy: 0.9966\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0730 - accuracy: 0.9970\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0626 - accuracy: 0.9974\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0780 - accuracy: 0.9963\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.0633 - accuracy: 0.9973\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0665 - accuracy: 0.9975\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0620 - accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0553 - accuracy: 0.9968\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 13s 321us/step - loss: 0.0747 - accuracy: 0.9974\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0658 - accuracy: 0.9972\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0627 - accuracy: 0.9976\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0851 - accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0861 - accuracy: 0.9976\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0545 - accuracy: 0.9981\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0562 - accuracy: 0.9985\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0489 - accuracy: 0.9983\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0759 - accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0484 - accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0645 - accuracy: 0.9985\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0511 - accuracy: 0.9989\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0532 - accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0835 - accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0604 - accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0496 - accuracy: 0.9989\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0501 - accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0331 - accuracy: 0.9989\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0458 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0558 - accuracy: 0.9984\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0546 - accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0651 - accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 14s 323us/step - loss: 0.0766 - accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0605 - accuracy: 0.9988\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 13s 320us/step - loss: 0.0531 - accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0289 - accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 13s 318us/step - loss: 0.0953 - accuracy: 0.9975\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 14s 322us/step - loss: 0.0714 - accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 13s 317us/step - loss: 0.0537 - accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0506 - accuracy: 0.9988\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 14s 333us/step - loss: 0.0324 - accuracy: 0.9991\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0475 - accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0576 - accuracy: 0.9987\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 14s 324us/step - loss: 0.0616 - accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 13s 319us/step - loss: 0.0447 - accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 13s 316us/step - loss: 0.0246 - accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 06:16:34,681 : INFO : Best params: {'epochs': 100, 'layers_candidates_key': 2}\n",
      "2020-07-09 06:16:34,682 : INFO : Best CV score: 0.9886428571428573\n",
      "2020-07-09 06:16:34,683 : INFO : Best std: 0.001540459630440178\n",
      "2020-07-09 06:16:36,168 : INFO : Saved file: ../predictions/cnn_basic_grid_search.csv\n",
      "2020-07-09 06:16:36,215 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0248 - accuracy: 0.9993 - val_loss: 0.0236 - val_accuracy: 0.9993\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0267 - accuracy: 0.9992 - val_loss: 0.0686 - val_accuracy: 0.9992\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0201 - accuracy: 0.9995 - val_loss: 0.0161 - val_accuracy: 0.9995\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.0197 - val_accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0270 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9998\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0075 - accuracy: 0.9997 - val_loss: 0.0405 - val_accuracy: 0.9989\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0067 - accuracy: 0.9999 - val_loss: 0.0618 - val_accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0303 - val_accuracy: 0.9992\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0216 - accuracy: 0.9996 - val_loss: 0.0935 - val_accuracy: 0.9989\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0165 - accuracy: 0.9996 - val_loss: 0.0971 - val_accuracy: 0.9989\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0212 - accuracy: 0.9994 - val_loss: 0.1227 - val_accuracy: 0.9989\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0177 - accuracy: 0.9995 - val_loss: 0.0429 - val_accuracy: 0.9989\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0291 - accuracy: 0.9993 - val_loss: 0.0233 - val_accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0917 - val_accuracy: 0.9989\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.1295 - val_accuracy: 0.9987\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0143 - accuracy: 0.9997 - val_loss: 0.0598 - val_accuracy: 0.9989\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0203 - accuracy: 0.9997 - val_loss: 0.1188 - val_accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0154 - accuracy: 0.9998 - val_loss: 0.0255 - val_accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0233 - accuracy: 0.9995 - val_loss: 0.0550 - val_accuracy: 0.9983\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0121 - accuracy: 0.9998 - val_loss: 0.0475 - val_accuracy: 0.9985\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0216 - accuracy: 0.9995 - val_loss: 0.1113 - val_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0338 - accuracy: 0.9993 - val_loss: 0.0825 - val_accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0470 - accuracy: 0.9994 - val_loss: 0.0910 - val_accuracy: 0.9981\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0147 - accuracy: 0.9997 - val_loss: 0.1149 - val_accuracy: 0.9985\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0156 - accuracy: 0.9995 - val_loss: 0.0975 - val_accuracy: 0.9983\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0472 - accuracy: 0.9992 - val_loss: 0.1022 - val_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0173 - accuracy: 0.9996 - val_loss: 0.0234 - val_accuracy: 0.9990\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0078 - accuracy: 0.9997 - val_loss: 0.0738 - val_accuracy: 0.9981\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0194 - accuracy: 0.9997 - val_loss: 0.0643 - val_accuracy: 0.9989\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0526 - val_accuracy: 0.9990\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0385 - val_accuracy: 0.9993\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9985\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0253 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9992\n",
      "{'val_loss': [0.02362180846771002, 0.06856406620570592, 0.016064950306235785, 0.01972271155654642, 0.006980657279061688, 0.04045456018492392, 0.06184710856140425, 0.030326410815818876, 0.09347087946865247, 0.09708816081642692, 0.12267408651891071, 0.042863685856332, 0.023287575102236762, 0.09171256110781716, 0.1295166277885437, 0.05983956222258043, 0.11876855854477199, 0.025465712968115915, 0.05499733543755567, 0.04753047652132498, 0.11131907418370929, 0.08245768199364106, 0.09099008321643837, 0.11490459733494456, 0.09748464722541117, 0.10222662846681632, 0.023423383917106872, 0.07377327868728224, 0.0643327749317645, 0.05264485973515547, 0.038536282475258594, 0.038357775314369257, 0.02526182384133177, 0.024426637928911425, 0.02440012847478231, 0.024407796576157298, 0.02441279066738259, 0.02441923845152338, 0.02442522861013328, 0.024431535891813145, 0.02443869760490608, 0.02444532673563615, 0.024451566519876993, 0.024458391663993096, 0.02446729246870334, 0.024474878210320034, 0.024481479396639597, 0.024485738006819267, 0.024491103276521115, 0.02449710295247964, 0.024504515741005196, 0.02451172709419249, 0.024518780551821, 0.02452536357268086, 0.02453430587309456, 0.024546683629117046, 0.024560480770407615, 0.024571739633702128, 0.024581066398237303, 0.02458900431777844, 0.02459603809162142, 0.024602106426324273, 0.02460762050878635, 0.024612632961395882, 0.024617425458673313, 0.02462220677298308, 0.02462667160082035, 0.024630883009575708, 0.024634657147303295, 0.024638288815737854, 0.02464167479950339, 0.02464490440622534, 0.02464798474588644, 0.024650823303563378, 0.024653654992514693, 0.024656374241561113, 0.0246587988591708, 0.024661088628368123, 0.024663367030107977, 0.024665589942761537, 0.02466763506327468, 0.024669694162495856, 0.02467236782817974, 0.024674871975415454, 0.02467740149719973, 0.02467985269564278, 0.024682194547945506, 0.024684465158506034, 0.024686683941408882, 0.024688898779051584, 0.024691078251272258, 0.024693136144208525, 0.024695113386383884, 0.024697133586478338, 0.024698996799291502, 0.02470113608095116, 0.02470331193431797, 0.02470529086529149, 0.02470727819768161, 0.024709175626399297], 'val_accuracy': [0.9992856979370117, 0.9991666674613953, 0.9995238184928894, 0.999404788017273, 0.9997618794441223, 0.9989285469055176, 0.9995238184928894, 0.9991666674613953, 0.9989285469055176, 0.9989285469055176, 0.9989285469055176, 0.9989285469055176, 0.9995238184928894, 0.9989285469055176, 0.9986904859542847, 0.9989285469055176, 0.998452365398407, 0.9995238184928894, 0.9983333349227905, 0.998452365398407, 0.9971428513526917, 0.9992856979370117, 0.9980952143669128, 0.998452365398407, 0.9983333349227905, 0.9983333349227905, 0.9990476369857788, 0.9980952143669128, 0.9989285469055176, 0.9990476369857788, 0.9992856979370117, 0.998452365398407, 0.9992856979370117, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953], 'loss': [0.024754080215884256, 0.026665200571371696, 0.020121641923748008, 0.01524337727167614, 0.02704076702279194, 0.0075057200619810275, 0.006653665008544476, 0.00613983824709517, 0.02161439189180393, 0.016478414788035002, 0.02122106582668553, 0.017709484668957696, 0.02909638648113316, 0.003348501799246888, 0.005039005679533862, 0.014278792849383774, 0.020297541052457818, 0.015388734929206074, 0.02328698485702865, 0.012090611278458384, 0.02162493229844479, 0.03382434976403542, 0.04696904354961589, 0.014733835795357477, 0.015581806299569189, 0.047186668200123495, 0.01732186559227461, 0.007805131470889778, 0.01943588169608005, 0.0034444597036145707, 0.004368635634226445, 0.002310911637697635, 0.003094606257620312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [0.9993155, 0.9992262, 0.9995238, 0.99943453, 0.9994643, 0.9997024, 0.99985117, 0.9998214, 0.99955356, 0.99964285, 0.999375, 0.9994941, 0.99934524, 0.9998214, 0.99985117, 0.9996726, 0.99973214, 0.9997619, 0.9995238, 0.9998214, 0.9994941, 0.99934524, 0.99943453, 0.9997024, 0.9994941, 0.9992262, 0.9995833, 0.9997024, 0.9997024, 0.99985117, 0.9999107, 0.99997026, 0.99994045, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 06:33:53,295 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.024709190158579357, 0.9991666674613953]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 10s 290us/step - loss: 0.0452 - accuracy: 0.9994 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 9s 277us/step - loss: 0.0341 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 9s 282us/step - loss: 0.0321 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9996\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 9s 276us/step - loss: 0.0271 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9996\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 0.0220 - accuracy: 0.9996 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 9s 277us/step - loss: 0.0162 - accuracy: 0.9998 - val_loss: 0.0113 - val_accuracy: 0.9999\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 9s 280us/step - loss: 0.0250 - accuracy: 0.9996 - val_loss: 0.0362 - val_accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 0.0083 - accuracy: 0.9999 - val_loss: 0.0144 - val_accuracy: 0.9993\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 0.0241 - accuracy: 0.9997 - val_loss: 0.0269 - val_accuracy: 0.9993\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 9s 278us/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9998\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 9s 279us/step - loss: 0.0191 - accuracy: 0.9996 - val_loss: 0.0783 - val_accuracy: 0.9985\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 9s 279us/step - loss: 0.0236 - accuracy: 0.9996 - val_loss: 0.0301 - val_accuracy: 0.9989\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 9s 279us/step - loss: 0.0108 - accuracy: 0.9997 - val_loss: 0.0391 - val_accuracy: 0.9993\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 9s 280us/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0808 - val_accuracy: 0.9993\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 10s 298us/step - loss: 0.0067 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9993\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 10s 300us/step - loss: 0.0164 - accuracy: 0.9996 - val_loss: 0.0318 - val_accuracy: 0.9996\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 0.0266 - val_accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 10s 298us/step - loss: 0.0122 - accuracy: 0.9999 - val_loss: 0.0146 - val_accuracy: 0.9996\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 10s 300us/step - loss: 0.0310 - accuracy: 0.9997 - val_loss: 0.0302 - val_accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0111 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9994\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0070 - accuracy: 0.9999 - val_loss: 0.0276 - val_accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0116 - val_accuracy: 0.9995\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 0.9998\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0141 - accuracy: 0.9999 - val_loss: 0.0045 - val_accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 10s 301us/step - loss: 0.0148 - accuracy: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9990\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0099 - accuracy: 0.9997 - val_loss: 0.1957 - val_accuracy: 0.9990\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0238 - accuracy: 0.9996 - val_loss: 0.0497 - val_accuracy: 0.9998\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0530 - val_accuracy: 0.9992\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0111 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9998\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 10s 300us/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0489 - val_accuracy: 0.9996\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0350 - val_accuracy: 0.9998\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0098 - accuracy: 0.9999 - val_loss: 0.1593 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0127 - accuracy: 0.9998 - val_loss: 0.0731 - val_accuracy: 0.9996\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 4.4348e-10 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9994\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0270 - val_accuracy: 0.9999\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9998\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 10s 301us/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0183 - val_accuracy: 0.9998\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: 0.0176 - val_accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0300 - val_accuracy: 0.9998\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9998\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9996\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9996\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9996\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 11s 314us/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0522 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0070 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0297 - accuracy: 0.9997 - val_loss: 0.1545 - val_accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0328 - accuracy: 0.9997 - val_loss: 0.0518 - val_accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 0.0932 - val_accuracy: 0.9989\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0330 - accuracy: 0.9995 - val_loss: 0.0128 - val_accuracy: 0.9993\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0246 - accuracy: 0.9996 - val_loss: 0.0753 - val_accuracy: 0.9993\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.0407 - val_accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0822 - val_accuracy: 0.9996\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0577 - val_accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0780 - val_accuracy: 0.9996\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.1580 - val_accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0275 - accuracy: 0.9996 - val_loss: 0.0780 - val_accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0919 - val_accuracy: 0.9990\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9990\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1385 - val_accuracy: 0.9988\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0104 - accuracy: 0.9996 - val_loss: 0.2084 - val_accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.0448 - val_accuracy: 0.9994\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0091 - accuracy: 0.9998 - val_loss: 6.0852e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 10s 302us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0852e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0982e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1157e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1259e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1346e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1566e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.1332e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0968e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0606e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.0018e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.9406e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.8717e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7870e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6953e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5810e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4455e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2956e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.1226e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.9104e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.6407e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.3303e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.9255e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.3957e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.5314e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0431e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 3.5479e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0271 - val_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 10s 300us/step - loss: 0.0189 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 10s 300us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0081 - accuracy: 0.9998 - val_loss: 0.1201 - val_accuracy: 0.9994\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0105 - accuracy: 0.9999 - val_loss: 0.0287 - val_accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 0.0409 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 1.8531e-04 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9994\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0754 - val_accuracy: 0.9994\n",
      "{'val_loss': [0.009701655170623165, 0.0050949024018787205, 0.006795563584282285, 0.04079196023089545, 0.0, 0.0, 0.011287115187872024, 0.036182651106833615, 0.014368659225957734, 0.026885399307523455, 0.016893654825817065, 0.07826794455448778, 0.03010868622962221, 0.03912669510943997, 0.0808392628033956, 0.07422274049407514, 0.03177499136567349, 0.026559404659838904, 0.014633744355468523, 0.03016105476323338, 0.011664067239145792, 0.027582920619419644, 0.011552970920290265, 0.008788582938058035, 0.00453720109803336, 0.05594571082553427, 0.19571259271530878, 0.04972558896589492, 0.052978872566976254, 0.009932750605401539, 0.04889758890583399, 0.034959251880645754, 0.15928511161179698, 0.07314038957868303, 0.05452804482360859, 0.027002201230538526, 0.01083156554826644, 0.018313691218571918, 0.01759254461243039, 0.030035960335461867, 0.030197282742176736, 0.03055178281806764, 0.03131520955779013, 0.03323663122951984, 0.23264721332561403, 0.022749820734583235, 0.05218248638368787, 0.051419178519752765, 0.1545265159720466, 0.05178545282000587, 0.09320852211151977, 0.012783127585425973, 0.07530829120946606, 0.0407336071559361, 0.08223795577174141, 0.0576746332077753, 0.07795975463730948, 0.1579831801033357, 0.0780036027356982, 0.09185467844917661, 0.09554722978955224, 0.13852755939674136, 0.20836697910513197, 0.04483015953075318, 6.085193849035672e-06, 6.085193849035672e-06, 6.098245669688497e-06, 6.115677810850598e-06, 6.125882445346741e-06, 6.134630668730963e-06, 6.156572185101963e-06, 6.133175144592921e-06, 6.096789702063515e-06, 6.0606224551087335e-06, 6.001750007271767e-06, 5.940620654395648e-06, 5.871692583674476e-06, 5.7869635167576015e-06, 5.6952881138949165e-06, 5.581011286094075e-06, 5.4455450957729705e-06, 5.295550273287864e-06, 5.122612097433635e-06, 4.910372552417574e-06, 4.640728057849975e-06, 4.3302588164806365e-06, 3.925463894293422e-06, 3.3956743954193024e-06, 2.5314374250315483e-06, 1.0431383825128987e-06, 0.0, 0.027082450162796746, 0.009344642495825176, 0.01669018889417029, 0.006903203214917864, 0.1200998557296892, 0.02867782892438949, 0.040944366064463146, 0.036553236416330036, 0.07540472345825817], 'val_accuracy': [0.999404788017273, 0.9998809695243835, 0.9996428489685059, 0.9996428489685059, 1.0, 1.0, 0.9998809695243835, 0.999404788017273, 0.9992856979370117, 0.9992856979370117, 0.9997618794441223, 0.998452365398407, 0.9989285469055176, 0.9992856979370117, 0.9992856979370117, 0.9992856979370117, 0.9996428489685059, 0.9995238184928894, 0.9996428489685059, 0.999404788017273, 0.999404788017273, 0.9996428489685059, 0.9995238184928894, 0.9997618794441223, 0.9996428489685059, 0.9990476369857788, 0.9990476369857788, 0.9997618794441223, 0.9991666674613953, 0.9997618794441223, 0.9996428489685059, 0.9997618794441223, 0.9992856979370117, 0.9996428489685059, 0.999404788017273, 0.9998809695243835, 0.9997618794441223, 0.9997618794441223, 0.9995238184928894, 0.9997618794441223, 0.9997618794441223, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.998452365398407, 0.999404788017273, 0.9991666674613953, 0.9992856979370117, 0.998452365398407, 0.9991666674613953, 0.9989285469055176, 0.9992856979370117, 0.9992856979370117, 0.9992856979370117, 0.9996428489685059, 0.9995238184928894, 0.9996428489685059, 0.9990476369857788, 0.999404788017273, 0.9990476369857788, 0.9990476369857788, 0.9988095164299011, 0.9988095164299011, 0.999404788017273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992856979370117, 0.9995238184928894, 0.9998809695243835, 0.9997618794441223, 0.999404788017273, 0.9996428489685059, 0.9996428489685059, 0.999404788017273, 0.999404788017273], 'loss': [0.04517927960442664, 0.034083656884419694, 0.032113613295604505, 0.0271204195840818, 0.021999388752272534, 0.006966008278264087, 0.016217824500040723, 0.02498158467475697, 0.00834707069964636, 0.02407375054598951, 0.004996819960547253, 0.019094469323891857, 0.02357845674753618, 0.010816158047728529, 0.00493935091772586, 0.006692316273138078, 0.01644614589858455, 0.00549076531237605, 0.01220473608090764, 0.030965757453364814, 0.011119614040904014, 0.00703189617009706, 0.004539916467281489, 0.008234758361290158, 0.014133590665899516, 0.014814854034698274, 0.009850748465768798, 0.02376679045535033, 0.008399501007766258, 0.011085913046484902, 0.004821549119210284, 0.005457523124558585, 0.009762754897986139, 0.012735383642519488, 4.43484033623471e-10, 0.002364857771566935, 0.007027380494676468, 0.005031359918833778, 0.00910793815267555, 0.003067498490348252, 0.0, 0.0, 0.0, 0.0, 0.0022797724480430287, 0.004491736069321632, 0.004795099894205729, 0.0069844200568539745, 0.02967264242075078, 0.03278466695385305, 0.008780429199251078, 0.0330164710119117, 0.02462568011311966, 0.009009327427710602, 0.005229063488188244, 0.004899903093242929, 0.003896775603992962, 0.005534837524617485, 0.027477509152321486, 0.0017610688068660759, 0.0, 0.003995745753247639, 0.010359479914675484, 0.010202780923549466, 0.009124786719801785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5478953108736276e-12, 0.006392239341990674, 0.018862129558194198, 0.001693227628600719, 0.0012971114325583109, 0.008123891142950881, 0.010470034562528045, 0.007304873037196138, 0.00018531166703408664, 0.0043274180342753625], 'accuracy': [0.999375, 0.9994643, 0.99964285, 0.9997024, 0.99964285, 0.99973214, 0.9998214, 0.9995833, 0.99985117, 0.99973214, 0.99985117, 0.99964285, 0.99955356, 0.9997024, 0.9998214, 0.9999107, 0.99964285, 0.99985117, 0.99985117, 0.99973214, 0.99985117, 0.99985117, 0.99988097, 0.99988097, 0.99988097, 0.9997024, 0.9996726, 0.9996131, 0.9997917, 0.99985117, 0.99988097, 0.9998214, 0.99988097, 0.9997917, 1.0, 0.9999107, 0.9997917, 0.99988097, 0.9999107, 0.99994045, 1.0, 1.0, 1.0, 1.0, 0.99997026, 0.9999107, 0.99994045, 0.99985117, 0.9996726, 0.9997024, 0.99994045, 0.9994941, 0.99955356, 0.99985117, 0.99994045, 0.99994045, 0.9999107, 0.9997917, 0.99955356, 0.99988097, 1.0, 0.99994045, 0.99964285, 0.9998214, 0.9997917, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997917, 0.9997917, 0.99997026, 0.99994045, 0.9998214, 0.99985117, 0.9998214, 0.99997026, 0.99994045]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 06:50:42,693 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07540472345825817, 0.999404788017273]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0216 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9999\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0289 - accuracy: 0.9998 - val_loss: 5.5347e-10 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0135 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9999\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0066 - accuracy: 0.9999 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0188 - accuracy: 0.9999 - val_loss: 0.0121 - val_accuracy: 0.9999\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0163 - accuracy: 0.9995 - val_loss: 4.1439e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0169 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0194 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 8.0694e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9998\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0194 - accuracy: 0.9999 - val_loss: 0.0383 - val_accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0184 - accuracy: 0.9998 - val_loss: 0.0519 - val_accuracy: 0.9996\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0179 - accuracy: 0.9998 - val_loss: 0.0172 - val_accuracy: 0.9996\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0144 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 0.9998\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9998\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0199 - val_accuracy: 0.9996\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0126 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9998\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9999\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0326 - accuracy: 0.9997 - val_loss: 0.0231 - val_accuracy: 0.9996\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0106 - accuracy: 0.9998 - val_loss: 0.0480 - val_accuracy: 0.9995\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0196 - accuracy: 0.9998 - val_loss: 2.2850e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 1.5666e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9999\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0186 - accuracy: 0.9998 - val_loss: 0.0028 - val_accuracy: 0.9999\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0080 - accuracy: 0.9998 - val_loss: 0.0369 - val_accuracy: 0.9995\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0101 - accuracy: 0.9999 - val_loss: 0.0303 - val_accuracy: 0.9998\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 1.0644e-11 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 10s 299us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9996\n",
      "{'val_loss': [0.005187029157366072, 5.534704022076247e-10, 0.008236687978108724, 0.0, 0.005107549031575521, 0.012116473969959077, 4.1438696436151595e-09, 0.0, 0.0, 0.0, 8.069436132375683e-08, 0.011769409193879083, 0.038302953232610064, 0.051885326615135584, 0.017214229460195855, 0.023545887766362978, 0.01224808190442023, 0.019940011160714286, 0.009829143768243911, 0.008220922373362728, 0.023128815491994224, 0.04802846999395461, 2.2849951471601215e-05, 0.020353422817729606, 0.0028097604829374523, 0.03690536862327939, 0.030328908003866673, 0.03947701482543012, 0.03947761427785757, 0.03947817378098123, 0.03947871147164343, 0.03947930002493584, 0.039479859513868135, 0.03948051709501583, 0.03948106933204946, 0.039481636087071774, 0.03948219557600407, 0.03948279866147654, 0.03948335451736382, 0.039483932185712334, 0.03948452437204976, 0.03948506569575697, 0.03948565424904939, 0.0394861701414415, 0.0394867405437002, 0.03948732183090258, 0.03948785588851977, 0.03948850620357743, 0.03948908022468978, 0.03948956706691292, 0.03949009022539507, 0.039490646081282346, 0.03949119103803458, 0.03949172146260675, 0.03949228823182044, 0.039492764160717383, 0.03949334181487475, 0.03949387587249194, 0.039494395397929066, 0.039495002116446555, 0.03949553255520987, 0.03949603754846694, 0.039496582505219174, 0.03949711292979135, 0.03949765062045355, 0.03949817742617207, 0.03949878051164454, 0.03949922374313636, 0.03949979049815868, 0.03950034635404596, 0.0395008331962691, 0.03950139268520139, 0.039501868614098344, 0.03950242810303063, 0.03950297305978286, 0.03950349258521999, 0.0395039903265784, 0.03950450258592549, 0.039505069340947815, 0.03950560339856501, 0.03950612292400213, 0.03950658433491017, 0.03950714382384246, 0.039507612486649385, 0.03950816834253666, 0.03950862973925355, 0.03950915291192706, 0.03950967970345422, 0.039510199228891346, 0.03951068242387832, 0.03951117288495533, 0.03951166334603234, 0.039512150188255483, 0.03951268061282766, 0.03951314200954455, 0.039513697865431824, 0.039514228290004, 0.039514646104372074, 0.039515161996764185, 0.03951562702652609], 'val_accuracy': [0.9998809695243835, 1.0, 0.9998809695243835, 1.0, 0.9998809695243835, 0.9998809695243835, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997618794441223, 0.9995238184928894, 0.9996428489685059, 0.9996428489685059, 0.9997618794441223, 0.9997618794441223, 0.9996428489685059, 0.9997618794441223, 0.9998809695243835, 0.9996428489685059, 0.9995238184928894, 1.0, 0.9998809695243835, 0.9998809695243835, 0.9995238184928894, 0.9997618794441223, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059, 0.9996428489685059], 'loss': [0.021565546563217595, 0.028903546132601366, 0.013510599981950453, 0.004241352280676524, 0.00656200195318282, 0.018780629351122548, 0.01630547542009091, 0.016860253012883256, 0.0012538238631705522, 0.019356369974132696, 0.0059139056361853124, 0.0015506408362006402, 0.019407510895112605, 0.01836723955413606, 0.017885838555053924, 0.014397034896700064, 0.007976040960695086, 0.005235971562894216, 0.012578135216939554, 0.001021401548669451, 0.0325720705304827, 0.010608589227000814, 0.019598201849388534, 0.00015666037084006976, 0.018615445332300928, 0.007995492830162957, 0.01008478764976774, 1.0643684875265622e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [0.99964285, 0.9997619, 0.9998214, 0.9999107, 0.99985117, 0.9999107, 0.9995238, 0.9996726, 0.99994045, 0.9996726, 0.9997917, 0.9999107, 0.99988097, 0.9997619, 0.9998214, 0.9997917, 0.99997026, 0.9999107, 0.99985117, 0.99997026, 0.9997024, 0.9998214, 0.9998214, 0.99997026, 0.9997619, 0.9998214, 0.99985117, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 07:07:54,654 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03951562702652609, 0.9996428489685059]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0151 - accuracy: 0.9999 - val_loss: 0.0412 - val_accuracy: 0.9996\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0114 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 5.6766e-11 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 10s 303us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 11s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 11s 317us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 11s 324us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 11s 323us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 11s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 11s 316us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 10s 304us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4192e-11 - val_accuracy: 1.0000\n",
      "{'val_loss': [0.0, 0.001296650455111549, 0.041166411950470036, 0.002317446754092262, 0.0, 5.6766314823367536e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11, 1.419158124349451e-11], 'val_accuracy': [1.0, 0.9998809695243835, 0.9996428489685059, 0.9998809695243835, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'loss': [0.008689069314857209, 0.00402079611247267, 0.015129478765383028, 0.011405458634801656, 0.0030534997156688145, 0.0032344738784290494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [0.9999107, 0.99985117, 0.99985117, 0.99985117, 0.9999107, 0.9999107, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 07:25:07,035 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.419158124349451e-11, 1.0]\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 3.5479e-12 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 10s 305us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 10s 312us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 10s 307us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 11s 315us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 11s 313us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 11s 328us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 10s 308us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 10s 310us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "{'val_loss': [0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625, 0.00540435791015625], 'val_accuracy': [0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835, 0.9998809695243835], 'loss': [3.5478953108736276e-12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 07:42:24,842 : INFO : CV accuracy: 0.99962, std: ±0.00030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00540435791015625, 0.9998809695243835]\n",
      "CPU times: user 4h 26min 44s, sys: 2h 58min 49s, total: 7h 25min 34s\n",
      "Wall time: 8h 26min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [5, 12, 50, 100], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    predictions = gcv.best_estimator_.predict(x)\n",
    "    csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "        val_accuracies = np.array([])\n",
    "        for train_index, val_index in skf.split(X, y_sparse):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index]) \n",
    "            best_grid_search_model = build_model(layers_candidates[gcv.best_params_['layers_candidates_key']])\n",
    "            history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "            print(history.history)\n",
    "            scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "            print(scores)\n",
    "            val_accuracies = np.append(val_accuracies, scores[1])\n",
    "        log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))\n",
    "    \n",
    "if args.run_grid_search:\n",
    "    grid_search()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "}\n",
    "\n",
    "def test():\n",
    "    return build_model(layers_candidates[1])\n",
    "\n",
    "keras_classifier_best = KerasClassifier(test)\n",
    "cross_val_score_sklearn(keras_classifier_best, X, y_sparse, fit_params={'epochs':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Results\n",
    "\n",
    "input:\n",
    "{'epochs': [2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "results:\n",
    "\n",
    "2020-04-26 15:34:19,980 : INFO : Best params: {'epochs': 10, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-26 15:34:19,982 : INFO : Best CV score: 0.9835238095238095\n",
    "2020-04-26 15:34:19,983 : INFO : Best std: 0.001621147098147533   \n",
    "\n",
    "---\n",
    "input:\n",
    " param_grid={'epochs': [10, 20, 30], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy'}\n",
    "\n",
    "\n",
    "2020-04-27 23:44:34,829 : INFO : Best params: {'epochs': 30, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-27 23:44:34,829 : INFO : Best CV score: 0.9846190476190475\n",
    "2020-04-27 23:44:34,830 : INFO : Best std: 0.002779092659317115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | 50 epochs | 0.98657 | 0.98790 ±0.00069 |\n",
    "| Early stop (val_loss) | 9 epochs | 0.98932 | 0.98948 ±0.00059 |\n",
    "| Early stop (val_accuracy) | 14 epochs | 0.99003 | 0.99017 ±0.00037 |\n",
    "| Basic grid search (accuracy) | 100 epochs out of 3, 15, 50, 100; layers: 2 | 0.98932 | 0.98864 ±0.00154 |\n",
    "| Basic grid search (neg_log_loss) | 2 epochs, layers: 2 | 0.98125 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  |\n",
    "|---|---|---|\n",
    "| Baseline | No validation, 200 epochs  | 0.99157, 0.98857 |\n",
    "| Baseline | Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_loss  | 0.98628 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_accuracy  | 0.98957 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_loss  | 0.98700 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_accuracy  | 0.98857 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=5  | 0.98200 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=12  | 0.98142 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the most confusing predicitons\n",
    "def analyse_confusing_predictions(predictions=predictions, n_confused=10, labels=None):\n",
    "    log.info(predictions.shape)\n",
    "    probabilities_sparse = np.max(predictions, axis=1)\n",
    "    min_prob = np.min(probabilities_spar§se)\n",
    "    min_index = np.argmin(probabilities_sparse, axis=0)\n",
    "    log.info('The most likely numbers for the less confident prediction: %s, probabilities: %s', \n",
    "             np.argpartition(predictions[min_index], -3)[-3:], \n",
    "             predictions[min_index][np.argpartition(predictions[min_index], -3)[-3:]])\n",
    "    \n",
    "    most_confused_predictions_indices = np.argpartition(probabilities_sparse, n_confused)[:n_confused]\n",
    "    log.info('Most confused indices: %s', most_confused_predictions_indices)\n",
    "    most_confused_probabilities = predictions[most_confused_predictions_indices]\n",
    "    likely_numbers_most_confused_probabilities = np.argpartition(most_confused_probabilities, -3, axis=1)[:, -3:]\n",
    "\n",
    "    probabilities_likely_numbers_most_confused_probabilities = np.empty(likely_numbers_most_confused_probabilities.shape)\n",
    "    for i, row in enumerate(most_confused_probabilities):\n",
    "        probabilities_likely_numbers_most_confused_probabilities[i] = row[likely_numbers_most_confused_probabilities[i]]\n",
    "\n",
    "    log.info('The most likely numbers for the less confident predictions: \\n%s, \\nprobabilities: \\n%s', \n",
    "            likely_numbers_most_confused_probabilities,\n",
    "            np.around(probabilities_likely_numbers_most_confused_probabilities, decimals=2))\n",
    "\n",
    "    if labels is not None:\n",
    "        for most_confusing_predictions_index in most_confused_predictions_indices:\n",
    "            draw_number(labels[most_confusing_predictions_index], \n",
    "                        args.raw_train.iloc[most_confusing_predictions_index, 1:].to_numpy().reshape(28, 28),\n",
    "                       (0.5, 0.5))\n",
    "\n",
    "analyse_confusing_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
