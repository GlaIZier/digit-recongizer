{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo stop the numbers to vary from time to time\n",
    "# Todo add K-fold\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo implement augmentation\n",
    "# Todo try to get a pretrained cnn\n",
    "# Todo early stop\n",
    "# Todo print the numbers in square like in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = 1337"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reproducibility\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(_seed)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(_seed)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.model_name = 'deep-learning-keras-model.hdf5'\n",
    "args.seed=_seed\n",
    "\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "\n",
    "args.run_baseline = False\n",
    "args.run_early_stop = False\n",
    "args.run_grid_search = True\n",
    "args.run_kfold_validation = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(label, pixels_2d, size_inches=None):\n",
    "    title = args.raw_train.iloc[random_row, 0]\n",
    "    fig, ax = plt.subplots()\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    ax.set_title(label)\n",
    "    imgplot = ax.imshow(pixels_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_sparse = args.labels.to_numpy()\n",
    "x = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)\n",
    "\n",
    "log.info('X.shape: %s', repr(X.shape))\n",
    "log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('y.shape: %s', repr(y.shape))\n",
    "log.info('y[0], %s', y[0])\n",
    "log.info('type of target y: %s', repr(sklearn.utils.multiclass.type_of_target(y)))\n",
    "\n",
    "log.info('y_sparse.shape: %s', repr(y_sparse.shape))\n",
    "log.info('y_sparse: %s', repr(y_sparse))\n",
    "log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('type of target y_sparse: %s', repr(sklearn.utils.multiclass.type_of_target(y_sparse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_sparse_predictions(predictions_sparse, filename):\n",
    "    image_ids = np.arange(1, len(predictions_sparse) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_sparse})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_sparse = np.argmax(predictions, axis=1)\n",
    "    csv_sparse_predictions(predictions_sparse, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cross_val_score_sklearn(sklearn_model, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params=None):\n",
    "    cvs = cross_val_score(sklearn_model, X, y, cv=n_splits, n_jobs=args.n_jobs, fit_params=fit_params)\n",
    "    log.info('CV mean accuracy: %0.5f. std: %0.5f', cvs.mean(), cvs.std())\n",
    "    return cvs\n",
    "    \n",
    "def cross_val_score_keras(keras_model_builder, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params={'epochs': args.epochs}):\n",
    "    keras_classifier = KerasClassifier(keras_model_builder)\n",
    "    return cross_val_score_sklearn(keras_classifier, X, y, scoring=scoring, n_splits=n_splits, fit_params=fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "def build_model(layers_list, optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy', metrics_tuple=('accuracy')):\n",
    "    model = models.Sequential(layers_list)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics_tuple])\n",
    "    log.info(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "\n",
    "def build_baseline_model_sparse():\n",
    "    layers_list = [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "    return build_model(layers_list=layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def baseline():\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1)\n",
    "    plot_history(history)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_baseline_predictions.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse)\n",
    "    \n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def early_stop(monitor='val_loss'):\n",
    "    # val_loss\n",
    "    # val_accuracy\n",
    "    early_stopping = EarlyStopping(monitor=monitor, patience=10, mode='auto', verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor=monitor, mode='auto', verbose=1)\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='auto')\n",
    "\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])\n",
    "\n",
    "    plot_history(history)\n",
    "    model.load_weights(args.model_name)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_early_stop_predictions.csv')\n",
    "    \n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse, fit_params={'validation_split': args.val_fraction, 'epochs': args.epochs, 'batch_size': 64, 'callbacks': [early_stopping, model_checkpoint, reduce_lr_on_plateau]})\n",
    "\n",
    "if args.run_early_stop:\n",
    "    early_stop(monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic grid search to choose the best architecture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from keras import backend\n",
    "\n",
    "def grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [25], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    predictions = gcv.best_estimator_.predict(x)\n",
    "    csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    return gcv, layers_candidates[gcv.best_params_['layers_candidates_key']]\n",
    "    \n",
    "if args.run_grid_search:\n",
    "    gcv, layers_list = grid_search()\n",
    "    if args.run_kfold_validation:\n",
    "        skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "        val_accuracies = np.array([])\n",
    "        for train_index, val_index in skf.split(X, y_sparse):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index])\n",
    "            # Clearing the NN.\n",
    "            best_grid_search_model = None\n",
    "            backend.clear_session()\n",
    "            best_grid_search_model = build_model(layers_list)\n",
    "            history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "            scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "            log.info('Iteration validation score: %s', repr(scores))\n",
    "            val_accuracies = np.append(val_accuracies, scores[1])\n",
    "        log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from keras import backend\n",
    "\n",
    "def grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [25], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse, refit=False)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "#     predictions = gcv.best_estimator_.predict(x)\n",
    "#     csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    return gcv, layers_candidates[gcv.best_params_['layers_candidates_key']]\n",
    "    \n",
    "if args.run_grid_search:\n",
    "    gcv, layers_list = grid_search()\n",
    "    if args.run_kfold_validation:\n",
    "        skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "        val_accuracies = np.array([])\n",
    "        for train_index, val_index in skf.split(X, y_sparse):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index])\n",
    "            # Clearing the NN.\n",
    "            best_grid_search_model = None\n",
    "            backend.clear_session()\n",
    "            best_grid_search_model = build_model(layers_list)\n",
    "            history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "            scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "            log.info('Iteration validation score: %s', repr(scores))\n",
    "            val_accuracies = np.append(val_accuracies, scores[1])\n",
    "        log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from keras import backend\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def get_layers_candidates_grid_search(): \n",
    "    return {\n",
    "    1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "\n",
    "def get_build_model_grid_search(recreate=False):\n",
    "    \n",
    "    tmp_model_dir = Path('/tmp/cnn_deep_learning_keras_models')\n",
    "    if recreate:\n",
    "        shutil.rmtree(tmp_model_dir, ignore_errors=True)\n",
    "    tmp_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        tmp_model_path = tmp_model_dir/'{}.h5'.format(layers_candidates_key)\n",
    "        print(tmp_model_path)\n",
    "        if tmp_model_path.exists():\n",
    "            return models.load_model(tmp_model_path)\n",
    "#         else: \n",
    "#             new_model = build_model(get_layers_candidates_grid_search()[layers_candidates_key])\n",
    "#             new_model.save(tmp_model_path)\n",
    "#             return new_model\n",
    "#     return _build_model_grid_search\n",
    "\n",
    "def grid_search():\n",
    "    build_model_grid_search = get_build_model_grid_search(recreate=True)\n",
    "    \n",
    "    keras_classifier = KerasClassifier(build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [1], \n",
    "                                     'layers_candidates_key': list(get_layers_candidates_grid_search().keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    predictions = gcv.best_estimator_.predict(x)\n",
    "    csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    return gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "if args.run_grid_search:\n",
    "    gcv = grid_search()\n",
    "    if args.run_kfold_validation:\n",
    "        skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "        val_accuracies = np.array([])\n",
    "        build_model_grid_search = get_build_model_grid_search()\n",
    "        for train_index, val_index in skf.split(X, y_sparse):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index])\n",
    "            best_grid_search_model = build_model_grid_search(gcv.best_params_['layers_candidates_key'])\n",
    "            history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "            scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "            log.info('Iteration validation score: %s', repr(scores))\n",
    "            val_accuracies = np.append(val_accuracies, scores[1])\n",
    "        log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_dir = Path('/tmp/cnn_deep_learning_keras_models')\n",
    "shutil.rmtree(tmp_model_dir, ignore_errors=True)\n",
    "tmp_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tmp_model_path = tmp_model_dir/'{}.h5'.format(1)\n",
    "# print(tmp_model_path)\n",
    "# if tmp_model_path.exists():\n",
    "#     return models.load_model(tmp_model_path)\n",
    "# else: \n",
    "new_model = build_model(get_layers_candidates_grid_search()[1])\n",
    "new_model.save(tmp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "\n",
    "#         4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [25], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    predictions = gcv.best_estimator_.predict(x)\n",
    "    csv_sparse_predictions(predictions, 'cnn_basic_grid_search.csv')\n",
    "    return gcv, layers_candidates[gcv.best_params_['layers_candidates_key']]\n",
    "\n",
    "layers_list = None\n",
    "gcv = None\n",
    "if args.run_grid_search:\n",
    "    gcv, layers_list = grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.run_grid_search and args.run_kfold_validation:\n",
    "    tmp_model_path = Path('/tmp/model.h5')\n",
    "    if tmp_model_path.exists():\n",
    "        tmp_model_path.unlink() \n",
    "    skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "    val_accuracies = np.array([])\n",
    "    for train_index, val_index in skf.split(X, y_sparse):\n",
    "        if tmp_model_path.exists():\n",
    "            best_grid_search_model = models.load_model(tmp_model_path)\n",
    "        else: \n",
    "            best_grid_search_model = build_model(layers_list)\n",
    "            best_grid_search_model.save(tmp_model_path)\n",
    "        history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "        scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "        log.info('Iteration validation score: %s', repr(scores))\n",
    "        val_accuracies = np.append(val_accuracies, scores[1])\n",
    "    log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp new\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from pathlib import Path\n",
    "from keras import backend\n",
    "\n",
    "_layers_list = [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')]\n",
    "_epochs = 25\n",
    "\n",
    "if args.run_kfold_validation:\n",
    "    tmp_model_path = Path('/tmp/model.h5')\n",
    "    if tmp_model_path.exists():\n",
    "        tmp_model_path.unlink() \n",
    "    skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "    val_accuracies = np.array([])\n",
    "    for train_index, val_index in skf.split(X, y_sparse):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index])\n",
    "        # Clearing the NN.\n",
    "        best_grid_search_model = None\n",
    "        backend.clear_session()\n",
    "        if tmp_model_path.exists():\n",
    "            best_grid_search_model = models.load_model(tmp_model_path)\n",
    "        else: \n",
    "            best_grid_search_model = build_model(_layers_list)\n",
    "            best_grid_search_model.save(tmp_model_path)\n",
    "        history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=_epochs, batch_size=64, verbose=1)\n",
    "        scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "        log.info('Iteration validation score: %s', repr(scores))\n",
    "        val_accuracies = np.append(val_accuracies, scores[1])\n",
    "    log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l = [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=args.seed)\n",
    "val_accuracies = np.array([])\n",
    "for train_index, val_index in skf.split(X[:], y_sparse[:]):\n",
    "#           , validation_data=(X[val_index], y_sparse[val_index]) \n",
    "    print(train_index)\n",
    "    print(val_index)\n",
    "    print(y_sparse[train_index])\n",
    "    best_grid_search_model = build_model(l)\n",
    "    history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=5, batch_size=64, verbose=1)\n",
    "    scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "    print(scores)\n",
    "    val_accuracies = np.append(val_accuracies, scores[1])\n",
    "log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "}\n",
    "\n",
    "def test():\n",
    "    return build_model(layers_candidates[1])\n",
    "\n",
    "keras_classifier_best = KerasClassifier(test)\n",
    "cross_val_score_sklearn(keras_classifier_best, X, y_sparse, fit_params={'epochs':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Results\n",
    "\n",
    "input:\n",
    "{'epochs': [2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "results:\n",
    "\n",
    "2020-04-26 15:34:19,980 : INFO : Best params: {'epochs': 10, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-26 15:34:19,982 : INFO : Best CV score: 0.9835238095238095\n",
    "2020-04-26 15:34:19,983 : INFO : Best std: 0.001621147098147533   \n",
    "\n",
    "---\n",
    "input:\n",
    " param_grid={'epochs': [10, 20, 30], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy'}\n",
    "\n",
    "\n",
    "2020-04-27 23:44:34,829 : INFO : Best params: {'epochs': 30, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-27 23:44:34,829 : INFO : Best CV score: 0.9846190476190475\n",
    "2020-04-27 23:44:34,830 : INFO : Best std: 0.002779092659317115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | 50 epochs | 0.98657 | 0.98790 ±0.00069 |\n",
    "| Early stop (val_loss) | 9 epochs | 0.98932 | 0.98948 ±0.00059 |\n",
    "| Early stop (val_accuracy) | 14 epochs | 0.99003 | 0.99017 ±0.00037 |\n",
    "| Basic grid search (accuracy) | 100 epochs out of 3, 15, 50, 100; layers: 2 | 0.98932 | 0.98864 ±0.00154 |\n",
    "| Basic grid search (neg_log_loss) | 2 epochs, layers: 2 | 0.98125 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  |\n",
    "|---|---|---|\n",
    "| Baseline | No validation, 200 epochs  | 0.99157, 0.98857 |\n",
    "| Baseline | Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_loss  | 0.98628 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_accuracy  | 0.98957 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_loss  | 0.98700 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_accuracy  | 0.98857 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=5  | 0.98200 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=12  | 0.98142 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the most confusing predicitons\n",
    "def analyse_confusing_predictions(predictions=predictions, n_confused=10, labels=None):\n",
    "    log.info(predictions.shape)\n",
    "    probabilities_sparse = np.max(predictions, axis=1)\n",
    "    min_prob = np.min(probabilities_spar§se)\n",
    "    min_index = np.argmin(probabilities_sparse, axis=0)\n",
    "    log.info('The most likely numbers for the less confident prediction: %s, probabilities: %s', \n",
    "             np.argpartition(predictions[min_index], -3)[-3:], \n",
    "             predictions[min_index][np.argpartition(predictions[min_index], -3)[-3:]])\n",
    "    \n",
    "    most_confused_predictions_indices = np.argpartition(probabilities_sparse, n_confused)[:n_confused]\n",
    "    log.info('Most confused indices: %s', most_confused_predictions_indices)\n",
    "    most_confused_probabilities = predictions[most_confused_predictions_indices]\n",
    "    likely_numbers_most_confused_probabilities = np.argpartition(most_confused_probabilities, -3, axis=1)[:, -3:]\n",
    "\n",
    "    probabilities_likely_numbers_most_confused_probabilities = np.empty(likely_numbers_most_confused_probabilities.shape)\n",
    "    for i, row in enumerate(most_confused_probabilities):\n",
    "        probabilities_likely_numbers_most_confused_probabilities[i] = row[likely_numbers_most_confused_probabilities[i]]\n",
    "\n",
    "    log.info('The most likely numbers for the less confident predictions: \\n%s, \\nprobabilities: \\n%s', \n",
    "            likely_numbers_most_confused_probabilities,\n",
    "            np.around(probabilities_likely_numbers_most_confused_probabilities, decimals=2))\n",
    "\n",
    "    if labels is not None:\n",
    "        for most_confusing_predictions_index in most_confused_predictions_indices:\n",
    "            draw_number(labels[most_confusing_predictions_index], \n",
    "                        args.raw_train.iloc[most_confusing_predictions_index, 1:].to_numpy().reshape(28, 28),\n",
    "                       (0.5, 0.5))\n",
    "\n",
    "analyse_confusing_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
