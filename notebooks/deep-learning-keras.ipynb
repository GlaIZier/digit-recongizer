{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo choose a model with the best validation accuracy\n",
    "# Todo add K-fold\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo implement augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "args.n_splits = 5\n",
    "args.n_jobs = 3\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 200\n",
    "args.model_name = 'model.hdf5'\n",
    "\n",
    "args.X = args.raw_train.iloc[:, 1:].copy()\n",
    "args.y = args.raw_train['label'].copy()\n",
    "args.x = args.raw_test.copy()\n",
    "\n",
    "args.run_cnn = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1) \n",
    "title = args.raw_train.iloc[random_row, 0]\n",
    "plt.title(title)\n",
    "imgplot = plt.imshow(args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1) \n",
    "title = args.raw_train.iloc[random_row, 0]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(0.5, 0.5)\n",
    "ax.set_title(title)\n",
    "imgplot = ax.imshow(args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = args.X.to_numpy().reshape(args.X.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.y, prefix='label').to_numpy()\n",
    "x = args.x.to_numpy().reshape(args.x.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, x, build_classifier, parameters, splits=args.n_splits, n_jobs=args.n_jobs):\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    classifier = build_classifier()\n",
    "    gcv = GridSearchCV(classifier, parameters, n_jobs=n_jobs, cv=skf, verbose=5)\n",
    "    gcv.fit(X, y)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    classifier = build_classifier(gcv.best_params_)\n",
    "    classifier.fit(X, y)\n",
    "    predictions = classifier.predict(x)\n",
    "    return gcv.best_params_, gcv.best_score_, predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_predictions(predictions, filename):\n",
    "    image_ids = np.arange(1, len(predictions) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers \n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/200\n",
      "37800/37800 [==============================] - 51s 1ms/step - loss: 0.5309 - accuracy: 0.9115 - val_loss: 0.1083 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96857, saving model to model.hdf5\n",
      "Epoch 2/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 0.0758 - accuracy: 0.9781 - val_loss: 0.0866 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96857 to 0.97500, saving model to model.hdf5\n",
      "Epoch 3/200\n",
      "37800/37800 [==============================] - 49s 1ms/step - loss: 0.0533 - accuracy: 0.9851 - val_loss: 0.0438 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97500 to 0.98810, saving model to model.hdf5\n",
      "Epoch 4/200\n",
      "37800/37800 [==============================] - 49s 1ms/step - loss: 0.0401 - accuracy: 0.9886 - val_loss: 0.0515 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.98810\n",
      "Epoch 5/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.0512 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98810\n",
      "Epoch 6/200\n",
      "37800/37800 [==============================] - 50s 1ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.0610 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98810\n",
      "Epoch 7/200\n",
      "37800/37800 [==============================] - 48s 1ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.0682 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98810\n",
      "Epoch 8/200\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0943 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98810\n",
      "Epoch 9/200\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.0501 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.98810 to 0.99024, saving model to model.hdf5\n",
      "Epoch 10/200\n",
      "37800/37800 [==============================] - 36s 953us/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 0.0753 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99024\n",
      "Epoch 11/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 0.0238 - accuracy: 0.9946 - val_loss: 0.0888 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99024\n",
      "Epoch 12/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.1013 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99024\n",
      "Epoch 13/200\n",
      "37800/37800 [==============================] - 36s 942us/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 0.0942 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99024\n",
      "Epoch 14/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 0.0233 - accuracy: 0.9954 - val_loss: 0.1005 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99024\n",
      "Epoch 15/200\n",
      "37800/37800 [==============================] - 44s 1ms/step - loss: 0.0226 - accuracy: 0.9959 - val_loss: 0.1303 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99024\n",
      "Epoch 16/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 0.0215 - accuracy: 0.9962 - val_loss: 0.1131 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99024\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0862 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.99024 to 0.99190, saving model to model.hdf5\n",
      "Epoch 18/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 4.0462e-04 - accuracy: 0.9999 - val_loss: 0.0861 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99190\n",
      "Epoch 19/200\n",
      "37800/37800 [==============================] - 48s 1ms/step - loss: 5.4745e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99190\n",
      "Epoch 20/200\n",
      "37800/37800 [==============================] - 49s 1ms/step - loss: 8.1431e-06 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.99190 to 0.99238, saving model to model.hdf5\n",
      "Epoch 21/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 2.4943e-06 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.99238 to 0.99262, saving model to model.hdf5\n",
      "Epoch 22/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 1.2757e-07 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9936\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.99262 to 0.99357, saving model to model.hdf5\n",
      "Epoch 23/200\n",
      "37800/37800 [==============================] - 46s 1ms/step - loss: 2.7944e-08 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99357\n",
      "Epoch 24/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 3.6456e-09 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99357\n",
      "Epoch 25/200\n",
      "37800/37800 [==============================] - 47s 1ms/step - loss: 1.0786e-09 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99357\n",
      "Epoch 26/200\n",
      "37800/37800 [==============================] - 48s 1ms/step - loss: 3.0591e-10 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.99357\n",
      "Epoch 27/200\n",
      "37800/37800 [==============================] - 48s 1ms/step - loss: 1.8291e-10 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.99357\n",
      "Epoch 28/200\n",
      "37800/37800 [==============================] - 46s 1ms/step - loss: 1.1669e-10 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.99357\n",
      "Epoch 29/200\n",
      "37800/37800 [==============================] - 35s 922us/step - loss: 1.0407e-10 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 30/200\n",
      "37800/37800 [==============================] - 35s 938us/step - loss: 6.9381e-11 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.99357\n",
      "Epoch 31/200\n",
      "37800/37800 [==============================] - 35s 931us/step - loss: 6.6227e-11 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.99357\n",
      "Epoch 32/200\n",
      "37800/37800 [==============================] - 35s 926us/step - loss: 6.3074e-11 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.99357\n",
      "Epoch 33/200\n",
      "37800/37800 [==============================] - 35s 920us/step - loss: 6.6227e-11 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.99357\n",
      "Epoch 34/200\n",
      "37800/37800 [==============================] - 35s 935us/step - loss: 5.9920e-11 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.99357\n",
      "Epoch 35/200\n",
      "37800/37800 [==============================] - 35s 931us/step - loss: 5.6766e-11 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.99357\n",
      "Epoch 36/200\n",
      "37800/37800 [==============================] - 35s 926us/step - loss: 5.9920e-11 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 37/200\n",
      "37800/37800 [==============================] - 36s 943us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.99357\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 35s 927us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.99357\n",
      "Epoch 39/200\n",
      "37800/37800 [==============================] - 35s 924us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.99357\n",
      "Epoch 40/200\n",
      "37800/37800 [==============================] - 35s 929us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.99357\n",
      "Epoch 41/200\n",
      "37800/37800 [==============================] - 35s 924us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.99357\n",
      "Epoch 42/200\n",
      "37800/37800 [==============================] - 35s 939us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.99357\n",
      "Epoch 43/200\n",
      "37800/37800 [==============================] - 35s 926us/step - loss: 5.3613e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 44/200\n",
      "37800/37800 [==============================] - 35s 923us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.99357\n",
      "Epoch 45/200\n",
      "37800/37800 [==============================] - 35s 921us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.99357\n",
      "Epoch 46/200\n",
      "37800/37800 [==============================] - 35s 921us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.99357\n",
      "Epoch 47/200\n",
      "37800/37800 [==============================] - 35s 925us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.99357\n",
      "Epoch 48/200\n",
      "37800/37800 [==============================] - 35s 924us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.99357\n",
      "Epoch 49/200\n",
      "37800/37800 [==============================] - 38s 999us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.99357\n",
      "Epoch 50/200\n",
      "37800/37800 [==============================] - 35s 928us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 51/200\n",
      "37800/37800 [==============================] - 36s 943us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.99357\n",
      "Epoch 52/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.99357\n",
      "Epoch 53/200\n",
      "37800/37800 [==============================] - 35s 927us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.99357\n",
      "Epoch 54/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.99357\n",
      "Epoch 55/200\n",
      "37800/37800 [==============================] - 35s 931us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.99357\n",
      "Epoch 56/200\n",
      "37800/37800 [==============================] - 35s 933us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.99357\n",
      "Epoch 57/200\n",
      "37800/37800 [==============================] - 35s 932us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 58/200\n",
      "37800/37800 [==============================] - 35s 929us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.99357\n",
      "Epoch 59/200\n",
      "37800/37800 [==============================] - 38s 1ms/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.99357\n",
      "Epoch 60/200\n",
      "37800/37800 [==============================] - 36s 957us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.99357\n",
      "Epoch 61/200\n",
      "37800/37800 [==============================] - 35s 919us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.99357\n",
      "Epoch 62/200\n",
      "37800/37800 [==============================] - 35s 925us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.99357\n",
      "Epoch 63/200\n",
      "37800/37800 [==============================] - 35s 935us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.99357\n",
      "Epoch 64/200\n",
      "37800/37800 [==============================] - 35s 928us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 65/200\n",
      "37800/37800 [==============================] - 35s 922us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.99357\n",
      "Epoch 66/200\n",
      "37800/37800 [==============================] - 35s 936us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.99357\n",
      "Epoch 67/200\n",
      "37800/37800 [==============================] - 35s 934us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.99357\n",
      "Epoch 68/200\n",
      "37800/37800 [==============================] - 36s 945us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.99357\n",
      "Epoch 69/200\n",
      "37800/37800 [==============================] - 36s 942us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.99357\n",
      "Epoch 70/200\n",
      "37800/37800 [==============================] - 35s 928us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.99357\n",
      "Epoch 71/200\n",
      "37800/37800 [==============================] - 35s 933us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.99357\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 72/200\n",
      "37800/37800 [==============================] - 35s 931us/step - loss: 5.0459e-11 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.99357\n",
      "Epoch 00072: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x170946390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# val_loss\n",
    "# val_accuracy\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=50, mode='auto', verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor='val_accuracy', mode='auto', verbose=1)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='auto')\n",
    "\n",
    "model.fit(X, y, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-26 13:30:01,890 : INFO : Saved file: ../predictions/cnn_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "if args.run_cnn:\n",
    "    model.load_weights(args.model_name)\n",
    "    predictions = model.predict(x)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    csv_predictions(predictions, 'cnn_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.X.shape\n",
    "args.X.to_numpy().reshape(args.X.shape[0], 28, 28, 1)\n",
    "pd.get_dummies(args.y, prefix='label').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_classifier_builder(params_dict=None):\n",
    "    _params_dict = params_dict if params_dict else {}\n",
    "    return SVC(**_params_dict, kernel='linear')\n",
    "\n",
    "parameters = {'C': [0.01], 'gamma': [0.001]}\n",
    "\n",
    "if args.run_svm:\n",
    "    best_params, score, predictions = predict(args.X, args.y, args.x, svm_classifier_builder, parameters)\n",
    "    csv_predictions(predictions, 'svm_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Model  | Test score  |\n",
    "|---|---|\n",
    "| No validation, 200 epochs  | 0.99157 |\n",
    "| Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Validation (20%), 200 epochs, early stopping val_loss  | 0.98628 |\n",
    "| Validation (20%), 200 epochs, early stopping val_accuracy  | 0.98957 |\n",
    "| Validation (10%), 200 epochs, early stopping val_loss  | 0.98700 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
