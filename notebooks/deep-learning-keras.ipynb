{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Keras-based solution of the MNIST problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo stop the numbers to vary from time to time\n",
    "# Todo add K-fold\n",
    "# Todo add a pipeline to scale params\n",
    "# Todo choose the best params and cnn architecture\n",
    "# Todo implement augmentation\n",
    "# Todo try to get a pretrained cnn\n",
    "# Todo early stop\n",
    "# Todo print the numbers in square like in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = 1337"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reproducibility\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(_seed)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(_seed)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "\n",
    "args.n_splits = 5\n",
    "args.n_jobs = -1\n",
    "args.val_fraction = 0.1\n",
    "args.epochs = 50\n",
    "args.model_name = 'deep-learning-keras-model.hdf5'\n",
    "args.seed=_seed\n",
    "\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "\n",
    "args.run_baseline = False\n",
    "args.run_early_stop = False\n",
    "args.run_grid_search = True\n",
    "args.run_kfold_validation = True\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.raw_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(label, pixels_2d, size_inches=None):\n",
    "    title = args.raw_train.iloc[random_row, 0]\n",
    "    fig, ax = plt.subplots()\n",
    "    if size_inches:\n",
    "        fig.set_size_inches(size_inches[0], size_inches[1])\n",
    "    ax.set_title(label)\n",
    "    imgplot = ax.imshow(pixels_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlbab state-based style of image rendering \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAABKCAYAAADkMDmGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAEeklEQVR4nO2aTWxUVRiGn3emgzLa+kuwlir+kQgLEVpQMTFKjMQFxLAQFi7coESi+LMwrIi6FIlKQlIDaoyJMdFEFyTEGBcalVAIyk8DBdJIkRjARSvR0um8Lua2GbEyw8w911u9b3OTe0/v/d4vT849c865n2zzf1fu304gDcogkEEAMghABgHIIAAZBCDFECStk9QraUTSeyG9WkIGb1I/A68BjwDTQxqlFoLtTwEkdQGzQnql9nVIUhkEMghABgFI8cAoqYVKfnkgL+lyoGS7FLuZ7VQewEbAFxwbQ3gp21TJxgQggwA0CUHSMkmHJR2V9HJcSSWthscESXngCPAwMAjsBlbbPhRfesmomZ6wCDhq+7jt88BHwIp40kpWzcwTOoATVdeDwOILb5K0BlgDkCe/sEhbE5b16w/Ocd4jqufe4JMl2z1AD0CbrvViLQ1tCcAuf1n3vc28DieBzqrrWVHblFMzEHYDd0i6RdI0YBXweTxpJauGIURz+HXATqAP+Nj2wbgSq1bpoYXM/K6N02vvDRG+uTHB9g5gR0y5TKpjm+7hs5Wbub3QwrNPjjKwNX6PVM8YW2bfxJYV7zKnMC2oT2oh5IpF+l5o58Hpv4X3Cu7QoH5/YB59K7ewdP/jwb1SCUEL5zG0dojlHd2cPHEdBeXJkSOvMMv+dEI48hPtz5yrXBhGPUaZMmOuawJ4yUolhPLwMKUTg+SKRa6eOTzR3rttfhC/VEIYlzpv5PuuDyau2wZGg/ikGkK1Xj29gGL/mSCxUw8hR46C8uwcvJPS8YEgHqndcgc4u2gGZcqMGsoB94NT2xO8ZD5vv/LWxHXr1quCeaUWwvm2AndVzZaL/WeDeaUWQpJKNYRc9Ddnx9OM9R8P5pPqgbFMGYC2A4WgPjV7gqROSV9JOiTpoKTnovaNkk5K2hcdj8aZ2NDaoYnzG978Ns7Qf1M9PaEEvGh7r6RWYI+kL6L/bbb9eojE7msfCBF2UtXsCbZP2d4bnQ9T2UrrCJ3YuFK3lJY0G7gb2BU1rZP0o6Ttkq75h2fWRKV4vaOM1O3V3z3C8o5urlgWbkAcV90QJF0JfAKstz0EbAVuA+YDp4BNkz1nu8d2l+2uApfFkHL8qguCpAIVAB+Ol9bZ/sX2mO0y8A6Vz3JTUjU/yEoS8D7wq+31Ve3ttk9F588Di22vqhFrGDjcdNYX1/XAGeBm2zPqeaAeCPcDXwP7Ifrhhg3AaiqvgoEB4KlxKBeJ1Wu7q57EGlUjHjV/Im1/A0y2rxX0e0OSSvW0OSklDaEnjR5Z9RrZ6wAkCCHuIq9YF3YJVafmgWPArcA04AdgbpMx24EF0XkrlSKyuVQqYV+6lFhJ9YTYi7ziXNglBWGyIq/YVqKNLOyqNeUHxkYXdtVKCkKQIq+4FnZJQYi9yCta2G0D+my/UdXeXnXbY8CBWrES2Wi1XZI0XuSVB7bHUOS1BHgC2C9pX9S2AVgt6S8Lu1qBshkj/4GBMQ5lEMggABkEIIMAZBCADAKQQQDgT6wB0WNARlhmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 36x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OO-style image rendering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "random_row = random.randrange(0, args.raw_train.shape[0], 1)\n",
    "label = args.raw_train.iloc[random_row, 0]\n",
    "pixels_2d = args.raw_train.iloc[random_row, 1:].to_numpy().reshape(28, 28)\n",
    "plot_number(label, pixels_2d, (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 02:04:42,166 : INFO : X.shape: (42000, 28, 28, 1)\n",
      "2020-07-23 02:04:42,167 : INFO : X[0][14][14]: [254]\n",
      "2020-07-23 02:04:42,168 : INFO : y.shape: (42000, 10)\n",
      "2020-07-23 02:04:42,168 : INFO : y[0], [0 1 0 0 0 0 0 0 0 0]\n",
      "2020-07-23 02:04:42,174 : INFO : type of target y: 'multilabel-indicator'\n",
      "2020-07-23 02:04:42,174 : INFO : y_sparse.shape: (42000,)\n",
      "2020-07-23 02:04:42,175 : INFO : y_sparse: array([1, 0, 1, ..., 7, 6, 9])\n",
      "2020-07-23 02:04:42,176 : INFO : y_sparse[0]: 1\n",
      "2020-07-23 02:04:42,178 : INFO : type of target y_sparse: 'multiclass'\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils.multiclass\n",
    "\n",
    "X = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_sparse = args.labels.to_numpy()\n",
    "x = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)\n",
    "\n",
    "log.info('X.shape: %s', repr(X.shape))\n",
    "log.info('X[0][14][14]: %s', X[0][14][14])\n",
    "\n",
    "log.info('y.shape: %s', repr(y.shape))\n",
    "log.info('y[0], %s', y[0])\n",
    "log.info('type of target y: %s', repr(sklearn.utils.multiclass.type_of_target(y)))\n",
    "\n",
    "log.info('y_sparse.shape: %s', repr(y_sparse.shape))\n",
    "log.info('y_sparse: %s', repr(y_sparse))\n",
    "log.info('y_sparse[0]: %s', y_sparse[0])\n",
    "log.info('type of target y_sparse: %s', repr(sklearn.utils.multiclass.type_of_target(y_sparse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_sparse_predictions(predictions_sparse, filename):\n",
    "    image_ids = np.arange(1, len(predictions_sparse) + 1)\n",
    "    submission = pd.DataFrame({'ImageId': image_ids, 'Label': predictions_sparse})\n",
    "    filepath = args.predictions_folder/filename\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    log.info('Saved file: %s', filepath)\n",
    "    \n",
    "def csv_predictions(predictions, filename):\n",
    "    log.debug('predictions.shape: %s', repr(predictions.shape))\n",
    "    predictions_sparse = np.argmax(predictions, axis=1)\n",
    "    csv_sparse_predictions(predictions_sparse, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    log.info(\"History keys: %s\", history.history.keys())\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(history.history['accuracy'], label='Train')\n",
    "    ax.plot(history.history['val_accuracy'], label='Test')\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True)\n",
    "    ax.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cross_val_score_sklearn(sklearn_model, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params=None):\n",
    "    cvs = cross_val_score(sklearn_model, X, y, cv=n_splits, n_jobs=args.n_jobs, fit_params=fit_params)\n",
    "    log.info('CV mean accuracy: %0.5f. std: %0.5f', cvs.mean(), cvs.std())\n",
    "    return cvs\n",
    "    \n",
    "def cross_val_score_keras(keras_model_builder, X, y, scoring='accuracy', n_splits=args.n_splits, fit_params={'epochs': args.epochs}):\n",
    "    keras_classifier = KerasClassifier(keras_model_builder)\n",
    "    return cross_val_score_sklearn(keras_classifier, X, y, scoring=scoring, n_splits=n_splits, fit_params=fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "def build_model(layers_list, optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy', metrics_tuple=('accuracy')):\n",
    "    model = models.Sequential(layers_list)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics_tuple])\n",
    "    log.info(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "\n",
    "def build_baseline_model_sparse():\n",
    "    layers_list = [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "    return build_model(layers_list=layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def baseline():\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1)\n",
    "    plot_history(history)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_baseline_predictions.csv')\n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse)\n",
    "    \n",
    "if args.run_baseline:\n",
    "    baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def early_stop(monitor='val_loss'):\n",
    "    # val_loss\n",
    "    # val_accuracy\n",
    "    early_stopping = EarlyStopping(monitor=monitor, patience=10, mode='auto', verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(args.model_name, save_best_only=True, monitor=monitor, mode='auto', verbose=1)\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='auto')\n",
    "\n",
    "    model = build_baseline_model_sparse()\n",
    "    history = model.fit(X, y_sparse, validation_split=args.val_fraction, epochs=args.epochs, batch_size=64, verbose=1, callbacks=[early_stopping, model_checkpoint, reduce_lr_on_plateau])\n",
    "\n",
    "    plot_history(history)\n",
    "    model.load_weights(args.model_name)\n",
    "    predictions = model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_early_stop_predictions.csv')\n",
    "    \n",
    "    if args.run_kfold_validation:\n",
    "        cross_val_score_keras(build_baseline_model_sparse, X, y_sparse, fit_params={'validation_split': args.val_fraction, 'epochs': args.epochs, 'batch_size': 64, 'callbacks': [early_stopping, model_checkpoint, reduce_lr_on_plateau]})\n",
    "\n",
    "if args.run_early_stop:\n",
    "    early_stop(monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic grid search to choose the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 220.9min finished\n",
      "2020-07-23 05:45:37,387 : INFO : Best params: {'epochs': 50, 'layers_candidates_key': 1}\n",
      "2020-07-23 05:45:37,387 : INFO : Best CV score: 0.9863095238095239\n",
      "2020-07-23 05:45:37,388 : INFO : Best std: 0.0007103063757226515\n",
      "2020-07-23 05:45:37,469 : INFO : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.5147 - accuracy: 0.9143 - val_loss: 0.1077 - val_accuracy: 0.9663\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0894 - val_accuracy: 0.9730\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.1031 - val_accuracy: 0.9733\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0414 - accuracy: 0.9877 - val_loss: 0.0648 - val_accuracy: 0.9814\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.0813 - val_accuracy: 0.9835\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0797 - val_accuracy: 0.9812\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0651 - val_accuracy: 0.9865\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 0.0747 - val_accuracy: 0.9848\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0234 - accuracy: 0.9944 - val_loss: 0.0916 - val_accuracy: 0.9849\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.1153 - val_accuracy: 0.9835\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.1078 - val_accuracy: 0.9858\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.1236 - val_accuracy: 0.9840\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0213 - accuracy: 0.9961 - val_loss: 0.0979 - val_accuracy: 0.9887\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0208 - accuracy: 0.9963 - val_loss: 0.1394 - val_accuracy: 0.9833\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 0.2050 - val_accuracy: 0.9848\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 0.1659 - val_accuracy: 0.9850\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 0.1825 - val_accuracy: 0.9858\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.2184 - val_accuracy: 0.9843\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0188 - accuracy: 0.9968 - val_loss: 0.1600 - val_accuracy: 0.9863\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 0.1714 - val_accuracy: 0.9857\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 0.1674 - val_accuracy: 0.9879\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0240 - accuracy: 0.9967 - val_loss: 0.2340 - val_accuracy: 0.9865\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 0.2029 - val_accuracy: 0.9867\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0180 - accuracy: 0.9974 - val_loss: 0.2384 - val_accuracy: 0.9856\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0226 - accuracy: 0.9972 - val_loss: 0.3300 - val_accuracy: 0.9845\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0223 - accuracy: 0.9972 - val_loss: 0.3525 - val_accuracy: 0.9835\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0179 - accuracy: 0.9978 - val_loss: 0.3030 - val_accuracy: 0.9857\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0162 - accuracy: 0.9982 - val_loss: 0.3094 - val_accuracy: 0.9856\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0196 - accuracy: 0.9978 - val_loss: 0.3099 - val_accuracy: 0.9862\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.3178 - val_accuracy: 0.9863\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0187 - accuracy: 0.9979 - val_loss: 0.2784 - val_accuracy: 0.9867\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0183 - accuracy: 0.9984 - val_loss: 0.3160 - val_accuracy: 0.9877\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 0.2994 - val_accuracy: 0.9886\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 0.3987 - val_accuracy: 0.9855\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0165 - accuracy: 0.9986 - val_loss: 0.5022 - val_accuracy: 0.9861\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0158 - accuracy: 0.9989 - val_loss: 0.4273 - val_accuracy: 0.9851\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0222 - accuracy: 0.9980 - val_loss: 0.4063 - val_accuracy: 0.9880\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0233 - accuracy: 0.9981 - val_loss: 0.5973 - val_accuracy: 0.9832\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0229 - accuracy: 0.9983 - val_loss: 0.4574 - val_accuracy: 0.9858\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 0.4513 - val_accuracy: 0.9874\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0160 - accuracy: 0.9986 - val_loss: 0.4325 - val_accuracy: 0.9882\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0184 - accuracy: 0.9987 - val_loss: 0.4629 - val_accuracy: 0.9858\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.4692 - val_accuracy: 0.9865\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.4033 - val_accuracy: 0.9883\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0159 - accuracy: 0.9988 - val_loss: 0.4678 - val_accuracy: 0.9868\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0199 - accuracy: 0.9986 - val_loss: 0.5216 - val_accuracy: 0.9879\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 0.4194 - val_accuracy: 0.9889\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.5724 - val_accuracy: 0.9892\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.5017 - val_accuracy: 0.9890\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0236 - accuracy: 0.9986 - val_loss: 0.6049 - val_accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 05:52:36,760 : INFO : Iteration validation score: [0.6048960089683533, 0.9884523749351501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.5255 - accuracy: 0.9102 - val_loss: 0.1127 - val_accuracy: 0.9690\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0792 - accuracy: 0.9766 - val_loss: 0.0639 - val_accuracy: 0.9810\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0554 - accuracy: 0.9837 - val_loss: 0.0697 - val_accuracy: 0.9821\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0445 - accuracy: 0.9878 - val_loss: 0.0716 - val_accuracy: 0.9790\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0369 - accuracy: 0.9901 - val_loss: 0.0553 - val_accuracy: 0.9855\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.0681 - val_accuracy: 0.9873\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 0.1092 - val_accuracy: 0.9830\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0249 - accuracy: 0.9940 - val_loss: 0.0710 - val_accuracy: 0.9857\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.0877 - val_accuracy: 0.9864\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.0896 - val_accuracy: 0.9855\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0887 - val_accuracy: 0.9883\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.1390 - val_accuracy: 0.9857\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.1266 - val_accuracy: 0.9873\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 0.1075 - val_accuracy: 0.9873\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.1203 - val_accuracy: 0.9873\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.1279 - val_accuracy: 0.9877\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0206 - accuracy: 0.9968 - val_loss: 0.1932 - val_accuracy: 0.9852\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0218 - accuracy: 0.9960 - val_loss: 0.1548 - val_accuracy: 0.9869\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0233 - accuracy: 0.9966 - val_loss: 0.1640 - val_accuracy: 0.9875\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.1556 - val_accuracy: 0.9882\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.1653 - val_accuracy: 0.9881\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0220 - accuracy: 0.9968 - val_loss: 0.1762 - val_accuracy: 0.9882\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0207 - accuracy: 0.9973 - val_loss: 0.1905 - val_accuracy: 0.9875\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2211 - val_accuracy: 0.9870\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.2515 - val_accuracy: 0.9870\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0210 - accuracy: 0.9974 - val_loss: 0.2841 - val_accuracy: 0.9880\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0237 - accuracy: 0.9977 - val_loss: 0.2480 - val_accuracy: 0.9881\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0177 - accuracy: 0.9978 - val_loss: 0.2120 - val_accuracy: 0.9879\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.2512 - val_accuracy: 0.9890\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0188 - accuracy: 0.9980 - val_loss: 0.3094 - val_accuracy: 0.9877\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0195 - accuracy: 0.9980 - val_loss: 0.3088 - val_accuracy: 0.9855\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.3028 - val_accuracy: 0.9881\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0182 - accuracy: 0.9982 - val_loss: 0.2459 - val_accuracy: 0.9883\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0233 - accuracy: 0.9976 - val_loss: 0.2989 - val_accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0199 - accuracy: 0.9983 - val_loss: 0.2870 - val_accuracy: 0.9876\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0244 - accuracy: 0.9981 - val_loss: 0.3516 - val_accuracy: 0.9887\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0221 - accuracy: 0.9980 - val_loss: 0.3887 - val_accuracy: 0.9869\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0184 - accuracy: 0.9982 - val_loss: 0.3541 - val_accuracy: 0.9883\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0206 - accuracy: 0.9983 - val_loss: 0.4849 - val_accuracy: 0.9856\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0198 - accuracy: 0.9983 - val_loss: 0.4639 - val_accuracy: 0.9875\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0194 - accuracy: 0.9983 - val_loss: 0.3856 - val_accuracy: 0.9875\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0136 - accuracy: 0.9988 - val_loss: 0.3473 - val_accuracy: 0.9894\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.2884 - val_accuracy: 0.9896\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0192 - accuracy: 0.9983 - val_loss: 0.3381 - val_accuracy: 0.9892\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0167 - accuracy: 0.9986 - val_loss: 0.4416 - val_accuracy: 0.9888\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0251 - accuracy: 0.9979 - val_loss: 0.3442 - val_accuracy: 0.9900\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0257 - accuracy: 0.9982 - val_loss: 0.4309 - val_accuracy: 0.9870\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0134 - accuracy: 0.9990 - val_loss: 0.3871 - val_accuracy: 0.9905\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.4843 - val_accuracy: 0.9869\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.4245 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 05:59:23,500 : INFO : Iteration validation score: [0.4244757294654846, 0.9898809790611267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.5410 - accuracy: 0.9128 - val_loss: 0.1313 - val_accuracy: 0.9625\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0832 - accuracy: 0.9747 - val_loss: 0.0675 - val_accuracy: 0.9806\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0534 - accuracy: 0.9844 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0432 - accuracy: 0.9879 - val_loss: 0.0628 - val_accuracy: 0.9860\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.0746 - val_accuracy: 0.9808\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0791 - val_accuracy: 0.9845\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0959 - val_accuracy: 0.9858\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0264 - accuracy: 0.9935 - val_loss: 0.0838 - val_accuracy: 0.9864\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.0981 - val_accuracy: 0.9836\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0231 - accuracy: 0.9945 - val_loss: 0.1012 - val_accuracy: 0.9879\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.1189 - val_accuracy: 0.9871\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 0.1522 - val_accuracy: 0.9824\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.1513 - val_accuracy: 0.9868\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.1259 - val_accuracy: 0.9864\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.1718 - val_accuracy: 0.9867\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0191 - accuracy: 0.9968 - val_loss: 0.1512 - val_accuracy: 0.9843\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.1857 - val_accuracy: 0.9842\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.1802 - val_accuracy: 0.9855\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.1676 - val_accuracy: 0.9882\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0200 - accuracy: 0.9975 - val_loss: 0.3201 - val_accuracy: 0.9857\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2346 - val_accuracy: 0.9846\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.3600 - val_accuracy: 0.9827\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.2390 - val_accuracy: 0.9886\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0231 - accuracy: 0.9973 - val_loss: 0.2936 - val_accuracy: 0.9851\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0204 - accuracy: 0.9977 - val_loss: 0.3357 - val_accuracy: 0.9838\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 0.2892 - val_accuracy: 0.9870\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.3495 - val_accuracy: 0.9863\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0181 - accuracy: 0.9979 - val_loss: 0.3845 - val_accuracy: 0.9848\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0209 - accuracy: 0.9979 - val_loss: 0.3380 - val_accuracy: 0.9863\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0190 - accuracy: 0.9983 - val_loss: 0.3072 - val_accuracy: 0.9856\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.3030 - val_accuracy: 0.9877\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0134 - accuracy: 0.9984 - val_loss: 0.3863 - val_accuracy: 0.9854\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.2909 - val_accuracy: 0.9873\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0216 - accuracy: 0.9978 - val_loss: 0.3512 - val_accuracy: 0.9858\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 0.4158 - val_accuracy: 0.9835\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.3920 - val_accuracy: 0.9880\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.4799 - val_accuracy: 0.9864\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.4289 - val_accuracy: 0.9889\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0208 - accuracy: 0.9987 - val_loss: 0.3599 - val_accuracy: 0.9873\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.4856 - val_accuracy: 0.9880\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.4884 - val_accuracy: 0.9882\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0261 - accuracy: 0.9983 - val_loss: 0.5014 - val_accuracy: 0.9890\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0210 - accuracy: 0.9987 - val_loss: 0.4386 - val_accuracy: 0.9882\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0234 - accuracy: 0.9987 - val_loss: 0.4592 - val_accuracy: 0.9868\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0146 - accuracy: 0.9989 - val_loss: 0.5352 - val_accuracy: 0.9875\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0234 - accuracy: 0.9986 - val_loss: 0.4495 - val_accuracy: 0.9865\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0193 - accuracy: 0.9987 - val_loss: 0.5486 - val_accuracy: 0.9873\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0162 - accuracy: 0.9989 - val_loss: 0.6831 - val_accuracy: 0.9861\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0176 - accuracy: 0.9989 - val_loss: 0.5368 - val_accuracy: 0.9863\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.7024 - val_accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 06:06:21,591 : INFO : Iteration validation score: [0.7024446725845337, 0.9869047403335571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.5279 - accuracy: 0.9126 - val_loss: 0.0891 - val_accuracy: 0.9746\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0623 - val_accuracy: 0.9835\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0554 - accuracy: 0.9840 - val_loss: 0.0685 - val_accuracy: 0.9799\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0425 - accuracy: 0.9876 - val_loss: 0.0854 - val_accuracy: 0.9825\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.9854\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.0844 - val_accuracy: 0.9810\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0258 - accuracy: 0.9936 - val_loss: 0.1174 - val_accuracy: 0.9808\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.0953 - val_accuracy: 0.9880\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.0762 - val_accuracy: 0.9869\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.1372 - val_accuracy: 0.9854\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.1190 - val_accuracy: 0.9857\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.1196 - val_accuracy: 0.9867\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.1585 - val_accuracy: 0.9855\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.1405 - val_accuracy: 0.9863\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.1960 - val_accuracy: 0.9794\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.1997 - val_accuracy: 0.9855\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0174 - accuracy: 0.9973 - val_loss: 0.1402 - val_accuracy: 0.9877\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 0.2317 - val_accuracy: 0.9835\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.1388 - val_accuracy: 0.9886\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0208 - accuracy: 0.9974 - val_loss: 0.1423 - val_accuracy: 0.9894\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0222 - accuracy: 0.9970 - val_loss: 0.1833 - val_accuracy: 0.9858\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.1824 - val_accuracy: 0.9850\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0168 - accuracy: 0.9977 - val_loss: 0.2372 - val_accuracy: 0.9861\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0172 - accuracy: 0.9979 - val_loss: 0.3645 - val_accuracy: 0.9830\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0199 - accuracy: 0.9976 - val_loss: 0.2208 - val_accuracy: 0.9879\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0156 - accuracy: 0.9979 - val_loss: 0.2311 - val_accuracy: 0.9862\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 0.2256 - val_accuracy: 0.9882\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0181 - accuracy: 0.9977 - val_loss: 0.2299 - val_accuracy: 0.9893\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0170 - accuracy: 0.9976 - val_loss: 0.2535 - val_accuracy: 0.9874\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0179 - accuracy: 0.9982 - val_loss: 0.2299 - val_accuracy: 0.9881\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0183 - accuracy: 0.9981 - val_loss: 0.2393 - val_accuracy: 0.9880\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.2862 - val_accuracy: 0.9887\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0262 - accuracy: 0.9974 - val_loss: 0.2502 - val_accuracy: 0.9870\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0211 - accuracy: 0.9978 - val_loss: 0.2461 - val_accuracy: 0.9876\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0201 - accuracy: 0.9981 - val_loss: 0.2708 - val_accuracy: 0.9898\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0264 - accuracy: 0.9979 - val_loss: 0.2932 - val_accuracy: 0.9879\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0188 - accuracy: 0.9983 - val_loss: 0.4664 - val_accuracy: 0.9856\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0153 - accuracy: 0.9986 - val_loss: 0.3602 - val_accuracy: 0.9857\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.2956 - val_accuracy: 0.9904\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0174 - accuracy: 0.9984 - val_loss: 0.4660 - val_accuracy: 0.9864\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0371 - accuracy: 0.9973 - val_loss: 0.3999 - val_accuracy: 0.9883\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.3940 - val_accuracy: 0.9896\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0225 - accuracy: 0.9984 - val_loss: 0.4126 - val_accuracy: 0.9883\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0180 - accuracy: 0.9985 - val_loss: 0.4709 - val_accuracy: 0.9905\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0177 - accuracy: 0.9989 - val_loss: 0.5166 - val_accuracy: 0.9894\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0192 - accuracy: 0.9989 - val_loss: 0.5884 - val_accuracy: 0.9882\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0169 - accuracy: 0.9985 - val_loss: 0.5440 - val_accuracy: 0.9881\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0278 - accuracy: 0.9981 - val_loss: 0.4581 - val_accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0142 - accuracy: 0.9987 - val_loss: 0.5755 - val_accuracy: 0.9874\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0221 - accuracy: 0.9987 - val_loss: 0.4981 - val_accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 06:13:17,334 : INFO : Iteration validation score: [0.49810388684272766, 0.9891666769981384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.5472 - accuracy: 0.9094 - val_loss: 0.1376 - val_accuracy: 0.9504\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0795 - accuracy: 0.9770 - val_loss: 0.0833 - val_accuracy: 0.9758\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0526 - accuracy: 0.9851 - val_loss: 0.0781 - val_accuracy: 0.9810\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0432 - accuracy: 0.9876 - val_loss: 0.0621 - val_accuracy: 0.9832\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0752 - val_accuracy: 0.9839\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0615 - val_accuracy: 0.9877\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.0925 - val_accuracy: 0.9838\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.1211 - val_accuracy: 0.9817\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.1101 - val_accuracy: 0.9843\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0907 - val_accuracy: 0.9867\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.1559 - val_accuracy: 0.9832\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.1550 - val_accuracy: 0.9833\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.1409 - val_accuracy: 0.9838\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.1462 - val_accuracy: 0.9823\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.1453 - val_accuracy: 0.9838\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.2859 - val_accuracy: 0.9815\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0229 - accuracy: 0.9965 - val_loss: 0.1702 - val_accuracy: 0.9876\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 0.2784 - val_accuracy: 0.9849\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.2137 - val_accuracy: 0.9842\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.1819 - val_accuracy: 0.9844\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.2054 - val_accuracy: 0.9864\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0231 - accuracy: 0.9970 - val_loss: 0.2021 - val_accuracy: 0.9862\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0175 - accuracy: 0.9977 - val_loss: 0.2906 - val_accuracy: 0.9849\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 0.2427 - val_accuracy: 0.9857\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0185 - accuracy: 0.9977 - val_loss: 0.2581 - val_accuracy: 0.9867\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0194 - accuracy: 0.9973 - val_loss: 0.2494 - val_accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0174 - accuracy: 0.9982 - val_loss: 0.3356 - val_accuracy: 0.9851\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0237 - accuracy: 0.9974 - val_loss: 0.3849 - val_accuracy: 0.9844\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: 0.3488 - val_accuracy: 0.9842\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0164 - accuracy: 0.9984 - val_loss: 0.2970 - val_accuracy: 0.9882\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0193 - accuracy: 0.9979 - val_loss: 0.4436 - val_accuracy: 0.9846\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.4013 - val_accuracy: 0.9862\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0221 - accuracy: 0.9983 - val_loss: 0.5301 - val_accuracy: 0.9850\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0265 - accuracy: 0.9982 - val_loss: 0.4261 - val_accuracy: 0.9869\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0262 - accuracy: 0.9979 - val_loss: 0.4343 - val_accuracy: 0.9867\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0243 - accuracy: 0.9979 - val_loss: 0.3985 - val_accuracy: 0.9871\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0245 - accuracy: 0.9978 - val_loss: 0.3639 - val_accuracy: 0.9876\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0177 - accuracy: 0.9987 - val_loss: 0.4751 - val_accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 0.5030 - val_accuracy: 0.9871\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0287 - accuracy: 0.9977 - val_loss: 0.5331 - val_accuracy: 0.9856\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0227 - accuracy: 0.9980 - val_loss: 0.6060 - val_accuracy: 0.9840\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 9s 16ms/step - loss: 0.0231 - accuracy: 0.9983 - val_loss: 0.4609 - val_accuracy: 0.9885\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 9s 17ms/step - loss: 0.0193 - accuracy: 0.9986 - val_loss: 0.5556 - val_accuracy: 0.9852\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 0.5386 - val_accuracy: 0.9867\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 0.5974 - val_accuracy: 0.9858\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0172 - accuracy: 0.9989 - val_loss: 0.5680 - val_accuracy: 0.9869\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0189 - accuracy: 0.9984 - val_loss: 0.5653 - val_accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.5018 - val_accuracy: 0.9883\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0141 - accuracy: 0.9987 - val_loss: 0.5508 - val_accuracy: 0.9871\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 8s 16ms/step - loss: 0.0141 - accuracy: 0.9992 - val_loss: 0.4682 - val_accuracy: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 06:20:19,480 : INFO : Iteration validation score: [0.46820807456970215, 0.9883333444595337]\n",
      "2020-07-23 06:20:19,481 : INFO : CV accuracy: 0.98855, std: ±0.00099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.4528 - accuracy: 0.9230\n",
      "Epoch 2/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0698 - accuracy: 0.9796\n",
      "Epoch 3/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0512 - accuracy: 0.9856\n",
      "Epoch 4/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0407 - accuracy: 0.9883\n",
      "Epoch 5/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0344 - accuracy: 0.9910\n",
      "Epoch 6/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0284 - accuracy: 0.9923\n",
      "Epoch 7/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0280 - accuracy: 0.9922\n",
      "Epoch 8/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0260 - accuracy: 0.9935\n",
      "Epoch 9/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0262 - accuracy: 0.9940\n",
      "Epoch 10/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0269 - accuracy: 0.9938\n",
      "Epoch 11/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0238 - accuracy: 0.9947\n",
      "Epoch 12/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0273 - accuracy: 0.9946\n",
      "Epoch 13/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0255 - accuracy: 0.9952\n",
      "Epoch 14/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0237 - accuracy: 0.9956\n",
      "Epoch 15/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0243 - accuracy: 0.9956\n",
      "Epoch 16/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0210 - accuracy: 0.9961\n",
      "Epoch 17/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0273 - accuracy: 0.9958\n",
      "Epoch 18/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "Epoch 19/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0224 - accuracy: 0.9962\n",
      "Epoch 20/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0206 - accuracy: 0.9969\n",
      "Epoch 21/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0179 - accuracy: 0.9973\n",
      "Epoch 22/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0256 - accuracy: 0.9965\n",
      "Epoch 23/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0250 - accuracy: 0.9970\n",
      "Epoch 24/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0231 - accuracy: 0.9974\n",
      "Epoch 25/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0246 - accuracy: 0.9969\n",
      "Epoch 26/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0193 - accuracy: 0.9973\n",
      "Epoch 27/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0211 - accuracy: 0.9977\n",
      "Epoch 28/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0322 - accuracy: 0.9968\n",
      "Epoch 29/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0258 - accuracy: 0.9974\n",
      "Epoch 30/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0211 - accuracy: 0.9977\n",
      "Epoch 31/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0282 - accuracy: 0.9971\n",
      "Epoch 32/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0257 - accuracy: 0.9977\n",
      "Epoch 33/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0239 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0235 - accuracy: 0.9979\n",
      "Epoch 35/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0315 - accuracy: 0.9977\n",
      "Epoch 36/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0286 - accuracy: 0.9975\n",
      "Epoch 37/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0245 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0221 - accuracy: 0.9981\n",
      "Epoch 39/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0268 - accuracy: 0.9979\n",
      "Epoch 40/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0327 - accuracy: 0.9978\n",
      "Epoch 41/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0311 - accuracy: 0.9974\n",
      "Epoch 42/50\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0305 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0276 - accuracy: 0.9980\n",
      "Epoch 44/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 45/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0184 - accuracy: 0.9983\n",
      "Epoch 46/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0222 - accuracy: 0.9984\n",
      "Epoch 47/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0166 - accuracy: 0.9986\n",
      "Epoch 48/50\n",
      "657/657 [==============================] - 10s 15ms/step - loss: 0.0316 - accuracy: 0.9981\n",
      "Epoch 49/50\n",
      "657/657 [==============================] - 10s 16ms/step - loss: 0.0221 - accuracy: 0.9986\n",
      "Epoch 50/50\n",
      "657/657 [==============================] - 11s 16ms/step - loss: 0.0304 - accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 06:28:50,114 : INFO : Saved file: ../predictions/cnn_basic_grid_search.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 54min 49s, sys: 55min 4s, total: 2h 49min 53s\n",
      "Wall time: 4h 24min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Todo check metrics for keras and grid search\n",
    "\n",
    "from keras import layers \n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def basic_grid_search():\n",
    "    layers_candidates = {\n",
    "        1: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        2: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        3: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "\n",
    "        4: [layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')],\n",
    "    }\n",
    "    \n",
    "    def _build_model_grid_search(layers_candidates_key=1):\n",
    "        return build_model(layers_candidates[layers_candidates_key])\n",
    "    \n",
    "    keras_classifier = KerasClassifier(_build_model_grid_search, \n",
    "                                       layers_candidates_key=1)\n",
    "    # scoring='neg_log_loss'\n",
    "    # refit=False to avoid info leak to the future kfold validation\n",
    "    gcv = GridSearchCV(keras_classifier,\n",
    "                         param_grid={'epochs': [5, 15, 25, 50], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys())},\n",
    "                         refit=False,\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=args.n_jobs,\n",
    "                         verbose=2)\n",
    "    gcv.fit(X, y_sparse)\n",
    "    log.info('Best params: %s', repr(gcv.best_params_))\n",
    "    log.info('Best CV score: %s', repr(gcv.best_score_))\n",
    "    log.info('Best std: %s', repr(gcv.cv_results_['std_test_score'][gcv.best_index_]))\n",
    "    return gcv, layers_candidates[gcv.best_params_['layers_candidates_key']]\n",
    "\n",
    "def basic_grid_search_cv(best_grid_search_model, initial_weights):\n",
    "    skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=args.seed)\n",
    "    val_accuracies = np.array([])\n",
    "    for train_index, val_index in skf.split(X, y_sparse):\n",
    "        # Clearing the NN.\n",
    "        best_grid_search_model.set_weights(initial_weights)\n",
    "        history = best_grid_search_model.fit(X[train_index], y_sparse[train_index], validation_data=(X[val_index], y_sparse[val_index]), epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "        scores = best_grid_search_model.evaluate(X[val_index], y_sparse[val_index], verbose=0)\n",
    "        log.info('Iteration validation score: %s', repr(scores))\n",
    "        val_accuracies = np.append(val_accuracies, scores[1])\n",
    "    log.info('CV accuracy: %0.5f, std: ±%0.5f', np.mean(val_accuracies), np.std(val_accuracies))\n",
    "\n",
    "if args.run_grid_search:\n",
    "    gcv, layers_list = basic_grid_search()\n",
    "    best_grid_search_model = build_model(layers_list)\n",
    "    # saving initial weights to avoid info leak to cross val stage\n",
    "    # keras doesn't reset weights, so cross validation starts with the weights that were used on the prev stage \n",
    "    # -> they are already adapted for the current validation fold\n",
    "    initial_weights = best_grid_search_model.get_weights()\n",
    "    if args.run_kfold_validation:\n",
    "        basic_grid_search_cv(best_grid_search_model, initial_weights)\n",
    "    best_grid_search_model.set_weights(initial_weights)\n",
    "    history = best_grid_search_model.fit(X, y_sparse, epochs=gcv.best_params_['epochs'], batch_size=64, verbose=1)\n",
    "    predictions = best_grid_search_model.predict(x)\n",
    "    csv_predictions(predictions, 'cnn_basic_grid_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Results\n",
    "\n",
    "input:\n",
    "{'epochs': [2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "results:\n",
    "\n",
    "2020-04-26 15:34:19,980 : INFO : Best params: {'epochs': 10, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-26 15:34:19,982 : INFO : Best CV score: 0.9835238095238095\n",
    "2020-04-26 15:34:19,983 : INFO : Best std: 0.001621147098147533   \n",
    "\n",
    "---\n",
    "input:\n",
    " param_grid={'epochs': [10, 20, 30], \n",
    "                                     'layers_candidates_key': list(layers_candidates.keys()), \n",
    "                                     'metrics_tuple': [('sparse_categorical_accuracy'), ('loss')]},\n",
    "                         cv=args.n_splits,\n",
    "                         scoring='accuracy'}\n",
    "\n",
    "\n",
    "2020-04-27 23:44:34,829 : INFO : Best params: {'epochs': 30, 'layers_candidates_key': 1, 'metrics_tuple': 'sparse_categorical_accuracy'}\n",
    "2020-04-27 23:44:34,829 : INFO : Best CV score: 0.9846190476190475\n",
    "2020-04-27 23:44:34,830 : INFO : Best std: 0.002779092659317115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  | CV mean score |\n",
    "|---|---|---|---|\n",
    "| Baseline | 50 epochs | 0.98657 | 0.98790 ±0.00069 |\n",
    "| Early stop (val_loss) | 9 epochs | 0.98932 | 0.98948 ±0.00059 |\n",
    "| Early stop (val_accuracy) | 14 epochs | 0.99003 | 0.99017 ±0.00037 |\n",
    "| Basic grid search (accuracy) | 50 epochs out of 5, 15, 25, 50; layers: 1 | 0.98800 | 0.98631 ±0.00007 |\n",
    "| Basic grid search (neg_log_loss) | 2 epochs, layers: 2 | 0.98125 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These numbers may vary from time to time \n",
    "| Approach | Model  | Test score  |\n",
    "|---|---|---|\n",
    "| Baseline | No validation, 200 epochs  | 0.99157, 0.98857 |\n",
    "| Baseline | Validation (20%), 45 epochs  | 0.98885 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_loss  | 0.98628 |\n",
    "| Baseline | Validation (20%), 200 epochs, early stopping val_accuracy  | 0.98957 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_loss  | 0.98700 |\n",
    "| Baseline | Validation (10%), 200 epochs, early stopping val_accuracy  | 0.98857 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=5  | 0.98200 |\n",
    "| K-Fold | Scoring neg_log_loss, cv=12  | 0.98142 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the most confusing predicitons\n",
    "def analyse_confusing_predictions(predictions=predictions, n_confused=10, labels=None):\n",
    "    log.info(predictions.shape)\n",
    "    probabilities_sparse = np.max(predictions, axis=1)\n",
    "    min_prob = np.min(probabilities_spar§se)\n",
    "    min_index = np.argmin(probabilities_sparse, axis=0)\n",
    "    log.info('The most likely numbers for the less confident prediction: %s, probabilities: %s', \n",
    "             np.argpartition(predictions[min_index], -3)[-3:], \n",
    "             predictions[min_index][np.argpartition(predictions[min_index], -3)[-3:]])\n",
    "    \n",
    "    most_confused_predictions_indices = np.argpartition(probabilities_sparse, n_confused)[:n_confused]\n",
    "    log.info('Most confused indices: %s', most_confused_predictions_indices)\n",
    "    most_confused_probabilities = predictions[most_confused_predictions_indices]\n",
    "    likely_numbers_most_confused_probabilities = np.argpartition(most_confused_probabilities, -3, axis=1)[:, -3:]\n",
    "\n",
    "    probabilities_likely_numbers_most_confused_probabilities = np.empty(likely_numbers_most_confused_probabilities.shape)\n",
    "    for i, row in enumerate(most_confused_probabilities):\n",
    "        probabilities_likely_numbers_most_confused_probabilities[i] = row[likely_numbers_most_confused_probabilities[i]]\n",
    "\n",
    "    log.info('The most likely numbers for the less confident predictions: \\n%s, \\nprobabilities: \\n%s', \n",
    "            likely_numbers_most_confused_probabilities,\n",
    "            np.around(probabilities_likely_numbers_most_confused_probabilities, decimals=2))\n",
    "\n",
    "    if labels is not None:\n",
    "        for most_confusing_predictions_index in most_confused_predictions_indices:\n",
    "            draw_number(labels[most_confusing_predictions_index], \n",
    "                        args.raw_train.iloc[most_confusing_predictions_index, 1:].to_numpy().reshape(28, 28),\n",
    "                       (0.5, 0.5))\n",
    "\n",
    "analyse_confusing_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
