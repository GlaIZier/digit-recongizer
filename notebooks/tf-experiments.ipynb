{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adjacent-continuity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "%config Completer.use_jedi = False # make autocompletion works in jupyter\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "durable-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.raw_train = pd.read_csv('../data/train.csv.zip')\n",
    "args.raw_test = pd.read_csv('../data/test.csv.zip')\n",
    "args.predictions_folder = Path('../predictions')\n",
    "args.n_splits = 5\n",
    "args.n_jobs = 3\n",
    "args.seed = 101\n",
    "args.val_fraction=0.1\n",
    "args.epochs = 50\n",
    "\n",
    "args.train = args.raw_train.iloc[:, 1:].copy()\n",
    "args.labels = args.raw_train['label'].copy()\n",
    "args.test = args.raw_test.copy()\n",
    "\n",
    "\n",
    "args.predictions_folder.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "spectacular-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = args.train.to_numpy().reshape(args.train.shape[0], 28, 28, 1)\n",
    "y = pd.get_dummies(args.labels, prefix='label').to_numpy()\n",
    "y_sparse = args.labels.to_numpy()\n",
    "x = args.test.to_numpy().reshape(args.test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "going-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'019A'], dtype=object)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "tf.square(t)\n",
    "keras.backend.transpose(t)\n",
    "t + tf.cast(tf.constant(1.), tf.int32)\n",
    "v = tf.Variable([[1, 2], [3, 4], [5, 6]])\n",
    "v[0,0].assign(100)\n",
    "tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
    "tf.constant(['019A'])\n",
    "# tf.strings.unicode_decode(tf.constant(['019A']), input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-manner",
   "metadata": {},
   "source": [
    "### Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "explicit-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-05 18:14:03,839 : INFO : Epoch 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-abb714727f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {metrics[0].result():.{5}f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mcustom_training_loop_my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-155-abb714727f05>\u001b[0m in \u001b[0;36mcustom_training_loop_my\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m   return K.sparse_categorical_crossentropy(\n\u001b[0m\u001b[1;32m   1569\u001b[0m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[1;32m   1570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4941\u001b[0m           labels=target, logits=output)\n\u001b[1;32m   4942\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4943\u001b[0;31m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0m\u001b[1;32m   4944\u001b[0m         labels=target, logits=output)\n\u001b[1;32m   4945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4238\u001b[0m       \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrank\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mminus\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4239\u001b[0m   \"\"\"\n\u001b[0;32m-> 4240\u001b[0;31m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m   4241\u001b[0m       labels=labels, logits=logits, name=name)\n\u001b[1;32m   4242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4145\u001b[0m     if logits.get_shape().ndims is not None and (\n\u001b[1;32m   4146\u001b[0m         \u001b[0mlabels_static_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4147\u001b[0;31m         labels_static_shape.ndims != logits.get_shape().ndims - 1):\n\u001b[0m\u001b[1;32m   4148\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   4149\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mndims\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;34m\"\"\"Deprecated accessor for `rank`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/digit-recongizer/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;34m\"\"\"Returns the rank of this shape, or None if it is unspecified.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def build_simple_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(28, 28)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax')) # !\n",
    "    return model\n",
    "\n",
    "def custom_training_loop_my():\n",
    "    def shuffle(X, y):\n",
    "        assert len(X) == len(y)\n",
    "        idx = np.random.permutation(len(X))\n",
    "        return X[idx], y[idx]\n",
    "    \n",
    "    n_epochs = 5\n",
    "    batch_size = 32\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    loss_fn = keras.losses.sparse_categorical_crossentropy # try class\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()] # try func\n",
    "    model = build_simple_model()\n",
    "    \n",
    "    # compute grad, autodiff\n",
    "    # perform grad step\n",
    "    # loss, metric\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        log.info(f'Epoch {epoch}...')\n",
    "        n_steps = len(X) // 32 + 1\n",
    "        X_shuffled, y_shuffled = shuffle(X, y_sparse)\n",
    "        for step in range(1, n_steps + 1):\n",
    "            ceiling = step * batch_size if step * batch_size < len(X_shuffled) else len(X_shuffled)\n",
    "            floor = (step - 1) * batch_size\n",
    "            X_batch, y_batch = X_shuffled[floor: ceiling], y_shuffled[floor: ceiling]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X_batch, training=True)\n",
    "                losses = loss_fn(y_batch, y_pred, from_logits=False)\n",
    "            trainable_weights = [weight for l in model.layers for weight in l.trainable_variables]\n",
    "            grads = tape.gradient(losses, trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_weights))\n",
    "            for metric in metrics:\n",
    "                metric.update_state(y_true=y_batch, y_pred=y_pred)\n",
    "        log.info(f'Accuracy: {metrics[0].result():.{5}f}')\n",
    "            \n",
    "custom_training_loop_my()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "functioning-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-05 18:31:57,803 : INFO : Epoch 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense_132/kernel:0' shape=(784, 300) dtype=float32, numpy=\n",
      "array([[ 0.07370681,  0.07299586, -0.07241157, ...,  0.02127581,\n",
      "         0.10312156,  0.10082609],\n",
      "       [-0.029597  , -0.04897328,  0.03768064, ...,  0.02325827,\n",
      "        -0.02766708,  0.08355017],\n",
      "       [ 0.08120636, -0.02418085,  0.04974856, ..., -0.07323386,\n",
      "        -0.00850875, -0.02393488],\n",
      "       ...,\n",
      "       [-0.0574012 , -0.03420052, -0.02062207, ...,  0.00929724,\n",
      "        -0.04794338,  0.08134733],\n",
      "       [-0.0001684 , -0.00425973,  0.03449818, ..., -0.04467567,\n",
      "         0.08932037,  0.01097009],\n",
      "       [-0.08497547, -0.02800078, -0.01991194, ...,  0.07249659,\n",
      "         0.03787834,  0.01467388]], dtype=float32)>, <tf.Variable 'dense_132/bias:0' shape=(300,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_133/kernel:0' shape=(300, 10) dtype=float32, numpy=\n",
      "array([[-0.0598556 , -0.03102905,  0.02385929, ...,  0.06288289,\n",
      "         0.13260956, -0.12523164],\n",
      "       [-0.04867028,  0.09468703, -0.0523178 , ..., -0.08280429,\n",
      "        -0.07578497,  0.02680001],\n",
      "       [ 0.05333453,  0.02415025, -0.0470295 , ..., -0.02577034,\n",
      "        -0.04517992, -0.07339443],\n",
      "       ...,\n",
      "       [ 0.09717183, -0.02319465,  0.1382898 , ...,  0.06510982,\n",
      "        -0.07467964, -0.09676746],\n",
      "       [ 0.09524702,  0.1208915 ,  0.03890096, ..., -0.07677991,\n",
      "         0.12310617, -0.02806   ],\n",
      "       [-0.09145157, -0.05193884, -0.12642251, ...,  0.02296558,\n",
      "         0.12234403, -0.07163119]], dtype=float32)>, <tf.Variable 'dense_133/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
      "///\n",
      "[<tf.Variable 'dense_132/kernel:0' shape=(784, 300) dtype=float32, numpy=\n",
      "array([[ 0.07370681,  0.07299586, -0.07241157, ...,  0.02127581,\n",
      "         0.10312156,  0.10082609],\n",
      "       [-0.029597  , -0.04897328,  0.03768064, ...,  0.02325827,\n",
      "        -0.02766708,  0.08355017],\n",
      "       [ 0.08120636, -0.02418085,  0.04974856, ..., -0.07323386,\n",
      "        -0.00850875, -0.02393488],\n",
      "       ...,\n",
      "       [-0.0574012 , -0.03420052, -0.02062207, ...,  0.00929724,\n",
      "        -0.04794338,  0.08134733],\n",
      "       [-0.0001684 , -0.00425973,  0.03449818, ..., -0.04467567,\n",
      "         0.08932037,  0.01097009],\n",
      "       [-0.08497547, -0.02800078, -0.01991194, ...,  0.07249659,\n",
      "         0.03787834,  0.01467388]], dtype=float32)>, <tf.Variable 'dense_132/bias:0' shape=(300,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_133/kernel:0' shape=(300, 10) dtype=float32, numpy=\n",
      "array([[-0.0598556 , -0.03102905,  0.02385929, ...,  0.06288289,\n",
      "         0.13260956, -0.12523164],\n",
      "       [-0.04867028,  0.09468703, -0.0523178 , ..., -0.08280429,\n",
      "        -0.07578497,  0.02680001],\n",
      "       [ 0.05333453,  0.02415025, -0.0470295 , ..., -0.02577034,\n",
      "        -0.04517992, -0.07339443],\n",
      "       ...,\n",
      "       [ 0.09717183, -0.02319465,  0.1382898 , ...,  0.06510982,\n",
      "        -0.07467964, -0.09676746],\n",
      "       [ 0.09524702,  0.1208915 ,  0.03890096, ..., -0.07677991,\n",
      "         0.12310617, -0.02806   ],\n",
      "       [-0.09145157, -0.05193884, -0.12642251, ...,  0.02296558,\n",
      "         0.12234403, -0.07163119]], dtype=float32)>, <tf.Variable 'dense_133/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainable_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-ae21c6270285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {metrics[0].result():.{5}f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mcustom_training_loop_revised_by_the_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-ae21c6270285>\u001b[0m in \u001b[0;36mcustom_training_loop_revised_by_the_book\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainable_weights' is not defined"
     ]
    }
   ],
   "source": [
    "def custom_training_loop_revised_by_the_book():\n",
    "    def shuffle(X, y):\n",
    "        assert len(X) == len(y)\n",
    "        idx = np.random.permutation(len(X))\n",
    "        return X[idx], y[idx]\n",
    "    \n",
    "    n_epochs = 5\n",
    "    batch_size = 32\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    "    model = build_simple_model()\n",
    "    \n",
    "    # compute grad, autodiff\n",
    "    # perform grad step\n",
    "    # loss, metric\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        log.info(f'Epoch {epoch}...')\n",
    "        n_steps = len(X) // 32 + 1\n",
    "        X_shuffled, y_shuffled = shuffle(X, y_sparse)\n",
    "        for step in range(1, n_steps + 1):\n",
    "            ceiling = step * batch_size if step * batch_size < len(X_shuffled) else len(X_shuffled)\n",
    "            floor = (step - 1) * batch_size\n",
    "            X_batch, y_batch = X_shuffled[floor: ceiling], y_shuffled[floor: ceiling]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X_batch, training=True)\n",
    "                main_losses = loss_fn(y_batch, y_pred, from_logits=False)\n",
    "                main_mean_loss = tf.reduce_mean(main_losses)\n",
    "                regularization_loss = model.losses\n",
    "                loss = tf.add_n([main_mean_loss] + regularization_loss)\n",
    "            print(model.trainable_variables)\n",
    "            print('///')\n",
    "            print(model.trainable_weights)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_weights))\n",
    "            for metric in metrics:\n",
    "                metric.update_state(y_true=y_batch, y_pred=y_pred)\n",
    "            break\n",
    "        log.info(f'Accuracy: {metrics[0].result():.{5}f}')\n",
    "            \n",
    "custom_training_loop_revised_by_the_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "weighted-bridges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 3)) + 1\n",
    "np.array([[3, 4], [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "talented-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[3, 4],\n",
       "       [1, 2]])>>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[3, 4], [1, 2]]).numpy()\n",
    "tf.Variable([[3, 4], [1, 2]]).numpy()\n",
    "tf.convert_to_tensor(np.array([[3, 4], [1, 2]])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "controlled-vessel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2] + [3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
